{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#  Copyright 2024 -  United Kingdom Research and Innovation\n",
    "#  Copyright 2024 -  The University of Manchester\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "#\n",
    "#  Authored by:    Margaret Duff (STFC-UKRI)\n",
    "#                  Vaggelis Papoutsellis (Finden)\n",
    "#                  Jakob Sauer JÃ¸rgensen (DTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cil\n",
    "from cil.optimisation.functions import L2NormSquared, TotalVariation, MixedL21Norm\n",
    "from cil.optimisation.operators import BlockOperator, FiniteDifferenceOperator, CompositionOperator, DiagonalOperator\n",
    "from cil.optimisation.algorithms import PDHG\n",
    "from cil.utilities import dataexample\n",
    "from cil.plugins.ccpi_regularisation.functions import FGP_dTV\n",
    "import numpy as np\n",
    "\n",
    "from cil.utilities import dataexample\n",
    "from cil.utilities.display import show2D\n",
    "from cil.recon import FDK\n",
    "from cil.processors import TransmissionAbsorptionConverter, Slicer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cil.plugins.tigre import ProjectionOperator\n",
    "from cil.optimisation.algorithms import FISTA\n",
    "from cil.optimisation.functions import LeastSquares, TotalVariation\n",
    "from cil.optimisation.operators import BlurringOperator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up default colour map for visualisation\n",
    "cmap = \"gray\"\n",
    "\n",
    "# set the backend for FBP and the ProjectionOperator\n",
    "device = 'gpu'\n",
    "\n",
    "print(cil.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Simulated sphere fan beam reconstruction using directional total variation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we motivate and demonstrate the directional TV regulariser from the CCPi regularisation toolkit. We use this regulariser to reconstruct a slice from a simulated sphere cone beam dataset where the forward model involves a gaussian blur and then a tomographic cone beam projection. We then show how this regulariser could be implemented using the CIL optimisation toolkit. \n",
    "\n",
    "Learning objectives:\n",
    "- Introduce the dTV regulariser \n",
    "- Demonstrate the dTV regularisation using the CCPi regularisation toolkit, seeing examples of over and under regularisation \n",
    "- Use the CIL BlockFramework and PDHG to define and minimise an objective function written in CIL for using dTV for denoising.\n",
    "\n",
    "For further examples of using dTV and for references, please see the second CIL paper (https://doi.org/10.1098/rsta.2020.0193) and the accompanying code  (https://github.com/TomographicImaging/Paper-2021-RSTA-CIL-Part-II/tree/main/CaseStudy_DynamicTomography)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, create and show the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the simulated spheres dataset contained in the CIL `dataexample` module. We consider just the central slice for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load data\n",
    "ground_truth = dataexample.SIMULATED_SPHERE_VOLUME.get()\n",
    "\n",
    "data = dataexample.SIMULATED_CONE_BEAM_DATA.get()\n",
    "\n",
    "data = data.get_slice(vertical='centre')\n",
    "ag = data.geometry\n",
    "absorption = TransmissionAbsorptionConverter()(data)\n",
    "\n",
    "ground_truth = ground_truth.get_slice(vertical='centre')\n",
    "ig = ground_truth.geometry\n",
    "\n",
    "show2D([ground_truth], title=['Ground Truth'], origin='upper', num_cols=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward model, we will include both a tomographic projection and a blurr. In the next cell, we define a point spread function and pass this to the CIL `BlurringOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf(n=5, sig=1.):\n",
    "    \"\"\"\n",
    "    creates psf with side length `n` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(n - 1) / 2., (n - 1) / 2., n)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "\n",
    "PSF = psf(5, 2)\n",
    "B = BlurringOperator(PSF, ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this to the ground truth image, we can see the effect of the blurring operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([ground_truth, B.direct(ground_truth)], title=['Ground Truth',\n",
    "       'Blurred image'], origin='upper', num_cols=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the tomographic projection operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ProjectionOperator(image_geometry=ig,\n",
    "                       acquisition_geometry=ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compose the two operators and apply it to our ground truth data before adding noise. We compare the original sinogram with the new noisy and blurred sinogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forward = CompositionOperator(A, B)\n",
    "\n",
    "noisy_absorption = forward.direct(ground_truth)\n",
    "noisy_absorption += 0.1*noisy_absorption.array.max() * \\\n",
    "    noisy_absorption.geometry.allocate('random')\n",
    "\n",
    "show2D([absorption, noisy_absorption], title=[\n",
    "       'Absorption', 'Noisy absorption'], origin='upper', num_cols=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use FDK to attempt to reconstruct the data. The FDK reconstruction assumes the data arises only from a tomographic acquisition and knows nothing about the noise or the blurring.  As expected, it is both blurred and noisy compared to the ground truth image. In the next few sections, we will try and improve this reconstruction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_FDK = FDK(noisy_absorption, image_geometry=ig).run()\n",
    "\n",
    "show2D([ground_truth, recon_FDK], title=['Ground Truth',\n",
    "       'FDK Reconstruction'], origin='upper', num_cols=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FISTA + TV Recon \n",
    "\n",
    "As a baseline we try a TV reconstruction with a non-negativity constraint, using the FISTA algorithm, minimising the objective \n",
    "\n",
    "$$ \\arg \\min_x \\|ABx-y\\|_2^2  + \\alpha g(x)$$ \n",
    "\n",
    " where $B$ is the blurring operator, $A$ the tomographic projection, $ y$ the noisy measured data and $g$ is the TV regulariser with regularisation paramater $\\alpha$. \n",
    "\n",
    " We try a few regularisation parameters and visualise the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alpha=[1, 10, 100, 200]\n",
    "list_solutions_TV = []\n",
    "for alpha in [1, 10, 100, 200]:\n",
    "    F = LeastSquares(A=forward, b=noisy_absorption)\n",
    "    G = alpha*TotalVariation(lower=0)\n",
    "\n",
    "    algo_tv = FISTA(initial=ig.allocate(0), f=F, g=G,\n",
    "                    update_objective_interval=10)\n",
    "    algo_tv.run(250)\n",
    "    list_solutions_TV.append(algo_tv.solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([ground_truth, recon_FDK, list_solutions_TV[0], list_solutions_TV[1], list_solutions_TV[2], list_solutions_TV[3]], title=['Ground Truth', 'FDK Reconstruction',\n",
    "           'TV solution, alpha={}'.format(list_alpha[0]), 'TV solution, alpha={}'.format(list_alpha[1]), 'TV solution, alpha={}'.format(list_alpha[2]), 'TV solution, alpha={}'.format(list_alpha[3])], origin='upper', num_cols=3, fix_range=(0, 0.004));\n",
    "show2D([ground_truth, recon_FDK - ground_truth, list_solutions_TV[0] - ground_truth, list_solutions_TV[1] - ground_truth, list_solutions_TV[2] - ground_truth, list_solutions_TV[3] - ground_truth], title=['Ground Truth', 'FDK reconstruction error',\n",
    "           'TV solution error, alpha={}'.format(list_alpha[0]), 'TV solution error, alpha={}'.format(list_alpha[1]), 'TV solution error, alpha={}'.format(list_alpha[2]) , 'TV solution error, alpha={}'.format(list_alpha[3])], origin='upper', num_cols=3, fix_range=[(0, 0.004), (-0.004, 0.004), (-0.004, 0.004), (-0.004, 0.004), (-0.004, 0.004), (-0.004, 0.004)], cmap=['gray', 'seismic', 'seismic', 'seismic', 'seismic', 'seismic']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the larger values of regularisation parameter, $alpha$, give a smaller error compared with the ground truth image. However, they give quite blocky/cartoon-like images, as expected for TV regularisation. There are errors between the spheres, where they appear still joined together. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directional Total Variation \n",
    "\n",
    "The directional total variation regulariser uses a reference image. The idea is that the $\\textrm{dTV}(x)$ function is smaller when the gradients of $x$ are more aligned with those of the reference image, reaching its minimum when all gradients are perfectly parallel. This regulariser encourages the gradient of the reconstructed image to be equal to or parallel to the gradient of the reference image. The CCPi regularisation toolkit implementation also allows us to add a non-negativity constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical description (can be skipped if wished)\n",
    "\n",
    "First, define the normalised gradient, $\\zeta$ of the reference image, $\\nu$ as $$\\zeta = -\\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}}.$$\n",
    "Here, $\\eta$ is a scalar smoothing parameter to ensure the denominator is always non-zero and is chosen so that  $0<\\eta<<\\|\\nabla\\nu\\|$.\n",
    "\n",
    "For a 2D image, $\\nu \\in \\mathbb{R}^{n\\times m}$, the gradient is calculated in the horizontal and vertical directions and thus the gradient $\\nabla \\nu \\in \\mathbb{R}^{n\\times m \\times 2}$. We then  define  $|\\nabla\\nu|$ to be defined pixel wise as $|\\nabla\\nu|_{i,j}^2=\\nabla\\nu_{i,j,0}^2 + \\nabla\\nu_{i,j,1}^2 $. The addition, square root and division is done pixel wise. Thus for each point in the image space we have a normalised direction, with horizontal and vertical component, as to the gradients in the reference image. \n",
    "\n",
    "We now define weights $D$ to be $$D=I-\\zeta \\zeta^T.$$\n",
    "\n",
    "This is chosen such that, when applied to the gradient of an image $x$, it is small if the gradients of $x$ and $\\nu$ align.\n",
    "\n",
    "As a simple example, consider that the gradient of the reconstructed image, $x$,  and the reference image, $\\nu$,  are perpendicular so that $\\nabla x^T\\nabla \\nu=0$. We then have that\n",
    "\n",
    "$$D\\nabla x = (I-\\zeta \\zeta^T)\\nabla x= \\nabla x - \\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\dfrac{\\nabla \\nu^T }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\nabla x =\\nabla x. $$\n",
    "Thus, encouraging $D\\nabla x$ to be small, means encouraging gradients of $x$ perpendicular to the gradients of the reference image to be small. \n",
    "\n",
    "For a second example, consider that $\\nabla x= \\gamma \\nabla \\nu$ i.e. the gradients of $x$ are a multiple of the gradients of the reference image,  then\n",
    "\n",
    " $$D\\nabla x = \\gamma D\\nabla \\nu= \\gamma (I-\\zeta \\zeta^T)\\nabla \\nu= \\gamma \\left(\\nabla \\nu -\\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\dfrac{\\nabla \\nu^T }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\nabla \\nu \\right)=\\gamma \\nabla \\nu \\left(1-|\\zeta|^2\\right) = \\nabla x \\left(1-|\\zeta|^2 \\right)$$\n",
    "So, in the case where the gradients of $x$ are a multiple of the gradients of the reference image, and that  $|\\zeta|^2$ is close to but less than 1 (recall that $0<\\eta<<\\|\\nabla\\nu\\|$) and  we have that $D\\nabla x $ is a small constant multiplied by $\\nabla x$. This weighting means that gradients parallel to the reference image are penalised much less than gradients perpendicular to the reference image. \n",
    "\n",
    "\n",
    "We thus define the directional total variation regulariser \n",
    "\n",
    "$$g(x) =\\textrm{dTV}(x):= \\sum_i||\\left(D\\nabla x\\right)_i||_2$$\n",
    "\n",
    " where the sum is over the entries, $i$, of the object $D\\nabla x$. Again, in the two dimensional case this is the sum of the norms of the gradients in the horizontal and vertical directions. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reference image \n",
    "\n",
    "To use this regulariser we need a reference image. In the next cell we create a reference image for our reconstruction. From the original spheres image we take just some of the spheres and change the values, compared to the original image. This is to mimic a reference image being taken using a different imaging modality, that would give different intensity values, and might not be able to see all the elements of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% create masks\n",
    "top = ig.allocate(0)\n",
    "bottom = ig.allocate(0)\n",
    "middle = ig.allocate(0)\n",
    "\n",
    "top.fill(\n",
    "    np.asarray(ground_truth.array > 0.8 * ground_truth.max(),\n",
    "               dtype=np.float32)\n",
    ")\n",
    "bottom.fill(\n",
    "    np.asarray(np.invert(ground_truth.array < 0.4 * ground_truth.max()),\n",
    "               dtype=np.float32)\n",
    ")\n",
    "middle.fill(\n",
    "    np.asarray(np.invert(ground_truth.array < 0.7 * ground_truth.max()),\n",
    "               dtype=np.float32)\n",
    ")\n",
    "\n",
    "\n",
    "reference = top*0.2+bottom*0.7 + middle*0.9\n",
    "show2D([ground_truth, reference], title=[\n",
    "       'Ground Truth', 'Reference'], origin='upper', num_cols=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results using dTV\n",
    "We can now compare the dTV results for a number of values of the regularisation parameter,  $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alpha=[1, 10, 100, 1000]\n",
    "list_solutions_dTV = []\n",
    "for alpha in list_alpha:\n",
    "    eta = 0.01\n",
    "    F = LeastSquares(A=forward, b=noisy_absorption)\n",
    "    G = FGP_dTV(reference=reference, alpha=alpha, eta=eta, nonnegativity=True)\n",
    "\n",
    "    algo_dtv = FISTA(initial=ig.allocate(0), f=F, g=G,\n",
    "                     update_objective_interval=10)\n",
    "    algo_dtv.run(250)\n",
    "    list_solutions_dTV.append(algo_dtv.solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([ground_truth, recon_FDK, list_solutions_TV[3], reference,  list_solutions_dTV[0],list_solutions_dTV[1],list_solutions_dTV[2],list_solutions_dTV[3],], title=['Ground Truth', 'FDK Reconstruction', 'TV solution, alpha=200',\n",
    "       'Reference image',  'dTV solution, alpha = {}'.format(list_alpha[0]), 'dTV solution, alpha = {}'.format(list_alpha[1]), 'dTV solution, alpha = {}'.format(list_alpha[2]), 'dTV solution, alpha = {}'.format(list_alpha[3])], origin='upper', num_cols=4, fix_range=[(0, 0.004), (0, 0.004), (0, 0.004), (0, 2), (0, 0.004), (0, 0.004), (0, 0.004), (0, 0.004)]);\n",
    "show2D([ground_truth, recon_FDK - ground_truth, list_solutions_TV[3] - ground_truth, reference,  list_solutions_dTV[0] - ground_truth,  list_solutions_dTV[1] - ground_truth,  list_solutions_dTV[2] - ground_truth,  list_solutions_dTV[3] - ground_truth], title=['Ground Truth', 'FDK reconstruction error', 'TV solution error, alpha = 200', 'Reference image',\n",
    "       'dTV solution error, alpha={}'.format(list_alpha[1]), 'dTV solution error, alpha={}'.format(list_alpha[2]), 'dTV solution error, alpha={}'.format(list_alpha[0]), 'dTV solution error, alpha={}'.format(list_alpha[3])], origin='upper', num_cols=4, fix_range=[(0, 0.004), (-0.004, 0.004), (-0.004, 0.004), (0, 2), (-0.004, 0.004), (-0.004, 0.004), (-0.004, 0.004), (-0.004, 0.004)], cmap=['gray', 'seismic', 'seismic', 'gray', 'seismic', 'seismic', 'seismic', 'seismic']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too small a value of alpha for dTV reconstruction and the solution is noisy and we get some odd artifacts because of the blurring operator. For intermediate values of alpha, the dTV reconstruction gives sharp edges around the spheres in the reference image and blurrier reconstructions of the other spheres. For too large values of alpha, the dTV solution fails to reconstruct the spheres not in the reference image. In this case, too much weight has been given to the reference image and not enough to the data. This is a risk of adding information to the problem, in this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directional TV regularisation, written in CIL \n",
    "\n",
    "Recall the FDK reconstruction from above: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show2D([ground_truth, recon_FDK], title=['Ground Truth',\n",
    "       'FDK Reconstruction'], origin='upper', num_cols=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we consider using the reference image to improve the FDK reconstructed image. We treat this as just a denoising problem and ignore the tomography forward operator. In this case, we choose to denoise the FDK reconstruction using the directional TV regularisation term, i.e. solving the problem\n",
    "\n",
    "$$ \\arg \\min_x \\|x-x_{FDK}\\|_2^2  + \\alpha \\textrm{dTV}(x) .$$ \n",
    "\n",
    "We could use dTV from the regularisation toolkit as above but instead take the opportunity to demonstrate using the BlockOperators in CIL to build up challenging objective functions to minimise.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use PDHG, which solves problems of the form \n",
    "$$\n",
    "\\min_{x\\in\\mathbb{X}} \\mathcal{F}(K x) + \\mathcal{G}(x)\n",
    "\\tag{PDHG form}\n",
    "$$\n",
    "\n",
    "where $F$ and $G$ need to have a calculable proximal and proximal conjugate,  respectively.  We choose $G$ to be the `L2NormSquared` function, $\\min_x \\|x-x_{FDK}\\|_2^2 $ which has a calculable proximal conjugate in CIL.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fidelity term\n",
    "g = L2NormSquared(b=recon_FDK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves the term $\\mathcal{F}(K x) $ to be $\\alpha \\textrm{dTV}(x) $. In the next few blocks, we will set this up. \n",
    "\n",
    "First define a discrete gradient operator, using BlockOperators, that computes finite differences in the vertical and horizontal directions:\n",
    "\n",
    "$$ \\nabla(x) = \n",
    "\\begin{bmatrix}\n",
    "   \\nabla_v\\\\\n",
    "   \\nabla_h\\\\\n",
    "\\end{bmatrix}\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "    \\nabla_vx\\\\\n",
    "    \\nabla_hx\\\\\n",
    "\\end{bmatrix} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX = FiniteDifferenceOperator(ig, direction=0)\n",
    "DY = FiniteDifferenceOperator(ig, direction=1)\n",
    "\n",
    "Grad = BlockOperator(DX, DY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Using this, we can define the normalised gradient $\\zeta = -\\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}}$. This is a BlockDataContainer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grad_ref = Grad.direct(reference)\n",
    "#setting the constant eta \n",
    "eta = 1e-2* grad_ref.norm()\n",
    "denom = np.sqrt(eta**2 + grad_ref.pnorm(2)**2)\n",
    "zeta = grad_ref/denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise $\\zeta$ to see the vertical and horizontal gradients of the reference image. We first use `show2D` to visualise the vertical and horizontal components and then use a quiver plot to combine the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D(zeta);\n",
    "plt.plot\n",
    "x = np.arange(0, 128)\n",
    "y = np.arange(0, 128)\n",
    " \n",
    "X, Y = np.meshgrid(x, y)\n",
    "plt.quiver(X,Y, zeta[0].as_array(), zeta[1].as_array())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $$D=I-\\zeta \\zeta^T$$ and that we are looking to compute $D\\nabla x$. Let's look at the operator $D\\nabla$:\n",
    "\n",
    "$$ D\\nabla = (I-\\zeta \\zeta^T)\\nabla = \\left(I-\\begin{bmatrix}\n",
    "   \\zeta_0\\\\\n",
    "   \\zeta_1\\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "   \\zeta_0 \\ \\ \n",
    "   \\zeta_1\\\\\n",
    "\\end{bmatrix}  \\right)\\begin{bmatrix}\n",
    "   \\nabla_v\\\\\n",
    "   \\nabla_h\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where $\\zeta_0$ and $\\zeta_1$ are the normalised gradient of $\\nu$ in the horizontal and vertical directions, the two elements of the $\\zeta$ BlockOperator we defined above. \n",
    "\n",
    "This can be simplified to be \n",
    "$$ D\\nabla = \\begin{bmatrix}\n",
    "   \\nabla_v- \\left(\\zeta_0^2\\nabla_v + \\zeta_0\\zeta_1\\nabla_h\\right)\\\\\n",
    "   \\nabla_h - \\left(\\zeta_1\\zeta_0\\nabla_v + \\zeta_1^2\\nabla_h\\right)\\\\\n",
    "\\end{bmatrix}. $$\n",
    "\n",
    "Looking at the first entry in the BlockOperator, $\\nabla_v- \\left(\\zeta_0^2\\nabla_v + \\zeta_0\\zeta_1\\nabla_h\\right)$, we do a pointwise multiplication for $\\zeta_0^2\\nabla_v$ and $\\zeta_0\\zeta_1\\nabla_h$ using a `DiagonalOperator` and a `CompositionOperator`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = DX - CompositionOperator(DiagonalOperator(zeta[0]**2), DX)- CompositionOperator(DiagonalOperator(zeta[0]*zeta[1]), DY) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then do the same for the second entry and create a block operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A2 = DY - CompositionOperator(DiagonalOperator(zeta[1]*zeta[0]), DX) - CompositionOperator(DiagonalOperator(zeta[1]**2), DY) \n",
    "\n",
    "\n",
    "operator = BlockOperator(A1, A2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We then choose $F$ to be $\\alpha$ multiplied by the  `MixedL21Norm`: $\\| X \\|_{2,1} = \\sum_{i=1}^{m} \\| X_i \\|_2$. This will do the two norm and the sum to calculate the dTV regulariser. \n",
    "\n",
    "Note: We try with the regularisation parameter $\\alpha=0.02$. This is different to the optimal parameter above because we have a different forward model and the CCPi Regularisation toolikt and CIL dTV implementation may have different scaling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularisation parameter \n",
    "alpha = 0.02\n",
    "f = alpha * MixedL21Norm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the PDHG algorithm to minimise the objective $\\mathcal{F}(K x) + \\mathcal{G}(x)$. \n",
    "\n",
    "Note: our choice of $G$ being strongly convex means we can use primal acceleration in PDHG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg = PDHG(f=f, g=g, operator=operator,\n",
    "            update_objective_interval=100, gamma_g=1.) # use primal acceleration, g being strongly convex\n",
    "pdhg.run(500)\n",
    "\n",
    "\n",
    "show2D([ground_truth, recon_FDK, algo_tv.solution, reference,  pdhg.solution], title=['Ground Truth', 'FDK Reconstruction', 'TV solution, alpha = 200',\n",
    "       'Reference image',  'dTV solution'], origin='upper', num_cols=5, fix_range=[(0, 0.004), (0, 0.004), (0, 0.004), (0, 2), (0, 0.004)]);\n",
    "show2D([ground_truth, recon_FDK-ground_truth, algo_tv.solution-ground_truth, reference,  pdhg.solution-ground_truth], title=['Ground Truth', 'FDK Reconstruction error', 'TV solution error, alpha = 200',\n",
    "       'Reference image',  'dTV solution error'], origin='upper', cmap=['gray', 'seismic', 'seismic', 'gray', 'seismic'], num_cols=5, fix_range=[(0, 0.004), (-0.004, 0.004), (-0.004, 0.004), (0, 2), (-0.004, 0.004)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the FDK reconstruction, the dTV solution has sharper edges and reduced noise. Recall that this dTV reconstruction was set-up to denoise the FDK reconstruction and was unaware of the tomography set-up or the tomographic data. Compared to the TV solution, which utilised this knowledge, the errors plot shows higher errors, especially in the background and in the intensity values of some of the spheres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise \n",
    "\n",
    "The $\\eta$ value controls the weighting $D$ that is applied to the gradient. Play around with the $\\eta$ value in the above code and see what you observe. A smaller value of $\\eta$ will weight the gradients in the reference image more and a larger value of $\\eta$ will focus more on gradients across the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further work\n",
    "This notebook is not quite complete. It would be good to use a CIL dTV implementation for the full forward problem, including the tomographic operators and data. However, CIL currently can't take the proximal of an operator composed with a function so there is no proximal defined for the CIL LeastSquares function (https://github.com/TomographicImaging/CIL/issues/1561). This means we cannot use a CIL LeastSquares function as the function $G$ in PDHG. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil_24_2_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
