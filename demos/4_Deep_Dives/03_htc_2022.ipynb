{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#  Copyright 2024 -  United Kingdom Research and Innovation\n",
    "#  Copyright 2024 -  The University of Manchester\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "#\n",
    "#   Authored by: Jakob S. Jørgensen (DTU)\n",
    "#                Evangelos Papoutsellis(Finden)\n",
    "#                Gemma Fardell (UKRI-STFC)\n",
    "#                Edoardo Pasca (UKRI-STFC)     \n",
    "#                Laura Murgatroyd (UKRI-STFC)\n",
    "#                Margaret Duff (UKRI-STFC)\n",
    "#                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helsinki Tomography Challenge - Limited Angle CT Reconstruction \n",
    "\n",
    "\n",
    "NOTE: this notebook takes a little while to run so we suggest that you \"run all cells\" before starting to read! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the challenge is to recover the shapes of 2D targets imaged with limited-angle tomography on a lab based cone beam set-up. \n",
    "\n",
    "The training set of the HTC2022 challenge consist of homogenous acrylic disk phantoms of 70 mm in diameter, with holes of varying shapes made with a laser cutter. Each disk has a different number of irregular holes in random locations:\n",
    "\n",
    "![image](./htc_code/htc_discs.jpg)\n",
    "\n",
    "The required outcome of the challenge was an algorithm which takes in the X-ray data, i.e., the sinogram and it’s associated metadata about the measurement geometry, and produces a reconstruction which has been segmented into two components: air and plastic. For more details of the challenge see https://fips.fi/data-challenges/helsinki-tomography-challenge-2022/ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIL developer team submitted 5 algorithm submissions to the challenge with algorithm 2 gaining 3rd place, the highest non-machine learning based solution. The paper describing the solution can be found https://doi.org/10.3934/ammc.2023011 and a blog https://ccpi.ac.uk/the-helsinki-tomography-challenge-2022-part-1/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes you through the development and prototyping process used by the team during preparation of the challenge submission. We demonstrate the results on one 50 degree limited angle test data set. \n",
    "\n",
    "In this notebook we do not discuss the segmentation, instead use a segmentation algorithm based on Otsu thresholding (for more information see \"htc_code/helper_functions.py\")\n",
    "\n",
    "The objective of this notebook is to see  examples of:\n",
    "- incorporating prior knowledge of a problem in an variational regularisation framework \n",
    "- utilising the flexibility and near-math syntax of the CIL optimisation toolkit to prototype different reconstruction objectives \n",
    "- the CIL Block Framework and PDHG optimisation algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from htc_code.helper_functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate  \n",
    "from cil.utilities.display import show2D, show_geometry\n",
    "from cil.recon import FDK\n",
    "from cil.optimisation.algorithms import FISTA, PDHG\n",
    "from cil.optimisation.functions import LeastSquares, TotalVariation, L1Norm, MixedL21Norm, L2NormSquared, IndicatorBox, BlockFunction, ZeroFunction\n",
    "from cil.optimisation.operators import GradientOperator, IdentityOperator, BlockOperator, FiniteDifferenceOperator\n",
    "from cil.plugins.tigre import ProjectionOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one of the training data examples available on [zenodo](https://zenodo.org/records/6984868) which can be downloaded from: https://zenodo.org/records/6984868/files/htc2022_ta_full.mat. If you are running this notebook locally you will need to download the data and change the path in the following cell. \n",
    "\n",
    "First consider the full dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full data:\n",
    "full_data = load_htc2022data(\"/mnt/materials/SIRF/Fully3D/CIL/HTC/htc2022_ta_full.mat\")\n",
    "show_geometry(full_data.geometry)\n",
    "ig=full_data.geometry.get_ImageGeometry()\n",
    "fdk =  FDK(full_data, ig)\n",
    "recon_full = fdk.run()\n",
    "show2D([recon_full, apply_crazy_threshold(recon_full)], title=[' Full angle FDK reconstruction', 'Thresholded full angle FDK reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now subset the data considering restricted angles. We restrict to 50 angles but you can always change this and rerun the notebook if you wish. In the next cell we subset the data, print out the chosen angles and plot these in a circle to demonstrate the chosen wedge of angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=generate_reduced_data(full_data, 0, 50)\n",
    "print(data.geometry.angles)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for angle in data.geometry.angles:\n",
    "    plt.plot([0, np.cos(angle*2*np.pi/360)], [0, np.sin(angle*2*np.pi/360)], color='blue')\n",
    "circle1=plt.Circle((0, 0), 1.0, color='r', fill=False)\n",
    "plt.gca().add_patch(circle1)\n",
    "plt.text(0.8,0 , '0 degrees', color='r')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the data. From the left hand axis you can see the limited angles again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show2D(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do an FDK reconstruction to see the effect of subsetting the angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fdk =  FDK(data, ig)\n",
    "recon = fdk.run()\n",
    "show2D([recon, apply_crazy_threshold(recon)], title=['FDK reconstruction', 'Thresholded FDK reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the missing angles leads to poor reconstructions along the edges perpedicular to the observed angles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known information \n",
    "\n",
    "We now add additional information to the reconstruction through preproccessing and variational regularisation. We utilise the following facts:\n",
    "- The objects are made of a single homogeneous material​\n",
    "- The objects have sharp edges \n",
    "- The objects are approximately disk shaped\n",
    "- There is zero attenuation value outside the object \n",
    "- There is a constant attenuation value of 0.0409 mm-1 inside the object\n",
    "- The limited observation angles are known \n",
    "\n",
    "\n",
    "Throughout the next sections we will highlight in bold where we have used these assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We first normalise the data and pad with zeros. For more information see the \"helper_functions.py\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalise data\n",
    "data_renorm = correct_normalisation(data)\n",
    "# pad data\n",
    "data_pad = pad_zeros(data_renorm)\n",
    "\n",
    "\n",
    "\n",
    "#plot the reconstructed image\n",
    "fdk =  FDK(data_pad, ig)\n",
    "recon = fdk.run()\n",
    "show2D([recon, apply_crazy_threshold(recon)], title=['FDK padded reconstruction', 'Thresholded FDK padded reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting a line plot, along the centre of the reconstructed images we see evidence of beam hardening. Beam hardening is when the energy distribution of X-rays shifts toward the higher side as X-rays go through an object. It is visible in the line plot as a \"u\" shaped \"cup\" where the material should have a constant absorption value, such as on the right hand side in this plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the middle row of the reconstruction image\n",
    "middle_row = recon.array[recon.shape[0] // 2, :]\n",
    "\n",
    "# Plot the values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(middle_row)\n",
    "plt.title('Line Plot Through the Middle Row of the Reconstruction Image')\n",
    "plt.xlabel('Pixel Index')\n",
    "plt.ylabel('Intensity Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting the beam hardening artefacts is relatively straightforward for this example as the object being imaged is made of **one constant material** and the training data for the challenge contained the results of imaging a  solid disk (https://zenodo.org/records/6937616/files/htc2022_solid_disc_full.mat). The beam hardening correction values were computed as a one off for the simple full disk full data case and reused across all limited angle cases in the competition.  We can use the `correct_beam_hardening` function from the `helper_functions` module  and these precalculated values to correct the beam hardening artifacts. This gives a small improvement to the reconstructed image and line profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply beam hardening correction\n",
    "data_preprocessed = apply_BHC(data_pad)\n",
    "\n",
    "#plot the reconstructed image\n",
    "fdk =  FDK(data_preprocessed, ig)\n",
    "recon_preprocessed = fdk.run()\n",
    "show2D([recon_preprocessed, apply_crazy_threshold(recon_preprocessed)], title=['FDK preprocessed reconstruction', 'Thresholded FDK preprocessed reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no visible improvement to the reconstruction or segementation but the line plot looks a little better: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the middle row of the reconstruction image\n",
    "middle_row = recon.array[recon.shape[0] // 2, :]\n",
    "middle_row_preprocessed = recon_preprocessed.array[recon.shape[0] // 2, :]\n",
    "\n",
    "# Plot the values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(middle_row)\n",
    "plt.plot(middle_row_preprocessed)\n",
    "plt.title('Line Plot Through the Middle Row of the Reconstruction Image')\n",
    "plt.xlabel('Pixel Index')\n",
    "plt.ylabel('Intensity Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect is more easily seen if running with 360 deg data where there aren't any limited angle artifacts to obscure things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotropic TV reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The objects have sharp edges** and are made of **one constant material** and this suggests using isotropic (the same all directions) TV regularisation, which favours cartoon like images with sharp edges.  \n",
    "\n",
    "We wish to solve\n",
    "\n",
    "$$  \\arg\\min_u \\|Au-y\\|_2^2 + \\alpha \\mathrm{TV}(u) $$\n",
    "\n",
    "where total variation (isotropic) is defined as $$\\mathrm{TV}(u) = \\|\\mathbf{D} u \\|_{2,1} = \\sum \\sqrt{ (\\partial_{y}u)^{2} + (\\partial_{x}u)^{2} }$$ \n",
    "\n",
    "We implement this regularisation using CIL optimisation toolkit and make use of the (explicit) PDHG algorithm as an optimisation algorithm because of its flexibility.\n",
    "\n",
    "In order to use the PDHG algorithm for the problem above, we need to express our minimisation problem into the following form:\n",
    "\n",
    "<a id='PDHG_form'></a>\n",
    "$$\n",
    "\\min_{u\\in\\mathbb{X}} \\mathcal{F}(K u) + \\mathcal{G}(u)\n",
    "\\tag{PDHG form}\n",
    "$$\n",
    "\n",
    "where we assume that:\n",
    "\n",
    "1. $K$ is a continuous linear operator acting from the image (reconstruction) space $\\mathbb{X}$ to the data (sinogram) space $\\mathbb{Y}$ :\n",
    "\n",
    "    $$K : \\mathbb{X} \\rightarrow \\mathbb{Y}. $$\n",
    "\n",
    "2. $\\mathcal{F}$, $\\mathcal{G}$ are __convex__ functionals:\n",
    "    \n",
    "    - $\\mathcal{F}: \\mathbb{Y} \\rightarrow \\mathbb{R}$ \n",
    "    \n",
    "    - $\\mathcal{G}: \\mathbb{X} \\rightarrow \\mathbb{R}$\n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For the setup of the **($L^{2}-TV$) Explicit PDHG**, we let\n",
    "\n",
    "$$\\begin{align*}\n",
    "& f_{1}: \\mathbb{X} \\rightarrow \\mathbb{R}, \\quad f_{1}(z_{1}) = \\|z_{1} - g\\|_{2}^{2}, \\text{ ( the data-fitting term ) }\\nonumber\\\\ \n",
    "\n",
    "& f_{2}: \\mathbb{Y} \\rightarrow \\mathbb{R}, \\quad f_{2}(z_{2}) = \\alpha\\,\\|z_{2}\\|_{2,1}, \\text{ ( the TV term ). }\\nonumber\n",
    "\n",
    "\\end{align*}$$\n",
    "\n",
    "```python\n",
    "\n",
    "                                f1 = L2NormSquared(b=absorption_data)\n",
    "                                f2 = alpha * MixedL21Norm()\n",
    "                                \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "For $z = (z_{1}, z_{2})\\in \\mathbb{Y}\\times \\mathbb{X}$, we define a separable function, e.g., BlockFunction, see the [appendix](../appendix.ipynb).\n",
    "\n",
    "$$\\mathcal{F}(z) : = \\mathcal{F}(z_{1},z_{2}) = f_{1}(z_{1}) + f_{2}(z_{2})$$\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    \n",
    "                                         F = BlockFunction(f1, f2)\n",
    "       \n",
    "```\n",
    "\n",
    "\n",
    "In order to obtain an element $z = (z_{1}, z_{2})\\in \\mathbb{Y}\\times \\mathbb{X}$, we need to define a `BlockOperator` $K$, using the two operators involved in [$L^{2}-TV$](#TomoTV), i.e., the `GradientOperator` $\\mathbf{D}$ and the `ProjectionOperator` $\\mathcal{A}$.\n",
    "\n",
    "$$ \\mathcal{K} = \n",
    "\\begin{bmatrix}\n",
    "\\mathcal{A}\\\\\n",
    "\\mathbf{D}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    \n",
    "                                        Grad = GradientOperator(ig)\n",
    "                                        K = BlockOperator(A, Grad)\n",
    "       \n",
    "```\n",
    "\n",
    "Finally, we set  $\\mathcal{G} \\equiv 0 $ and so  `G = ZeroFunction(lower=0)`.\n",
    "\n",
    "We can verify that with the above setting we can express our problem into PDHG form, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg\\min_u  \\|\\mathcal{A} u - g\\|^{2}_{2} +  \\alpha\\|\\mathbf{D} u\\|_{2,1} + 0 =  \\arg\\min_u   f_{1}(\\mathbf{A} u) + f_{2}(\\mathcal{D}x) + 0 \\\\ = \\arg\\min_u   F\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{A} \\\\\n",
    "\\mathbf{D}\n",
    "\\end{bmatrix}u\\right) + 0 = \n",
    "\\arg\\min_u \\mathcal{F}(Ku) + \\mathcal{G}(u) \\nonumber\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "    \n",
    "Note that the constant $\\alpha$ is a regularisation parameter. We will not go into detail in this notebook how that parameter was chosen, but you can imagine a lot of trial and error! You will however note, in the next cell, that we choose `alpha = 0.01/omega`, where `omega = 90.0/ang_range` depends on range of angles observed. This balances the data discrepancy and the regularisation terms in the case of changing amounts of data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_range = np.abs(data_preprocessed.geometry.angles[-1]-data_preprocessed.geometry.angles[0])\n",
    "omega = 90.0/ang_range\n",
    "\n",
    "alpha = 0.01/omega\n",
    "Grad = GradientOperator(ig)\n",
    "A = ProjectionOperator(ig, data_preprocessed.geometry)\n",
    "Id = IdentityOperator(ig)\n",
    "K = BlockOperator(A, Grad)\n",
    "\n",
    "f1 = L2NormSquared(b=data_preprocessed)\n",
    "f2 = alpha*MixedL21Norm()\n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "G = ZeroFunction()\n",
    "\n",
    "normK = K.norm()\n",
    "sigma = 1.0\n",
    "tau = 1.0/(sigma*normK**2)\n",
    "\n",
    "algo_tv = PDHG(initial=ig.allocate(0.0), f=F, g=G, operator=K, \n",
    "            sigma=sigma, tau=tau,\n",
    "            update_objective_interval=100)\n",
    "algo_tv.run(7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the results: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([algo_tv.solution, apply_crazy_threshold(algo_tv.solution)], title=['Isotropic TV reconstruction', 'Thresholded isotropic TV reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the objective function to check that the algorithm has converged, which it *just* has. We will use 7000 iterations throughout this notebook, though if you have a bit more time, you might get slightly better results with a larger number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(0, 100*len(algo_tv.objective), 100)[5:], algo_tv.objective[5:], label='Objective Function')\n",
    "plt.xlabel('Objective Function')\n",
    "plt.ylabel('Iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the reconstruction that there are negative values and the background is not uniformly 0. We know that tomographic reconstructions should take positive values and we know that for this dataset that there should be **no attenuation in the background**, and that **there is a constant attenuation value of 0.0409 mm-1 inside the object**. We use an indicator function to enforce this in our solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we enforce a non-negativity constraint by letting $\\mathcal{G} = \\mathbb{I}_{\\{0.040859>x>0\\}}(u)$ $\\Longleftrightarrow$ `G = IndicatorBox(lower=0, upper=0.040859)`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01/omega\n",
    "ub_val = 0.040859 # acrylic_attenuation in unit 1/mm\n",
    "\n",
    "\n",
    "Grad = GradientOperator(ig)\n",
    "A = ProjectionOperator(ig, data_preprocessed.geometry)\n",
    "Id = IdentityOperator(ig)\n",
    "K = BlockOperator(A, Grad)\n",
    "\n",
    "f1 = L2NormSquared(b=data_preprocessed)\n",
    "f2 = alpha*MixedL21Norm()\n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "G = IndicatorBox(lower=0, upper=ub_val)\n",
    "\n",
    "normK = K.norm()\n",
    "sigma = 1.0\n",
    "tau = 1.0/(sigma*normK**2)\n",
    "\n",
    "algo_tv_nn = PDHG(initial=ig.allocate(0.0),\n",
    "            f=F, g=G, operator=K, \n",
    "            sigma=sigma, tau=tau,\n",
    "            update_objective_interval=100)\n",
    "algo_tv_nn.run(7000)\n",
    "show2D([algo_tv_nn.solution, apply_crazy_threshold(algo_tv_nn.solution)], title=['TV+non-neg reconstruction', 'Thresholded TV+non-neg reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The background of the reconstruction looks better and there are no negative values but the segmentation still looks bad! \n",
    "\n",
    "We now use the fact that the **object is approximately disk shaped**. We use the clear disk edges on the bottom left and top right in the FDK to fit the disk (see the file \"/htc_code/helper_functions.py\" for more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper bound mask\n",
    "ub_val = 0.040859 # acrylic_attenuation in unit 1/mm\n",
    "ub_mask_type = 2   # 1 basic 0.97 circle. 2 fitted\n",
    "basic_mask_radius = 0.97\n",
    "\n",
    "# Lower bound mask\n",
    "lb_mask_type = 0   # 0:  lower bound 0 everywhere, 1: outer annulus equal to upper bound acrylic\n",
    "lb_inner_radius = 200\n",
    "lb_val = ub_val  # could be changed to 0.04 or other smaller values\n",
    "\n",
    "lb, ub = create_lb_ub(data, ig, ub_mask_type, lb_mask_type, \n",
    "                        ub_val, lb_val, basic_mask_radius, lb_inner_radius);\n",
    "\n",
    "show2D([lb, ub], title=['Lower Bound Mask', 'Upper Bound Mask']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the lower and upper bound masks to the PDHG algorithm and see that this improves both the reconstruction and thresholded image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01/omega\n",
    "\n",
    "Grad = GradientOperator(ig)\n",
    "A = ProjectionOperator(ig, data_preprocessed.geometry)\n",
    "Id = IdentityOperator(ig)\n",
    "K = BlockOperator(A, Grad)\n",
    "\n",
    "f1 = L2NormSquared(b=data_preprocessed)\n",
    "f2 = alpha*MixedL21Norm()\n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "G = IndicatorBox(lower=lb, upper=ub)\n",
    "\n",
    "normK = K.norm()\n",
    "sigma = 1.0\n",
    "tau = 1.0/(sigma*normK**2)\n",
    "\n",
    "algo_mask = PDHG(initial=ig.allocate(0.0),\n",
    "            f=F, g=G, operator=K, \n",
    "            sigma=sigma, tau=tau,\n",
    "            update_objective_interval=100)\n",
    "algo_mask.run(7000)\n",
    "show2D([algo_mask.solution, apply_crazy_threshold(algo_mask.solution)], title=['TV+mask reconstruction', 'Thresholded TV+mask reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotropic and Anisotropic TV \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted above that we are struggling to reconstruct those edges perpendicular to the observation angles. We have not yet used the information on **what angles were observed (and not observed)** in our reconstruction. \n",
    "\n",
    "The idea of this section is that we should try and encourage more edges perpendicular to the observation angles and we do this using an anisotropic (not the same in all directions) TV regularisation term. \n",
    "\n",
    "\n",
    "\n",
    "Consider the objective function $$ \\arg\\min_u\\|Au-b\\|_2^2+\\alpha\\|\\mathbf{D} u\\|_{2,1} +\\alpha_\\mathrm{hori}\\|\\mathbf{D}_{\\mathrm{hori}}u\\|_1+ \\chi_{[0, vm]}(u)$$\n",
    "where $ \\mathbf{D}$ is the gradient function, as above and $\\mathbf{D}_{hori}$ is a finite difference operator acting  horizontally across the image. This can be minimised using PDHG and in the next section we take you through how you would do this. \n",
    "\n",
    "First consider a block function, \n",
    "$$\\begin{equation*}\n",
    "\\mathcal{F} = \\left( \n",
    "\\begin{array}{c}\n",
    "\\| \\cdot - b \\|_2^2 \\\\\n",
    "\\alpha \\| \\cdot \\|_{2,1} \\\\\n",
    "\\alpha_\\mathrm{hori} \\| \\cdot \\|_1\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation*}$$\n",
    "which can be written\n",
    "```python\n",
    "# Define the function f\n",
    "F = BlockFunction(\n",
    "     L2NormSquared(data),\n",
    "    alpha * MixedL21Norm(),\n",
    "    alpha_dx * L1Norm()\n",
    ").\n",
    "```\n",
    "This can be composed with a block operator \n",
    "$$\\begin{equation*}\n",
    "\\mathbf{K} = \n",
    "\\left( \n",
    "\\begin{array}{c}\n",
    "\\mathbf{A} \\\\\n",
    "\\mathbf{D} \\\\\n",
    "\\mathbf{D}_{\\mathrm{hori}}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation*}$$\n",
    "again written in the CIL optimisation framework as\n",
    "```python\n",
    "# Define the operator K\n",
    "K = BlockOperator(\n",
    "    ProjectionOperator(ig, ag),\n",
    "    GradientOperator(ig),\n",
    "    FiniteDifferenceOperator(ig, 'horizontal_x')\n",
    ").\n",
    "```\n",
    "Finally, we include the characteristic function\n",
    "$$\\begin{equation*}\n",
    "\\mathcal{G}  = \\chi_{[0, vm]}\n",
    "\\end{equation*}\n",
    "$$\n",
    "written in CIL as\n",
    "```python\n",
    "# Define the indicator function g\n",
    "G = IndicatorBoxPixelwise(lower=0.0, upper=v * m).\n",
    "```\n",
    "Putting this together in a form suitable for PDHG\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\arg\\min_{u} \\, \\mathcal{F} (\\mathbf{K}u) + \\mathcal{G} (u)\n",
    "\\end{equation*}$$\n",
    "we would then run the code with the following: \n",
    "```python\n",
    "# Set up the Primal-Dual Hybrid Gradient (PDHG) algorithm\n",
    "algo = PDHG(\n",
    "    initial=ig.allocate(0.0),\n",
    "    f=F,\n",
    "    g=G,\n",
    "    operator=K\n",
    ")\n",
    "```\n",
    "```python\n",
    "# Run the algorithm\n",
    "algo.run(7000)\n",
    "```\n",
    "\n",
    "The code above is runnable, however, we are missing data perpendicular to the observation angles and in the above code we consider finite-differences in the horizontal direction. The following code, available from the \"htc_code/helper_functions.py\" will rotate the data so that the mean (centre) observation angle is pointing vertically downwards and we can utilise the finite differences in the horizontal direction to provide more information. For example, on the solution from above: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_middle = (data_preprocessed.geometry.angles[0]+data_preprocessed.geometry.angles[-1])/2\n",
    "show2D( [algo_mask.solution, rotate(algo_mask.solution.as_array(), -ang_middle)], title=['TV+mask reconstruction', 'Rotated TV+mask reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By enforcing additional TV regularisation in this horizontal direction on the rotated images, we try and propogate the information that we do have, along the horizontal direction. \n",
    "\n",
    "We now put this together, rotating the data, reconstructing using PDHG and rotating back again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction\n",
    "alpha = 0.01/omega\n",
    "alpha_dx = 0.03/omega\n",
    "\n",
    "ag_rotated = data_preprocessed.geometry.copy()\n",
    "    \n",
    "ang_middle = (data_preprocessed.geometry.angles[0]+data_preprocessed.geometry.angles[-1])/2\n",
    "ag_rotated.set_angles(data_preprocessed.geometry.angles - ang_middle, angle_unit='degree')\n",
    "\n",
    "data_preprocessed = AcquisitionData(data_preprocessed.as_array(), geometry=ag_rotated)\n",
    "\n",
    "\n",
    "Grad = GradientOperator(ig)\n",
    "A = ProjectionOperator(ig, data_preprocessed.geometry)\n",
    "Dx = FiniteDifferenceOperator(ig, direction='horizontal_x')\n",
    "K12x = BlockOperator(A, Grad, Dx)\n",
    "\n",
    "f1 = L2NormSquared(b=data_preprocessed)\n",
    "f2 = alpha*MixedL21Norm()\n",
    "f_dx = alpha_dx*L1Norm()\n",
    "F12x = BlockFunction(f1, f2, f_dx)\n",
    "\n",
    "lb_copy = lb.copy()\n",
    "ub_copy = ub.copy()\n",
    "lb_copy.array = rotate(lb.as_array(), -ang_middle)\n",
    "ub_copy.array = rotate(ub.as_array(), -ang_middle)\n",
    "\n",
    "G = IndicatorBox(lower=lb_copy, upper=ub_copy)\n",
    "\n",
    "normK = K12x.norm()\n",
    "sigma = 1.0\n",
    "tau = 1.0/(sigma*normK**2)\n",
    "\n",
    "algo_anisotropic = PDHG(initial=ig.allocate(0.0),\n",
    "        f=F12x, g=G, operator=K12x, \n",
    "        sigma=sigma, tau=tau,\n",
    "        update_objective_interval=100)\n",
    "algo_anisotropic.run(7000)\n",
    "sol =  algo_anisotropic.solution.copy()\n",
    "sol.array = rotate(sol.as_array(), ang_middle)\n",
    "\n",
    "\n",
    "show2D([sol, apply_crazy_threshold(sol)], title=['Anisotropic+Isotropic TV reconstruction', 'Thresholded Anisotropic+Isotropic TV reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We can now compare the reconstruction results of all the algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([recon_full, recon_preprocessed, algo_tv.solution, algo_tv_nn.solution, algo_mask.solution, sol], title=['Full angle FDK reconstruction', 'FDK limited angle reconstruction', 'TV reconstruction',  'TV+non-neg reconstruction', 'TV+mask reconstruction', 'Anisotropic+Isotropic TV reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise the thresholded results from all the algorithms: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([apply_crazy_threshold(recon_full), apply_crazy_threshold(recon_preprocessed), apply_crazy_threshold(algo_tv.solution), apply_crazy_threshold(algo_tv_nn.solution), apply_crazy_threshold(algo_mask.solution), apply_crazy_threshold(sol)], title=['Full angle FDK reconstruction', 'FDK limited angle reconstruction', 'TV reconstruction',  'TV+non-neg reconstruction', 'TV+mask reconstruction', 'Anisotropic+Isotropic TV reconstruction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge organisers gave a scoring function, used as the basis for deciding the winner, and quantitively measures the difference between the segmented solution and true solution. The maximum score is one.  We calculate the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in zip([ apply_crazy_threshold(recon_preprocessed), apply_crazy_threshold(algo_tv.solution), apply_crazy_threshold(algo_tv_nn.solution), apply_crazy_threshold(algo_mask.solution), apply_crazy_threshold(sol)],  [ 'FDK limited angle reconstruction', 'TV reconstruction',  'TV+non-neg reconstruction', 'TV+mask reconstruction', 'Anisotropic+Isotropic TV reconstruction']):\n",
    "    print(label, ' : ', calcScoreArray(data.array, apply_crazy_threshold(recon_full).array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more time, even better results could probably be gained, for example, by working on the segmentation alogrithm, however this algorithm finished third in the competition! The results can be seen here https://fips.fi/data-challenges/helsinki-tomography-challenge-2022/#results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "margaret_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
