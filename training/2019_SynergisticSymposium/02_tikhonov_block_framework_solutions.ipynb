{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Copyright 2019 Science Technology Facilities Council\n",
    "# Copyright 2019 University of Manchester\n",
    "#\n",
    "# This work is part of the Core Imaging Library developed by Science Technology\t\n",
    "# Facilities Council and University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# \n",
    "#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tikhonov regularisation using CGLS and block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise introduces Tikhonov regularisation and explains how this is implemented in the CIL framework using the so-called block framework.\n",
    "\n",
    "In the previous exercise, it was seen how CGLS could be used to determine a reconstruction based on the least squares reconstruction problem. It was seen that in case of noisy data, the least squares solution obtained by running until convergence is not desirable due to a high amount of noise. The number of iterations was seen to have a regularising effect, with the smooth, low-frequency components of the image recovered in the first iterations, while high-frequency components of the image such as edges were recovered later. Unfortunately, noise also kicks in, and one needs to pick the number of iterations that best balances the sharpness and amount of noise. As such, the regularising effect is implicitly obtained by choosing the number of iterations to run and never actually running until converged to the least squares solution.\n",
    "\n",
    "Tikhonov regularisation is more explicit in that a regularisation term is added to the least squares fitting term, specifically a squared 2-norm. This problem should now be solved to convergence instead of using the number of iterations as implicit regularising effect. Instead, a parameter, the regularisation parameter, balances the emphasis on fitting the data and enforcing the regularity and must be chosen to provide the best trade-off.\n",
    "\n",
    "Tikhonov regularisation tends to offer reduction of noise in the reconstruction, at the price of some blurring. This will be seen in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Learning objectives:**\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularisation parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all imports required are carried out. This includes tools from the ccpi.framework and ccpi.optimisation modules, as well as test image generation tools in the tomophantom library and standard imports such as numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from ccpi.framework import ImageGeometry, ImageData \n",
    "from ccpi.framework import AcquisitionGeometry, AcquisitionData\n",
    "from ccpi.framework import BlockDataContainer\n",
    "from ccpi.framework import TestData\n",
    "\n",
    "from ccpi.optimisation.algorithms import CGLS\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient, Identity, FiniteDiff\n",
    "\n",
    "from ccpi.astra.operators import AstraProjectorSimple \n",
    "\n",
    "import tomophantom\n",
    "from tomophantom import TomoP2D\n",
    "import scipy\n",
    "import numpy as np    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import plotter2D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting up a simulated 2D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D parallel beam case will be simulated. We start by creating a test image and will use the classic Shepp-Logan Phantom with 1024x1024 pixels. We set up the `ImageGeometry` to specify the dimensions of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up image geometry\n",
    "num_voxels_xy = 1024\n",
    "ig = ImageGeometry(voxel_num_x = num_voxels_xy, voxel_num_y = num_voxels_xy)\n",
    "print(ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tomophantom library we can create a numpy array holding the Shepp-Logan image of the desired size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shepp-Logan phantom \n",
    "model = 1\n",
    "path = os.path.dirname(tomophantom.__file__)\n",
    "path_library2D = os.path.join(path, \"Phantom2DLibrary.dat\")\n",
    "\n",
    "#tomophantom takes angular input in degrees\n",
    "phantom_2D = TomoP2D.Model(model, num_voxels_xy, path_library2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the acquisition parameter and store them in an `AcquisitionGeometry` object. We use 180 projections, a detector of size 1024 pixels and a parallel-beam geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#set up acquisition geometry\n",
    "number_pixels_x = 1024\n",
    "number_projections = 180\n",
    "angles = np.linspace(0, np.pi, number_projections, dtype=np.float32)\n",
    "ag = AcquisitionGeometry(geom_type='parallel', angles=angles, pixel_num_h=number_pixels_x)\n",
    "print(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the library tomophantom it is also possible to generate a numpy array with an analytically computed sinogram from the test image as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "phantom_sino = TomoP2D.ModelSino(model, num_voxels_xy, number_pixels_x, angles*180./np.pi, path_library2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values of both the test image and the sinogram are rescaled for the purpose of Poisson noise simulation in a subsequent step. After scaling the numpy arrays are stored into an ImageData object `model` and AcquisitionData object `sinogram`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Rescale the tomophantom data, set the max absorbtion to 25%\n",
    "set_ratio_absorption = 0.25\n",
    "new_max_value = -np.log(set_ratio_absorption)\n",
    "sino_max = np.amax(phantom_sino)\n",
    "scale = new_max_value/sino_max\n",
    "\n",
    "# Allocate the image data container and copy the dataset in.\n",
    "# This is only used as a reference to the ground truth\n",
    "model = ig.allocate(0)\n",
    "model.fill(phantom_2D*scale)\n",
    "\n",
    "# Allocate the acquisition data container and copy the sinogram in\n",
    "sinogram = ag.allocate(0)\n",
    "sinogram.fill(phantom_sino*scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated test image and sinogram are displayed as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [model, sinogram]\n",
    "titles = [\"Ground truth\", \"sinogram\"]\n",
    "plotter2D(plots,titles,fix_range=False, stretch_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_noise\"></a>\n",
    "Next Poisson noise will be applied to this noise-free sinogram. The severity of the noise can be adjusted by changing the background_counts variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_counts = 1000 #lower counts will increase the noise\n",
    "\n",
    "counts = float(background_counts) * np.exp(-sinogram.as_array())\n",
    "noisy_counts = np.random.poisson(counts)\n",
    "sino_out = -np.log(noisy_counts/background_counts)\n",
    "\n",
    "sinogram_noisy = ag.allocate()\n",
    "sinogram_noisy.fill(sino_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated clean and noisy sinograms are displayed side by side as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [sinogram, sinogram_noisy]\n",
    "titles = [\"sinogram\", \"sinogram noisy\"]\n",
    "plotter2D(plots,titles,fix_range=False, stretch_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_simple\"></a>\n",
    "### Reconstruct using CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before describing Tikhonov regularisation, we recall the problem solved by CGLS:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b\\end{Vmatrix}^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be determined\n",
    "\n",
    "In the solution provided by CGLS the low frequency components tend to converge faster than the high frequency components. This means we need to control the number of iterations carefully to select the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To solve using CGLS (and Tikhonov afterwards) we define the operator A and can choose between a CPU or GPU back-end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "device = \"gpu\"\n",
    "operator = AstraProjectorSimple(ig, ag, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We define the `data` to be used in CGLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = sinogram_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Set up the CGLS algorithm, including specifying its initial point to start from, and an upper bound on the number of iterations to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_init = ig.allocate(0)\n",
    "cgls_simple = CGLS(x_init=x_init, operator=operator, data=data)\n",
    "cgls_simple.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once set up, we can run the algorithm for a specified number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgls_simple.run(20, verbose = True)\n",
    "#cgls_simple.run(5, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Display the resulting image from CGLS, along with its difference image with the original ground truth image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "CGLS_simple_output = cgls_simple.get_output()\n",
    "\n",
    "plots = [CGLS_simple_output, CGLS_simple_output - model]\n",
    "titles = [\"CGLS reconstruction\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot central vertical line profile of CGLS and ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(CGLS_simple_output.subset(horizontal_y=512).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 1:**</span> Try running fewer and more iterations to see how the image and line profile changes. Remember you can change the number of iterations to run between outputs. Also note that the algorithm will continue from the point it stopped and run more iterations from that point if `run` is called again. If you want to run from the beginning, the algorithm needs to be re-initialised. Try to stop the algorithm before the solution starts to diverge. [go to section start](#section_CGLS_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tikhonov regularisation using CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularisation\n",
    "\n",
    "Noisy datasets lead to an ill-posed problem. If we try to solve these using CGLS we end up with an unstable solution. Regularisation adds information in order for us to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "We can add a regularisation term to problem solved by CGLS; this gives us the minimisation problem in the following form, which is known as Tikhonov regularisation:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b \\end{Vmatrix}^2_2 + \\alpha^2\\|Lu\\|^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be solved for\n",
    "\n",
    "- $\\alpha$ is the regularisation parameter\n",
    "\n",
    "- $L$ is a regularisation operator\n",
    "\n",
    "\n",
    "The first term measures the fidelity of the solution to the data. The second term meausures the fidelity to the prior knowledge we have imposed on the system, operator $L$. $\\alpha$ controls the trade-off between these terms. $L$ is often chosen to be a smoothing operator like the identity matrix, or a gradient operator **constrained to the squared L2-norm**.\n",
    "\n",
    "This can be re-written equivalently in the block matrix form:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha L} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha L}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "this can now be recognised as a least squares problem:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "and being a least squares problem, it can be solved using CGLS with $\\tilde{A}$ as operator and $\\tilde{b}$ as data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Introducing the block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can construct $\\tilde{A}$ and $\\tilde{b}$ using the BlockFramework in the CIL.\n",
    "\n",
    "$\\tilde{A}$ is a (column) BlockOperator of size 2x1 and can be set up by\n",
    "\n",
    "`BlockOperator(op0,op1)`\n",
    "\n",
    "The right hand side $\\tilde{b}$ is a BlockDataContainer and can be set up by\n",
    "\n",
    "`BlockDataContainer(DataContainer0, DataContainer1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_alpha\"></a>\n",
    "#### Reconstruct using CGLS and the identity operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest form of Tikhonov uses the identity matrix as the regularisation operator. We use an identity matrix as our regularisation operator we are penalising on the magnitude of the solution $u$, which will tend to reduce the pixel values of $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the operator A\n",
    "device = \"gpu\"\n",
    "A = AstraProjectorSimple(ig, ag, device)\n",
    "L = Identity(ig)\n",
    "alpha = 50\n",
    "\n",
    "operator_block = BlockOperator( A, alpha * L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the formulation of Tikhonov as a least squares problem, we need to set up the right hand side vector $\\tilde{b}$ holding both the $b$ and a zero-filled `ImageData` of the right size, matching the range of the regularising operator. The operator allows us to query the geometry of its range and allocate a zero-filled `ImageData` of that geometry. We combine both into a `BlockDataContainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "zero_data = L.range_geometry().allocate(0)\n",
    "\n",
    "data_block = BlockDataContainer(sinogram_noisy, zero_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Run CGLS as before, but passing the BlockOperator and BlockDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the Block Operator and Block DataContainer\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_regularised = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_regularised.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_regularised.run(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Display results as images and plot central vertical line profile of the Tikhonov with Identity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Tikhonov_identity_output = cgls_regularised.get_output()\n",
    "\n",
    "plots = [Tikhonov_identity_output, Tikhonov_identity_output - model]\n",
    "titles = [\"Tikhonov with Identity regularisation\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the reconstructions from CGLS and Tikhonov with identity regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [CGLS_simple_output, Tikhonov_identity_output]\n",
    "titles = [\"CGLS\",\"Tikhonov with Identity regularisation\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(CGLS_simple_output.subset(horizontal_y=512).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(Tikhonov_identity_output.subset(horizontal_y=512).as_array(),label=\"Tikhonov with Identity regularisation\",color='firebrick')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 2:**</span> Try running Tikhonov with a range of $\\alpha$ values from very small to very large, display reconstruction and line profile and describe the effect of $\\alpha$. Find the value of $\\alpha$ that gives you the best solution. Then change how much noise you add to the data by going back here: [set noise](#section_noise) and run through the notebook again. Try with `background_counts` set to 5000, 10000 and 1000 remember to find an appropriate value of alpha for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Tikhonov regularisation the problem should now be solved to convergence instead of using the number of iterations as implicit regularising effect. By increasing the regularisation parameter $\\alpha$ we balances the emphasis on fitting the data and enforcing the regularity. A low value of $\\alpha$ will give you the CGLS solution, a higher value will reduce the noise in the reconstruction but at the cost of some blurring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the BlockFramework to build a gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Tikhonov with the identity operator provided perhaps a bit of improvement compared to just CGLS, but there was still a lot of noise in the reconstruction and the pixel values had been reduced. Using the identity as regularising operator means that we penalise pixel values that are non-zero, which may not be what we want. Instead, we want to encourage similar values of neighboring pixels to smooth out the noise. This can be achieved by using the gradient as the smoothing operator. \n",
    "\n",
    "To do that we will again need to use the BlockFramework, which is now demonstrated in a bit more detail.\n",
    "\n",
    "A discrete gradient operator (using finite differences) can be constructed using BlockOperators.\n",
    "\n",
    "The direct gradient operator $\\nabla$ acts on an image $u$ and returns a BlockDataContainer $\\textbf{w}$, holding finite differences in the $x$ and $y$ directions:\n",
    "\n",
    "$$ \\nabla(u) = \n",
    "\\begin{bmatrix}\n",
    "   \\nabla_x\\\\\n",
    "   \\nabla_y\\\\\n",
    "\\end{bmatrix}\n",
    "*u =\n",
    "\\begin{bmatrix}\n",
    "    \\nabla_xu\\\\\n",
    "    \\nabla_yu\\\\\n",
    "\\end{bmatrix}\n",
    "=  \n",
    "\\begin{bmatrix}w_{x}\\\\w_{y}\\end{bmatrix}= \\textbf{w}$$\n",
    "\n",
    "The adjoint gradient operator $\\nabla^*$ acts on the BlockDataContainer $\\textbf{y}$ and returns an image $\\rho$\n",
    "\n",
    "$$  \\nabla^*(\\textbf w) = \n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x &\n",
    "    \\nabla^*_y\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "    w_{x}\\\\\n",
    "    w_{y}\\\\\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x w_x + \\nabla^*_y w_y\n",
    "\\end{bmatrix} =  \\rho$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a test image to demonstrate how the gradient operator works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#loading a test image\n",
    "loader = TestData()\n",
    "shapes = loader.load(TestData.SHAPES)\n",
    "shapes_ig = shapes.geometry\n",
    "\n",
    "#plot ths results\n",
    "plotter2D(shapes, \"shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite difference operator can be called from the framework. This returns the difference between each pair of pixels along one direction.\n",
    "\n",
    "We need to initialise it with the image geometry, the direction of the calculation and the boundary conditions to use.\n",
    "\n",
    "`FiniteDiff(gm_domain, direction, bnd_cond='Neumann' or 'Periodic')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the operator FiniteDiff - needs to image geometry, the direction and the boundary conditions\n",
    "fdx = FiniteDiff(shapes_ig, direction=1, bnd_cond='Neumann')\n",
    "\n",
    "#run it over the input image\n",
    "image_2D_dx = fdx.direct(shapes)\n",
    "\n",
    "#plot ths results\n",
    "plotter2D(image_2D_dx, \"dx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how all vertical edges have been picked up (and their sign) applying this operator doing finite differences in the horizontal direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up a gradient in both $x$ and $y$ directions, we can create a BlockOperator to containing a finite difference operator for each of the $x$ and $y$ directions. We can apply it (using its `direct` method) to the test image and visualise the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the x and y operators \n",
    "fdx = FiniteDiff(shapes_ig, direction=1, bnd_cond='Neumann')\n",
    "fdy = FiniteDiff(shapes_ig, direction=0, bnd_cond='Neumann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the BlockOperator combining the two operators\n",
    "FD = BlockOperator(fdx, fdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run it on the test image\n",
    "fd_out = FD.direct(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "plots = [fd_out.get_item(0), fd_out.get_item(1)]\n",
    "titles = [\"dx\",\"dy\" ]\n",
    "plotter2D(plots,titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what is going on, we take a closer look at data types.\n",
    "\n",
    "First, the input is an `ImageData` and its shape is a 2-element vector with the number of pixels in each direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Input\")\n",
    "print(\"\\ttype:\\t\", type(shapes))\n",
    "print(\"\\tshape:\\t\", shapes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output however is a `BlockDataContainer`, essentially a list (with additional functionality) holding two `ImageData` elements, one for each direction we have taken finite differences. We can pick out each element of the `BlockDataContainer` and see that they indeed are `ImageData` and print their shapes (number of pixels in each direction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#output is BloackDataContainer\n",
    "print(\"Output\")\n",
    "print(\"\\ttype:\\t\", type(fd_out))\n",
    "print(\"\\tshape:\\t\", fd_out.shape)\n",
    "\n",
    "print(\"\\tDataContainer 0\")\n",
    "print(\"\\t\\ttype:\\t\", type(fd_out.get_item(0)))\n",
    "print(\"\\t\\tshape:\\t\", fd_out.get_item(0).shape)\n",
    "\n",
    "print(\"\\tDataContainer 1\")\n",
    "print(\"\\t\\ttype:\\t\", type(fd_out.get_item(1)))\n",
    "print(\"\\t\\tshape:\\t\", fd_out.get_item(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BlockFramework provides basic algebra between BlockDataContainers, numpy arrays, lists of numbers,  DataContainers, subclasses and scalars providing the shape of the containers are compatible\n",
    "- add\n",
    "- subtract\n",
    "- multiply\n",
    "- divide\n",
    "- power\n",
    "- squared_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BlockOperator` is a special kind of `Operator`, and being an `Operator` it should have an adjoint method. This is automatically provided from the ajoints of the operators. In the present case our `BlockOperator` will take a `BlockDataContainer` as input to its adjoint and return an `ImageData`, as visualised below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Run the adjoint method\n",
    "adjoint_output = FD.adjoint(fd_out)\n",
    "\n",
    "plotter2D(adjoint_output, \"adjoint gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper look at the BlockFramework\n",
    "#### BlockDataContainer \n",
    "\n",
    "BlockDataContainer holds datacontainers as a column vector\n",
    "\n",
    "$$\\textbf{x} = \\begin{bmatrix}x_{1}\\\\ x_{2}\\end{bmatrix}$$\n",
    "\n",
    "$$\\textbf{y} = \\begin{bmatrix}y_{1}\\\\ y_{2} \\\\ y_{3}\\end{bmatrix}$$\n",
    "\n",
    "#### BlockOperator: \n",
    "\n",
    "BlockOperator is a matrix of operators.\n",
    "\n",
    "$$ K = \\begin{bmatrix}\n",
    "A_{1} & A_{2} \\\\\n",
    "A_{3} & A_{4} \\\\\n",
    "A_{5} & A_{6}\n",
    "\\end{bmatrix}_{(3,2)} *  \\quad \\underbrace{\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \n",
    "\\end{bmatrix}_{(2,1)}}_{\\textbf{x}} =  \\begin{bmatrix}\n",
    "A_{1}x_{1}  + A_{2}x_{2}\\\\\n",
    "A_{3}x_{1}  + A_{4}x_{2}\\\\\n",
    "A_{5}x_{1}  + A_{6}x_{2}\\\\\n",
    "\\end{bmatrix}_{(3,1)} =  \\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix}_{(3,1)} = \\textbf{y}$$\n",
    "\n",
    "Column: Share the same domains $X_{1}, X_{2}$<br>\n",
    "Rows: Share the same ranges $Y_{1}, Y_{2}, Y_{3}$\n",
    "\n",
    "$$ K : (X_{1}\\times X_{2}) \\rightarrow (Y_{1}\\times Y_{2} \\times Y_{3})$$\n",
    "\n",
    "\n",
    "$$ A_{1}, A_{3}, A_{5}: \\text{share the same domain }  X_{1}$$\n",
    "$$ A_{2}, A_{4}, A_{6}: \\text{share the same domain }  X_{2}$$\n",
    "\n",
    "$$A_{1}: X_{1} \\rightarrow Y_{1}, \\quad A_{3}: X_{1} \\rightarrow Y_{2}, \\quad  A_{5}: X_{1} \\rightarrow Y_{3}$$\n",
    "$$A_{2}: X_{2} \\rightarrow Y_{1}, \\quad A_{4}: X_{2} \\rightarrow Y_{2}, \\quad  A_{6}: X_{2} \\rightarrow Y_{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconstruct using Tikhonov CLGS with the gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "Now go back to our Tikonov reconstruction, this time define the gradient operator as the regulariser.\n",
    "\n",
    "$${\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha \\nabla} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha \\nabla}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "And solve using CGLS:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "\n",
    "We'll use the framework's `Gradient()` operator - this is an optimised form of FD over the space dimensions (or even or space+channels in case of multiple channels).\n",
    "\n",
    "\n",
    "<span style=\"color:red;font-size:larger\">**Exercise 3:**</span> Set up the BlockOperator $\\tilde{A}$ and the BlockDataContainer $\\tilde{b}$ as before but with the Gradient operator. Outline code to be completed is given in the next two code cells. Once set up, run the following cells to execute CGLS with these as input. Run Tikhonov reconstruction using gradient regularisation. Try a range of $\\alpha$ values ranging from very small to very large, visualise the resulting image and central line profiles, and describe the effect of the regularisation parameter choice. Find the $\\alpha$ that (visually) gives you the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the operator A\n",
    "device = \"gpu\"\n",
    "A = AstraProjectorSimple(ig, ag, device)\n",
    "L = Gradient(ig)\n",
    "alpha = 100\n",
    "\n",
    "#operator_block = BlockOperator( )\n",
    "operator_block = BlockOperator( A, alpha * L, shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the data b\n",
    "\n",
    "#data_block = BlockDataContainer( )\n",
    "data_block = BlockDataContainer(sinogram_noisy, L.range_geometry().allocate(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the block operator and block data\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_tikhonov = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikhonov.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_tikhonov.run(1000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#plot the results\n",
    "Tikhonov_gradient_output = cgls_tikhonov.get_output()\n",
    "\n",
    "plots = [Tikhonov_gradient_output, Tikhonov_gradient_output - model]\n",
    "titles = [\"Tikhonov with gradient regularisation\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central vertical line profiles of ground truth and Tikhonov with Gradient operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Tikhonov_gradient_output.subset(horizontal_y=512).as_array(),label=\"Tikhonov with Gradient regularisation\",color='purple')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the outputs of each reconstruction\n",
    "\n",
    "To wrap up we compare the reconstructions produced by all reconstruction methods considered in this notebook: Simple CGLS, Tikhonov with Identity regularisation and Tikhonov with Gradient regularisation, along with the ground truth image. We display images and central vertical line profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs of unregularise and regularised CGLS\n",
    "plots = [model, CGLS_simple_output, Tikhonov_identity_output, Tikhonov_gradient_output]\n",
    "titles = [\"Ground truth\", \"CGLS simple\",\"Tikhonov with Identity regularisation\",\"Tikhonov with gradient regularisation\" ]\n",
    "plotter2D(plots,titles,fix_range=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(CGLS_simple_output.subset(horizontal_y=512).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Tikhonov_identity_output.subset(horizontal_y=512).as_array(),label=\"Tikhonov with Identity regularisation\",color='firebrick')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Tikhonov_gradient_output.subset(horizontal_y=512).as_array(),label=\"Tikhonov with Gradient regularisation\",color='purple')\n",
    "plt.plot(model.subset(horizontal_y=512).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from images and line profiles, Tikhonov with Gradient regularisation allows us to reduce the noise in the reconstruction substantially. However, we may pay a price in terms of blurring the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "\n",
    "After having worked through this notebook, we have now seen how to:\n",
    "\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularisation parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the present exercise on Tikhonov regularisation with the CGLS algorithm.  In the next exercise we will see how to use the CIL framework for real data reconstruction and later how to do regularisation based on non-smooth optimisation, to help preserve edges better, while reducing the noise."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cil_19.07] *",
   "language": "python",
   "name": "conda-env-.conda-cil_19.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
