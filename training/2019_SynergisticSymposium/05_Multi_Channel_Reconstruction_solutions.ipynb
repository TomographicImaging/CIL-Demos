{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t#========================================================================\n",
    "\t# Copyright 2019 Science Technology Facilities Council\n",
    "\t# Copyright 2019 University of Manchester\n",
    "\t#\n",
    "\t# This work is part of the Core Imaging Library developed by Science Technology\n",
    "\t# Facilities Council and University of Manchester\n",
    "\t#\n",
    "\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "\t# you may not use this file except in compliance with the License.\n",
    "\t# You may obtain a copy of the License at\n",
    "\t#\n",
    "\t#         http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "\n",
    "\t#\n",
    "\t# Unless required by applicable law or agreed to in writing, software\n",
    "\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "\t# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\t# See the License for the specific language governing permissions and\n",
    "\t# limitations under the License.\n",
    "\t#\n",
    "\t#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Multi-Channel Reconstruction</center></h1>\n",
    "\n",
    "<h2><center>Learning Objectives</center></h2>\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Identify the key differences in building Image/Acquisition Geometries and Operators for multi-channel datasets \n",
    "- Build your own reconstructions using FDK, CGLS and PDHG\n",
    "- Determine optimum regularisation parameters based on reconstruction method\n",
    "- Evaluate the effectiveness of each reconstruction routine using energy profiles and elemental maps.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Acquisition/Image Geometry, Acquisition Data\n",
    "- AstraProjectorMC/3DMC\n",
    "- FDK, CGLS, PDHG, TV\n",
    "- BlockFramework\n",
    "\n",
    "### Background:\n",
    "\n",
    "Conventional X-ray detectors only measure the variable density of objects they pass through, giving no insight into what materials are actually inside. This is because standard detectors measure only the number of photons that arrive at each point on the detector.\n",
    "\n",
    "For multi-channel imaging, one can use an energy-sensitive X-ray detector, which measures the energy of every X-ray photon that arrives at each individual pixel. This provides an additional layer of information which can provide important insight on a sample's composition or structure. However, adapted reconstruction routines are required to account for the extra energy-based dimension.\n",
    "\n",
    "The additional energy dimension is stored as a histogram of energy 'channels', indicating the number of X-ray photons detected by a pixel within a fine energy range. Typically 200+ channels are acquired, however in order to speed up computation time, we will restrict our dataset to just 40 channels, where the dominant energy signals are known to appear.   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from utilities import islicer, link_islicer\n",
    "from utilities.show_utilities import channel_to_energy, show\n",
    "\n",
    "from ccpi.framework import ImageGeometry, AcquisitionGeometry, AcquisitionData, ImageData, BlockDataContainer\n",
    "\n",
    "import numpy as np                 \n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from ccpi.io import NEXUSDataReader\n",
    "from ccpi.optimisation.algorithms import PDHG, CGLS\n",
    "\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient\n",
    "from ccpi.optimisation.functions import L2NormSquared, KullbackLeibler,\\\n",
    "                                MixedL21Norm, BlockFunction, IndicatorBox\n",
    "\n",
    "from ccpi.astra.utils import *\n",
    "from ccpi.astra.processors import FBP\n",
    "from ccpi.astra.operators import AstraProjectorMC, AstraProjector3DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.framework.TestData import data_dir\n",
    "pathname = data_dir\n",
    "filename = 'sinogram_centered_channels100_140.h5'\n",
    "\n",
    "path = os.path.join(pathname , filename)\n",
    "arrays = {}\n",
    "\n",
    "with h5py.File(path, 'r+') as f: \n",
    "    for k, v in f.items():\n",
    "        arrays[k] = np.array(v)\n",
    "    X = arrays['SC'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample we will look at in this notebook is an iodine-stained lizard head. The use of elemental staining is common in biology and medicine, by acting as a contrast agent to provide improved visibility of internal structures for X-ray imaging. Iodine is a popular choice in the clinical and research fields, due to its energy-based properties falling in the typical range for diagnostic X-ray imaging.\n",
    "\n",
    "The sample was scanned in a lab-based X-ray CT cone-beam system at 50keV, 0.8W, using an energy-sensitive detector to acquire a full 4D dataset. The detector consisted of an 80 x 80 pixel array, with pixel sizes of 250 $\\mu$m x 250 $\\mu$m. A source-sample distance of 233.0 mm and a sample-detector distance of 245.0 mm gave a geometric magnification of 2.05x. The sample was scanned for 60 projections over a full 360$^{\\circ}$ rotation, with 60s exposure time per projection.\n",
    "\n",
    "A diagram of the style of setup used for spectral imaging is shown below from a paper by [C.K.Egan *et al*, 2015](https://www.nature.com/articles/srep15979#):\n",
    "\n",
    "<img src=\"images/Spectral_Imaging_Geometry.jpg\" width=800 height=800 align=\"center\">   \n",
    "\n",
    "\n",
    "As shown by the diagram, each pixel stores its own energy channel histogram, with characteristic signals such as 'Absorption edges' (caused by photoelectric absorption of X-ray photons by the iodine in our sample) producing sharp rises in signal. These are the key features we look for when analysing spectral data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Setting up Acquisition/Image Geometry</center></h1>\n",
    "\n",
    "First we need to setup the geometries based on the acquisition system.\n",
    "These are currently ordered based on the 4D raw dataset.\n",
    "\n",
    "Run the code to see the current dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can allocate these separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = X.shape[0]\n",
    "num_pixels_h = X.shape[3]\n",
    "num_pixels_v = X.shape[1]\n",
    "num_angles = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the angles used based on the parameters chosen for data acquisition. An offset is also applied (this just gives us the freedom to adjust the rotation of our reconstructed images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.linspace(-180-55,180-55,num_angles,endpoint=False)*np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4D_Acquisition_Image_Geometry'></a>\n",
    "We encode all this information into `AcquisitionGeometry` and `ImageGeometry`.\n",
    "\n",
    "Recall that the Geometry for scanning with a cone-beam X-ray source is defined by the following parameters:\n",
    "(See **Notebook00_Building_Blocks** for more information)\n",
    "\n",
    "<img src=\"images/cone_geometry.png\" width=800 height=800 align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define acquisition geometry from the detector system acquisition settings\n",
    "# with reordering of the dimension labels to match the raw data\n",
    "\n",
    "distance_source_center = 233.0  # [mm]\n",
    "distance_center_detector = 245.0  # [mm]\n",
    "detector_pixel_size = 0.25  # [mm]\n",
    "\n",
    "ag = AcquisitionGeometry('cone',\n",
    "                         '3D',\n",
    "                         angles,\n",
    "                         pixel_num_h=num_pixels_h,\n",
    "                         pixel_size_h=detector_pixel_size,\n",
    "                         pixel_num_v=num_pixels_v,\n",
    "                         pixel_size_v=detector_pixel_size,                            \n",
    "                         dist_source_center=distance_source_center, \n",
    "                         dist_center_detector=distance_center_detector,\n",
    "                         channels=num_channels,\n",
    "                         dimension_labels = ['channel', 'vertical', 'angle', 'horizontal'])\n",
    "\n",
    "# Create the 4D acquisition data\n",
    "data = ag.allocate()\n",
    "data.fill(X)\n",
    "\n",
    "# Calculate the geometric magnification to scale the voxel size relative\n",
    "# to the detector pixel size.\n",
    "mag = (ag.dist_source_center + ag.dist_center_detector)/ag.dist_source_center\n",
    "\n",
    "# Define Image Geoemtry\n",
    "ig = ImageGeometry(voxel_num_x=ag.pixel_num_h, \n",
    "                     voxel_num_y=ag.pixel_num_h,\n",
    "                     voxel_num_z=ag.pixel_num_h,\n",
    "                     voxel_size_x=ag.pixel_size_h/mag, \n",
    "                     voxel_size_y=ag.pixel_size_h/mag, \n",
    "                     voxel_size_z=ag.pixel_size_h/mag, \n",
    "                     channels=num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an interactive image slicer `islicer` to provide a visualisation of the `AcquisitionData` in any dimension below. Simply by taking a data subset in a particular dimension, we can then visualise the data in any other given dimension.\n",
    "\n",
    "Run the code below to see three such examples:\n",
    "\n",
    "1) Projection radiographs for each of the 60 rotation angles acquired in a single channel\n",
    "\n",
    "2) The sinogram for each energy channel for the central slice subset\n",
    "\n",
    "3) The spectral signals acquired in each energy channel for a single projection angle  \n",
    "\n",
    "\n",
    "**Note: You can adjust the look of your reconstructions by varying certain parameters**  \n",
    " - by removing `cmap`, you return to the default colour map of 'gray'\n",
    " - the default scaling runs from 0.0 through the full data range, vary this using e.g. `minmax = (0.0 , 2.0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(data.subset(channel=20), direction='angle', title = 'Projection Angle', cmap='inferno')\n",
    "islicer(data.subset(vertical=40), direction='channel', title = 'Sinogram Channel', cmap='inferno')\n",
    "islicer(data.subset(angle=40), direction='channel', title = 'Channel', cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the tomography operator for 3D multi-channel data using the `AcquisitionGeometry` and `ImageGeometry`\n",
    "<a id='A3DMC' ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3DMC = AstraProjector3DMC(ig, ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDK Reconstruction\n",
    "\n",
    "One of the simplest, and most common, means of image reconstruction for X-ray CT is the use of Filtered BackProjection (FBP). In the case of many lab-based X-ray sources, which utilise a cone-beam rather than parallel- or fan-beams, we use a specific case of FBP: The [Feldkamp-Davis-Kress (FDK)](https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-1-6-612) algorithm.\n",
    "\n",
    "The function `FBP` is capable of handling reconstructions for both parallel-beam and cone-beam geometries in 2D and 3D. When supplied with both Acquisition and Image Geometry (`ag`, `ig`), the function recognises and performs the appropriate form of FBP, in this case FDK.\n",
    "Run the code below to see a reconstruction using the FDK algorithm.  Here we use a `ram-lak` filter as part of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup geometry for FDK\n",
    "fdk = FBP(ig, ag, 'ram-lak') \n",
    "# Provide dataset\n",
    "fdk.set_input(data)\n",
    "# Store results\n",
    "recon = fdk.get_output()\n",
    "# Check dimensions\n",
    "print('Shape: {}'.format(recon.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon.dimension_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we now have three spatial dimensions to our reconstructed data (each of size 80), along with our 40 energy channels. By selecting a single slice of a spatial dimension, we can view the resulting 80x80 reconstructed image for each energy channel using `islicer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "islicer(recon.subset(vertical=46),direction='channel',\n",
    "        title='FDK: Channel', cmap='inferno', minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some features of the lizard head can be seen in the reconstructed images, much of the signal is shrouded by noise.  \n",
    "In the next section, we will explore the first iterative algorithm - CGLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the CGLS algorithm on a 4D dataset\n",
    "\n",
    "As the next step, we will begin with a standard CGLS algorithm, applied to our 4D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the operator based on the dimensions of the 4D dataset\n",
    "\n",
    "Let's test the CGLS algorithm for just 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise \n",
    "x_init = A3DMC.volume_geometry.allocate()\n",
    "\n",
    "# Run the CGLS for 10 iterations\n",
    "cgls = CGLS(x_init = x_init, operator = A3DMC, data = data, max_iteration = 100)\n",
    "cgls.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use custom-made functions to visualise the quality of our reconstructions. Here we are looking at three commonly used views of the reconstructed dataset (axial, coronal and sagittal), and how these vary for different energy channels. Here we use the `show` function for multi-channel datasets, providing parameters to vary:\n",
    " - Title, Figure/font size\n",
    " - Channel number you wish to view (Currently takes one value for 4D data)\n",
    " - Colour map\n",
    " - Min/max colour map scaling\n",
    "\n",
    "Run the code below to see reconstructions for the 10th, 20th and 30th channel in our truncated dataset, with the X-ray energies these correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot axial, coronal and sagittal views\n",
    "# Plotter automatically converts channel number to energy\n",
    "show(cgls.get_output(), title='CGLS 4D Reconstruction', show_channels=10, \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.3)) \n",
    "show(cgls.get_output(), title='CGLS 4D Reconstruction', show_channels=20, \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.3)) \n",
    "show(cgls.get_output(), title='CGLS 4D Reconstruction', show_channels=30, \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of performing our reconstruction, we change the shape and dimensions of our 4D dataset, as we now have 3 spatial dimensions along with the energy channels.\n",
    "Run the following code to see the new shape and corresponding dimension labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape = ', cgls.get_output().shape)\n",
    "print('Labels = ', cgls.get_output().dimension_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use these labels to once more explore visualisations with the islicer function. Try varying the subset dimension and the direction using the label names above.\n",
    "e.g. try:  \n",
    " `islicer(cgls.get_output().subset(vertical=46),direction='channel',title='Axial: Channel', cmap='inferno', minmax = (0.0,0.4))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples slicer\n",
    "islicer(cgls.get_output().subset(vertical=46),direction='channel',\n",
    "        title='Axial View: Channel', cmap='inferno', minmax = (0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how the visualisation changes if we increase the number of iterations. Using the `show` function, we can visualise the reconstructed image slices at chosen iteration intervals. We'll run it for 30 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise \n",
    "x_init = A3DMC.volume_geometry.allocate()\n",
    "\n",
    "# Set up max iterations and step size\n",
    "max_iter = 30\n",
    "step = 10\n",
    "\n",
    "# Set up algorithm\n",
    "cgls2 = CGLS(x_init = x_init, operator = A3DMC, data = data, \n",
    "             max_iteration = max_iter, update_objective_interval = 10)\n",
    "\n",
    "for i in range(0, max_iter // step):\n",
    "    cgls2.run(step)\n",
    "    \n",
    "    # get and visusualise the results\n",
    "    cgls_out = cgls2.get_output()\n",
    "    show(cgls_out, title='Iteration {},'.format((i+1) * step) + ' Objective Function: {}'.format(cgls2.loss[-1]) + '\\n',\\\n",
    "         show_channels=20,cmap='inferno', figure_size=[15,6], font_size=[25,20], minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images highlight the instability of a basic CGLS algorithm, where the **number of iterations** effectively acts as the algorithm's **regularisation parameter**. As a result, too many iterations leads to a divergence from an optimum solution, and while the objective function continues to reduce, only additional noise is being contributed. \n",
    "\n",
    "In the next section, we will look at a different algorithm: Primal-Dual Hybrid Gradient (PDHG), combined with a Total Variation (TV) regularising factor, to see if this improves our reconstructed data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Variation Regularisation in 4D Volume using PDHG\n",
    "\n",
    "The PDHG algorithm and Total Variation regularisation were covered extensively in **Notebook_04_PDHG_Tomography**, but below gives a brief recap of the basics behind each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on PDHG\n",
    "\n",
    "PDHG aims to solve problems of the form:\n",
    "\n",
    "$$ \\begin{equation} \\min_{u} \\mathcal{F}(K u) + \\mathcal{G}(u) \\label{min_problem} \\end{equation} $$\n",
    "\n",
    "In order to setup and run PDHG, we need to define the following:\n",
    "\n",
    " - The operator $K$.\n",
    " - The function $\\mathcal{F}$ and $\\mathcal{G}$.\n",
    " - Step-sizes $\\sigma$ and $\\tau$ such that $\\sigma\\tau\\|K\\|^{2}<1$.\n",
    " \n",
    "Then we can setup PDHG:\n",
    "\n",
    "`pdhg = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma, max_iteration = maxiter)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Total Variation Regularisation\n",
    "\n",
    "<a id='TV_setup'></a>\n",
    "\n",
    "For this notebook, we will be applying Total Variation (TV) regularisation to our PDHG algorithm. TV is a non-smooth regulariser, \n",
    "\n",
    "$$ \\underset{u}{\\operatorname{argmin}} \\alpha\\,\\mathrm{TV}(u) + \\frac{1}{2} \\| \\mathcal{A} u - g\\|^{2}_{2} + \\mathbb{I}_{\\{u>0\\}}(u) $$\n",
    "\n",
    "where,\n",
    "\n",
    "- The Total Variation is taken as a `MixedL21Norm()`, such that $$\\mathrm{TV}(u) = \\|\\nabla u \\|_{2,1} = \\sum \\sqrt{ (\\partial_{y}u)^{2} + (\\partial_{x}u)^{2} }$$  \n",
    "- $g$ is the Acquisition data obtained from the detector  \n",
    "- $\\mathcal{A}$ is the projection operator ( Radon transform ) that maps from an image-space to an acquisition space, i.e.,  \n",
    "$\\mathcal{A} : X \\rightarrow Y$.  \n",
    "- $\\alpha$ is the regularising parameter that measures a trade-off between the fidelity and the regulariser terms  \n",
    "- $\\mathbb{I}_{\\{u>0\\}}(u) : = \n",
    "\\begin{cases}\n",
    "0, \\mbox u>0\\\\\n",
    "\\infty, \\mbox otherwise\n",
    "\\quad\n",
    "\\end{cases}\n",
    "$ is a positivity constraint for the minimiser, $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up PDHG for TV\n",
    "\n",
    "We define K as a `BlockOperator`, containing the Gradient and Projection operator:\n",
    "\n",
    "$$ K = \n",
    "\\begin{bmatrix}\n",
    "\\nabla\\\\\n",
    "A\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "K = `BlockOperator(Gradient, A)`\n",
    "\n",
    "The function $\\mathcal{F}$, is a `BlockFunction` with\n",
    "\n",
    "a function $\\alpha\\|\\cdot\\|_{2,1}\\quad\\Longleftrightarrow\\quad$ `MixedL21Norm()` term that represents the Total variation regularisation ,\n",
    "\n",
    "a function $\\|\\cdot -g \\|_{2}^{2}\\quad\\Longleftrightarrow\\quad$ `L2NormSquared(data)` term that represents the data fitting.\n",
    "\n",
    "Hence, $\\mathcal{F} = [f_{1}, f_{2}] \\quad\\Longleftrightarrow\\quad $ `F = BlockFunction(MixedL21Norm(), L2NormSquared(data))`\n",
    "\n",
    "Finally, we have the function $\\mathcal{G} = \\mathbb{I}_{\\{u>0\\}}(u) \\quad\\Longleftrightarrow\\quad$ `G = IndicatorBox(lower=0)`\n",
    "\n",
    "Again, we can verify that with the above setting we can express our problem into this form, for $x=u$\n",
    "\n",
    "$$ \\begin{align} \\underset{u}{\\operatorname{argmin}}\\alpha\\|\\nabla u\\|_{2,1} + \\frac{1}{2}\\|\\mathcal{A} u - g\\|^{2}_{2} + \\mathbb{I}_{\\{u>0\\}}(u) \\\\= \\underset{u}{\\operatorname{argmin}} f_{1}(\\nabla u) + f_{2}(\\mathcal{A}u) + \\mathbb{I}_{\\{u>0\\}}(u) \\\\ = \\underset{u}{\\operatorname{argmin}} \\mathcal{F}( \\begin{bmatrix} \\nabla \\\\ \\mathcal{A} \\end{bmatrix}u) + \\mathbb{I}_{\\{u>0\\}}(u)\\\\ = \\underset{u}{\\operatorname{argmin}} \\mathcal{F}(Ku) + \\mathcal{G}(u)\\\\ = \\underset{x}{\\operatorname{argmin}} \\mathcal{F}(Kx) + \\mathcal{G}(x) \\end{align} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The operator K is a Block Operator that contains the gradient and the tomography operator \n",
    "op1 = Gradient(ig)\n",
    "op2 = A3DMC\n",
    "\n",
    "# Set up a BlockOperator K\n",
    "K = BlockOperator(op1, op2, shape=(2,1)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{F}$ is a `BlockFunction` of a fidelity term and our TV regularising term:\n",
    "\n",
    "- $f_{1}$ = $\\alpha\\|\\cdot\\|_{2,1}\\quad\\Longleftrightarrow\\quad$ `MixedL21Norm()` term that represents the Total variation regularisation ,\n",
    "\n",
    "- $f_{2}$ = $\\|\\cdot -g \\|_{2}^{2}\\quad\\Longleftrightarrow\\quad$ `L2NormSquared(data)` term that represents the data fitting.\n",
    "\n",
    "Therefore as $f_{1}$ and $f_{2}$ act on each element of $K$, we end up with  \n",
    "$$ \\mathcal{F}(Ku) = \\mathcal{F}(\n",
    "\\begin{bmatrix}\n",
    "\\nabla u \\\\\n",
    "A u\n",
    "\\end{bmatrix}) = ( f_{1}(\\nabla u), f_{2}(Au) ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "f1 = alpha * MixedL21Norm()  \n",
    "f2 = 0.5 * L2NormSquared(b = data) \n",
    "\n",
    "F = BlockFunction(f1, f2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have our positivity constraint function $\\mathcal{G} = \\mathbb{I}_{\\{u>0\\}}(u) \\quad\\Longleftrightarrow\\quad$ `G = IndicatorBox(lower=0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = IndicatorBox(lower = 0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the operator norm of $K$ (`normK = operator.norm()`), and set our step sizes, $\\sigma$ and $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the operator norm for K\n",
    "normK = K.norm()\n",
    "\n",
    "# Define the step sizes sigma and tau\n",
    "sigma = 1\n",
    "tau = 1/(sigma*normK**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can setup and run the PDHG algorithm. Here it will run for 100 iterations.\n",
    "\n",
    "Due to the increased complexity of the algorithm, combined with the reconstruction of a 4D dataset, the runtime for 100 iterations alone will be around **4 minutes**. However, we may require many more than 100 iterations to reach an optimum solution. Further, we may wish to reconstruct hundreds of energy channels, rather than just the 40 we use here.\n",
    "\n",
    "Therefore, consideration must be taken on the number of iterations you perform based on your choice of algorithm and size of your dataset.\n",
    "\n",
    "**Scroll past the cell below** if you wish to save yourself 4 minutes!  \n",
    "We have provided a final reconstruction after 1000 iterations of PDHG, which required around 40 minutes of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg_S_100 = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma,\n",
    "            max_iteration = 100, update_objective_interval = 25)\n",
    "pdhg_S_100.run()\n",
    "\n",
    "show(pdhg_S_100.get_output(), title='PDHG TV 100 Iterations', \n",
    "     show_channels=20, cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 Iterations\n",
    "\n",
    "We load in the 1000 iteration result using the `NEXUSDataReader()` we saw in **Notebook 03_3D_Diamond_dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in 1000 iteration dataset\n",
    "reader = NEXUSDataReader()\n",
    "reader.set_up(nexus_file = 'pdhg_S_1000.nxs')\n",
    "pdhg_S_1000 = reader.load_data()\n",
    "\n",
    "# Show the result\n",
    "show(pdhg_S_1000, title='PDHG TV 1000 Iterations', \n",
    "     show_channels=20, cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Change correlation to Space-Channel\n",
    "\n",
    "We can make some adjustments to our framework to see how these affect the reconstruction.\n",
    "Our gradient component is capable of smoothing our reconstruction both in the spatial domain, but also in the energy domain, by comparing reconstructions to its neighbouring channel.\n",
    "\n",
    "Try changing the gradient component of our operator, $\\nabla$, so that it is correlated in both the spatial and energy channel domain. We can do this by simply setting:  \n",
    "  \n",
    "  `op1 = Gradient(ig, correlation='SpaceChannels')` \n",
    "\n",
    "Keep the tomography operator, $A$ the same. \n",
    "\n",
    "There are three numerical parameters that have an impact on the resulting reconstruction: alpha ($\\alpha$), sigma ($\\sigma$) and tau ($\\tau$). For our original PDHG reconstruction, these optimum parameters were:  \n",
    "$\\alpha$ = 0.05,  \n",
    "$\\sigma$ = 1,  \n",
    "$\\tau$ = `1/(sigma*normK**2)`.\n",
    "\n",
    "For this test, we'll adjust our parameters slightly to:  \n",
    "$\\alpha$ = 0.07,  \n",
    "$\\sigma$ = 1,  \n",
    "$\\tau$ = `1/(sigma*normK**2)`.    \n",
    "\n",
    "See if you notice any difference when you visualise the new reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup BlockOperator, K\n",
    "op1 = Gradient(ig, correlation = \"SpaceChannels\")\n",
    "op2 = A3DMC\n",
    "\n",
    "K = BlockOperator(op1, op2, shape=(2,1) ) \n",
    "\n",
    "# Define regularising parameter\n",
    "alpha = 0.07\n",
    "\n",
    "# Setup BlockFunction, F\n",
    "f1 = alpha * MixedL21Norm()\n",
    "f2 = 0.5 * L2NormSquared(b = data) \n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "# Positivity Constraint Function\n",
    "G = IndicatorBox(lower = 0)\n",
    "\n",
    "# Compute the operator norm for K\n",
    "normK = K.norm()\n",
    "\n",
    "# Define the step sizes sigma and tau\n",
    "sigma = 1\n",
    "tau = 1/(sigma*normK**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've made these changes, have a go at running the reconstruction and see what influence your changes\n",
    "had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhgSC = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma,\n",
    "             max_iteration = 100, update_objective_interval = 25)\n",
    "pdhgSC.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(pdhgSC.get_output(), title='PDHG TV Reconstruction', show_channels=20, \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly compare the two types of PDHG reconstruction using `islicer`. As we move across energy channels, see if there are any major differences between the constructions:  \n",
    " 1) PDHG TV using a Spatial correlation for 1000 iterations  \n",
    " 2) PDHG TV using a Space-Channel correlation for 100 iterations\n",
    " \n",
    "**Note:** If you also ran the earlier code for 100 iterations of PDHG TV using a Spatial correlation, feel free to add in an extra line to compare this too:  \n",
    "`i3 = islicer(pdhg_S_100.get_output().subset(vertical=40),direction='channel',title='100 Iteration Space Corr.: Channel', cmap='inferno', minmax = (0.0,0.4))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = islicer(pdhg_S_1000.subset(vertical=46),direction='channel',\n",
    "             title='1000 Iteration Space Corr.: Channel', cmap='inferno', minmax = (0.0,0.4))\n",
    "i2 = islicer(pdhgSC.get_output().subset(vertical=46),direction='channel',\n",
    "             title='100 Iteration Space-Channel Corr.: Channel',cmap='inferno', minmax = (0.0,0.4))\n",
    "#i3 = islicer(pdhg_S_100.get_output().subset(vertical=46),direction='channel',\n",
    "#             title='100 Iteration Space Corr.: Channel', cmap='inferno', minmax = (0.0,0.4))\n",
    "link_islicer(i1,i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial/Energy Profiles\n",
    "\n",
    "One way we can directly observe the effect of applying Spatial/Energy Correlation to our algorithms is through the use of pixel profiles across our reconstructed images in each domain respectively.\n",
    "\n",
    "By plotting signal values across spatial pixels, or across energy channels, the smoothing effect of this correlation feature is seen. We will demonstrate each of these below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Spatial Profiles\n",
    "\n",
    "By identifying a region of our reconstructed slices were the Iodine signals are strong, we can plot along the pixels in this region and compare the line profiles for each algorithm covered here.\n",
    "\n",
    "Given the strong signals given by the eyes of the lizard head sample, we will look across this pixel row for a single channel, given by subset values of:\n",
    " - `vertical = 46`\n",
    " - `horizontal_y = 33`\n",
    " - `channel = 20`\n",
    " \n",
    "**Feel free to adjust these values in the cell below if you wish to explore different regions of the reconstructed images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# Extract line profiles for each algorithm\n",
    "plt.plot(recon.subset(vertical = 46, horizontal_y = 33, channel = 20).as_array())\n",
    "plt.plot(cgls.get_output().subset(vertical = 46, horizontal_y = 33, channel = 20).as_array())\n",
    "plt.plot(pdhg_S_1000.subset(vertical = 46, horizontal_y = 33, channel = 20).as_array())\n",
    "plt.plot(pdhgSC.get_output().subset(vertical = 46, horizontal_y = 33, channel = 20).as_array())\n",
    "\n",
    "# Label and add key\n",
    "plt.xlabel('Pixels X', fontsize=20)\n",
    "plt.ylabel('Optical Density (no units)', fontsize=20)\n",
    "plt.legend(labels=['FDK', 'Simple CGLS', 'Space Corr. PDHG TV', 'Space-Channel Corr. PDHG TV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the reduced noise fluctuations for the Space-correlated PDHG algorithms, compared to the significant noise seen in both FDK and CGLS reconstructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Energy Profiles\n",
    "\n",
    "Once we have chosen and optimised our reconstruction routine, we can exploit this additional, energy dimension further by identifying the spectral signals that lie within.\n",
    "\n",
    "First we can plot out energy profiles for any region-of-interest in our reconstructed slices. This allows us to find, for instance, an absorption edge.\n",
    "Iodine has a known absorption 'K-edge' of 33.169 keV, so we can test the accuracy of reconstruction algorithms by seeing where this edge falls in each case. A plot of an idealised, theoretical Iodine K-edge is shown below, falling precisely at 33.169 keV.\n",
    "<img src=\"images/Iodine_K_edge.png\" width=800 height=800 align=\"center\">\n",
    "We start by extracting a 3x3 set of pixels from each of the 3D multi-channel datasets. We can choose the pixels with the highest signal by looking at our previous reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 3x3 regions of interest for each dataset\n",
    "\n",
    "# FDK Recon\n",
    "# Sum along z-direction (vertical)\n",
    "fdk_ROI1 = np.mean(fdk.get_output().as_array()[:,44:47,:,:],1)\n",
    "# Sum along y-direction (horizontal_y)\n",
    "fdk_ROI2 = np.mean(fdk_ROI1[:,31:34,:],1)\n",
    "# Sum along x-direction (horizontal_x)\n",
    "fdk_ROI3 = np.mean(fdk_ROI2[:,14:17],1)\n",
    "\n",
    "# 3D multi-channel 10 iteration CGLS\n",
    "cgls_ROI1 = np.mean(cgls.get_output().as_array()[:,44:47,:,:],1)\n",
    "cgls_ROI2 = np.mean(cgls_ROI1[:,31:34,:],1)\n",
    "cgls_ROI3 = np.mean(cgls_ROI2[:,14:17],1)\n",
    "\n",
    "# 3D multi-channel space correlated PDHG\n",
    "pdhg_S_1000_ROI1 = np.mean(pdhg_S_1000.as_array()[:,44:47,:],1)\n",
    "pdhg_S_1000_ROI2 = np.mean(pdhg_S_1000_ROI1[:,31:34],1)\n",
    "pdhg_S_1000_ROI3 = np.mean(pdhg_S_1000_ROI2[:,14:17],1)\n",
    "\n",
    "# 3D multi-channel space-channel correlated PDHG TV\n",
    "pdhgSC_ROI1 = np.mean(pdhgSC.get_output().as_array()[:,44:47,:],1)\n",
    "pdhgSC_ROI2 = np.mean(pdhgSC_ROI1[:,31:34],1)\n",
    "pdhgSC_ROI3 = np.mean(pdhgSC_ROI2[:,14:17],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channel numbers for reduced dataset (here 100 to 140)\n",
    "channel_no = np.linspace(100,140,num_channels)\n",
    "# Apply linear calibration equation to convert channels to energy\n",
    "e_keV = 0.2786*channel_no + 0.8575\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(e_keV,fdk_ROI3)\n",
    "plt.plot(e_keV,cgls_ROI3) \n",
    "plt.plot(e_keV,pdhg_S_1000_ROI3)\n",
    "plt.plot(e_keV,pdhgSC_ROI3)\n",
    "\n",
    "plt.plot((33.169,33.169),plt.ylim(0.0,0.4))\n",
    "\n",
    "plt.legend(labels=['FDK', 'Simple CGLS', 'Space Corr. 1000 Iter. PDHG', \n",
    "                   'Space-Channel Corr. 100 Iter. PDHG', 'I K-edge 33.169 keV'])\n",
    "plt.ylim(0.1,0.3)\n",
    "plt.xlim([29,39])\n",
    "\n",
    "plt.ylabel('Optical Density (no units)',fontsize=20)\n",
    "plt.xlabel('Energy (keV)',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our plots, we can see all algorithms experience a sharp rise in signal value due to the iodine absorption K-edge. Compared to the theoretical value line, each of the cases match well with the expected position of the edge.\n",
    "An important factor to note is the increased smoothness of the signal for PDHG TV, when a 'Space-Channel' correlation is applied to our gradient operator for these methods. This correlation enforces our operator to use the previous energy channel as a reference point for reconstructing data in the next, resulting in a smoother transition across channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Move to 2D Spatial Geometry with Channels\n",
    "### Defining 2D `Acquisition/Image Geometry` and `Projector`\n",
    "\n",
    "From our 4D dataset, we can reduce the dimensionality by taking a single slice along a particular spatial dimension. \n",
    "We can go from a shape of \n",
    "\n",
    "                (Channel, Vertical, Angle, Horizontal) = (40, 80, 60, 80)  \n",
    "to a shape of \n",
    "\n",
    "                        (Channel, Angle, Horizontal) = (40, 60, 80)  \n",
    "by taking a vertical slice subset.\n",
    "\n",
    "Let's start by reducing our original `AcquisitionData`. For simplicity, choose a central slice subset by setting:  \n",
    "\n",
    "`data2DMC = data.subset(vertical=40)`  \n",
    "`ag2d = data2DMC.geometry`  \n",
    "\n",
    "This will set our new `AcquisitionGeometry`.\n",
    "\n",
    "We must then alter the dimensionality of `ag2d`. Currently this is stored as `'3D'`, but as we now use only 2 spatial dimensions, we must change it to `'2D'`. So we can do:  \n",
    "  \n",
    "`ag2d.dimension = '2D'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2DMC = data.subset(vertical=40)\n",
    "ag2d = data2DMC.geometry\n",
    "ag2d.dimension = '2D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to manually adjust the `ImageGeometry` parameters we used for the [4D dataset](#4D_Acquisition_Image_Geometry). \n",
    "Below we have the parameters used for the original dataset.  \n",
    "Which parts of this geometry do we no longer need?  \n",
    "**Delete** what's not needed and then run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig2d = ImageGeometry(voxel_num_x=ig.voxel_num_x,\n",
    "                     voxel_num_y=ig.voxel_num_y,\n",
    "                     voxel_size_x=ag.pixel_size_h/mag,\n",
    "                     voxel_size_y=ag.pixel_size_h/mag,\n",
    "                     channels = ig.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can setup the tomography operator for 2D multi-channel data using the redefined `AcquisitionGeometry` and `ImageGeometry` for 2D. Let's call it `A2DMC`.\n",
    "\n",
    "Remember: Last time we used [AstraProjector3DMC](#A3DMC) as we had a 3D multi-channel dataset. Here we instead use `AstraProjectorMC()`.\n",
    "\n",
    "Note: While `AstraProjector3DMC` required the use of `gpu`, we can setup our 2D multi-channel tomography operator using either `gpu` or `cpu`. The default is the use of `gpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2DMC = AstraProjectorMC(ig2d, ag2d ,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2DMC.dimension_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Running 2D plus channel CGLS\n",
    "\n",
    "In this exercise, use what you've learned about setting up reconstruction routines, and perform a simple CGLS using our 2D multi-channel data. Then run it for 10 iterations.\n",
    "\n",
    "Remember, the key parameters you need are:\n",
    " - initialisation x_init (`A2DMC.volume_geometry.allocate()`)\n",
    " - operator (`A2DMC`)\n",
    " - data (`data2DMC`)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = A2DMC.volume_geometry.allocate()\n",
    "\n",
    "cgls2d = CGLS(x_init = x_init, operator = A2DMC,\n",
    "              data = data2DMC, max_iteration = 100)\n",
    "cgls2d.run(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the results of your reconstruction by running the function `show` below, giving you axial views for two energy channels. Or run an interactive slicer across energy channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstruction \n",
    "show(cgls2d.get_output(), title='2D Multi-Channel CGLS', show_channels=[10,20,30], \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20],minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(cgls2d.get_output(),direction='channel',title='Channel',cmap='inferno',minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Running 2D plus channel regularised CGLS\n",
    "\n",
    "Here we will expand upon what you learned about BlockFrameworks. In particular, we will cover both `BlockOperators` and `BlockDataContainers`, which were covered in **Notebook 02_Tikhonov_Block_Framework**.\n",
    "\n",
    "Below gives a brief definition of each type:\n",
    "\n",
    "`BlockDataContainer` holds datacontainers as a column vector.\n",
    "\n",
    "`BlockOperator` is a matrix of operators.\n",
    "\n",
    "### Setting up Regularised CGLS\n",
    "\n",
    "For our regularisation, we wish to solve:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\binom{\\alpha \\nabla}{A} u - \\binom{0}{g}\\end{Vmatrix}^2_2$$\n",
    "With the definitions:\n",
    "\n",
    "$\\tilde{A} = \\binom{\\alpha \\nabla}{A} \\quad\\Longleftrightarrow\\quad$ `BlockOperator(alpha*Gradient(ig2d),A2DMC)`  \n",
    "(where $\\alpha$ is the regularisation parameter)\n",
    "\n",
    "$\\tilde{g} = \\binom{0}{g} \\quad\\Longleftrightarrow\\quad$ `BlockDataContainer(op1.range_geometry().allocate(),data2DMC)`\n",
    "\n",
    "this can now be recognised as a least squares problem:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{g}\\end{Vmatrix}^2_2$$\n",
    "and being a least squares problem, it can be solved using CGLS with $\\tilde{A}$ as operator and $\\tilde{g}$ as data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `BlockOperator`, $\\tilde{A} = \\binom{\\alpha \\nabla}{A}$\n",
    "\n",
    "Using the 2D multi-channel data and geometry constructed above, build a `BlockOperator`, $\\tilde{A}$, applying a Space-Channel correlation.  \n",
    "Choose a regularisation value around $\\alpha$ = 1.5 as a starting point.\n",
    "<a id='Choosing_alpha'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the BlockOperator\n",
    "op1 = Gradient(ig2d, correlation='SpaceChannels')\n",
    "op2 = A2DMC\n",
    "alpha = 1.5\n",
    "A_block = BlockOperator(alpha*op1,op2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `BlockDataContainer`\n",
    "\n",
    "Next build a `BlockDataContainer`, $\\tilde{g}$, containing an array with the range of the regularising operator, $\\alpha \\nabla$, and our reduced `AcquisitionData` (`data2DMC`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the BlockDataContainer\n",
    "g_block = BlockDataContainer(op1.range_geometry().allocate(),data2DMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise and Run\n",
    "\n",
    "Now we can initialise the `BlockOperator` and run the algorithm for 50 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the BlockOperator\n",
    "\n",
    "x_init = A_block.domain_geometry().allocate()\n",
    "\n",
    "# Setup and run the regularised CGLS algorithm\n",
    "\n",
    "cgls_reg = CGLS(x_init = x_init, operator = A_block, data = g_block,\n",
    "                max_iteration = 100,update_objective_interval = 10)\n",
    "cgls_reg.run(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the reconstruction below. Does the value of $\\alpha$ need changing? Click [here](#Choosing_alpha) if you want to go back and vary your initial value of $\\alpha$ to see if you can improve the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstruction \n",
    "show(cgls_reg.get_output(), show_channels=[10,20,30], title='2D Multi-Channel Regularised CGLS', \n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While still noisy, we can see a significant improvement in contrast to the CGLS algorithm when no regularisation is applied.   \n",
    "Next we will try the PDHG algorithm using TV regularisation to see if this fares any better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: 2D Multi-channel Total Variation with PDHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our reduced dataset with the PDHG algorithm using Total Variation regularisation.\n",
    "\n",
    "Based on what our construction looked like for the 4D version, try to recreate this for our 2D multi-channel data. You'll need to adjust the `BlockOperator`, $K$ and `BlockFunction`, $\\mathcal{F}$, accordingly.\n",
    "\n",
    "Play around with the numeric parameters ($\\alpha$, $\\sigma$ and $\\tau$) as well, and see how they affect the reconstruction here. Is there a big change when moving from 3D multi-channel to 2D multi-channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the BlockOperator, K\n",
    "op1 = Gradient(ig2d, correlation='SpaceChannels')\n",
    "op2 = A2DMC\n",
    "K = BlockOperator(op1,op2)\n",
    "\n",
    "# Define the regularising parameter, alpha\n",
    "alpha = 0.03\n",
    "\n",
    "# Setup the BlockFunction, F\n",
    "f1 = alpha * MixedL21Norm()\n",
    "f2 = 0.5 * L2NormSquared(b=data2DMC)\n",
    "F = BlockFunction(f1,f2)\n",
    "\n",
    "# Define indicator function that provides a positivity constraint\n",
    "G = IndicatorBox(lower=0)\n",
    "\n",
    "# Compute the operator norm for K\n",
    "normK = K.norm()\n",
    "\n",
    "# Define the step sizes sigma and tau\n",
    "sigma = 1\n",
    "tau = 1/(sigma*normK**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg_2d = PDHG(f=F, g=G, operator=K, tau=tau, sigma=sigma, \n",
    "               max_iteration = 1000, update_objective_interval = 25)\n",
    "pdhg_2d.run(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstruction \n",
    "show(pdhg_2d.get_output(), show_channels=[10,20,30], title='2D Multi-Channel TV PDHG',\n",
    "     cmap='inferno', figure_size = [15,6], font_size=[25,20], minmax=(0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2D Multi-channel Methods\n",
    "\n",
    "We can bring together the 2D multi-channel reconstructions we have performed for:\n",
    " - Simple CGLS\n",
    " - Regularised CGLS\n",
    " - PDHG with TV  \n",
    " \n",
    "Using the `islicer` tool, we can directly compare these reconstructions side-by-side and evaluate the level of noise removal and spatial/energy smoothing offered by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = islicer(cgls2d.get_output(),direction='channel',title='Simple CGLS: Channel',\n",
    "             cmap='inferno',minmax=(0.0,0.4))\n",
    "i2 = islicer(cgls_reg.get_output(),direction='channel',title='Regularised CGLS: Channel',\n",
    "             cmap='inferno',minmax=(0.0,0.4))\n",
    "i3 = islicer(pdhg_2d.get_output(),direction='channel',title='PDHG TV: Channel',\n",
    "             cmap='inferno',minmax = (0.0,0.4))\n",
    "link_islicer(i1,i2,i3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy profiles\n",
    "\n",
    "Once more we can extract energy profiles, to determine the K-edge position in our 2D multi-channel datasets.\n",
    "In this case, we extract a 3x3 set of pixels by only summing along two spatial domains, y (`horizontal_y`) and x (`horizontal_x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 3x3 regions of interest for each dataset\n",
    "\n",
    "# 2d multi-channel simple CGLS\n",
    "# Sum along y-direction\n",
    "cgls2d_ROI1 = np.mean(cgls2d.get_output().as_array()[:,33:36,:],1)\n",
    "# Sum along x-direction\n",
    "cgls2d_ROI2 = np.mean(cgls2d_ROI1[:,60:63],1)\n",
    "\n",
    "# 2d multi-channel regularised CGLS\n",
    "cgls_reg_ROI1 = np.mean(cgls_reg.get_output().as_array()[:,33:36,:],1)\n",
    "cgls_reg_ROI2 = np.mean(cgls_reg_ROI1[:,60:63],1)\n",
    "\n",
    "# 2d multi-channel PDHG TV\n",
    "pdhg_2d_ROI1 = np.mean(pdhg_2d.get_output().as_array()[:,33:36,:],1)\n",
    "pdhg_2d_ROI2 = np.mean(pdhg_2d_ROI1[:,60:63],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channel numbers for reduced dataset\n",
    "channel_no = np.linspace(100,140,num_channels)\n",
    "# Apply linear calibration equation to convert channels to energy\n",
    "e_keV = 0.2786*channel_no + 0.8575\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(e_keV,cgls2d_ROI2) \n",
    "plt.plot(e_keV,cgls_reg_ROI2)\n",
    "plt.plot(e_keV,pdhg_2d_ROI2)\n",
    "\n",
    "plt.plot((33.169,33.169),plt.ylim(0.0,0.4))\n",
    "\n",
    "plt.legend(labels=['Simple CGLS', 'Regularised (Space-Channel) CGLS',\n",
    "                   '(Space-Channel) PDHG TV', 'I K-edge 33.169 keV'])\n",
    "plt.ylim(0.1,0.4)\n",
    "plt.xlim([29,39])\n",
    "\n",
    "plt.ylabel('Optical Density (no units)',fontsize=20)\n",
    "plt.xlabel('Energy (keV)',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Elemental Maps\n",
    "\n",
    "Once we know have identified the position of this edge in our energy profile, we can narrow our dataset and produce an 'Iodine map'. That is, we can select only the energy channels occupied by the absorption edge, so all reconstructed signal is now due only to the iodine contrast agent. This method is known as **'K-edge subtraction'**, which you can read about in more detail in papers such as that by [C.K.Egan *et al*, 2015](https://www.nature.com/articles/srep15979#).  \n",
    "A basic concept is shown below for an energy profile plot. The hashed area highlights the energy range we are interested in, corresponding to the absorption edge.\n",
    "\n",
    "<img src=\"images/Kedge_Sub.png\" width=600 height=600 align=\"center\">\n",
    "\n",
    "Based on our plots, we will estimate the start and end of the edge to occur at approximately 32.5 keV and 34 keV respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy channels corresponding to start and end of the K-edge\n",
    "e_keV = np.array([32.5,34])\n",
    "channel_no = ((e_keV-0.8575)/0.2786)-100\n",
    "\n",
    "# Display the channels corresponding to the start and end of the K-edge\n",
    "print(\"Start of edge = channel\",int(channel_no[0]))\n",
    "print(\"End of edge = channel\",int(channel_no[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d multi-channel simple CGLS\n",
    "# Sum over all pixels for channels of interest\n",
    "cgls2d_COI = np.mean(cgls2d.get_output().as_array()[int(channel_no[0]):int(channel_no[1]),:,:],0)\n",
    "\n",
    "# 2d multi-channel regularised CGLS\n",
    "cgls_reg_COI = np.mean(cgls_reg.get_output().as_array()[int(channel_no[0]):int(channel_no[1]),:,:],0)\n",
    "\n",
    "# 2d multi-channel PDHG TV\n",
    "pdhg_2d_COI = np.mean(pdhg_2d.get_output().as_array()[int(channel_no[0]):int(channel_no[1]),:,:],0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By stacking our iodine maps as an array, we can use `islicer` to move between each, directly comparing the quality of feature definition and degree of background noise for each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect together iodine maps\n",
    "stack_maps = (np.array([cgls2d_COI, cgls_reg_COI, pdhg_2d_COI]))\n",
    "titles = ['Simple CGLS', 'Regularised CGLS', 'Space-Channel PDHG TV']\n",
    "islicer(stack_maps, title=titles, direction=0, cmap='inferno',minmax = (0.0,0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Conclusions</center></h1>\n",
    "\n",
    "This notebook focused on bringing together the core elements of the CIL framework you have learned in the previous courses, and seeing how these may be applied to a multi-channel dataset. \n",
    "\n",
    "We looked at the key differences in building Image/Acquisition Geometries and Operators for multi-channel datasets, and how these vary for both 2D and 3D multi-channel.\n",
    "\n",
    "We have covered three key algorithms (FDK, CGLS and PDHG) and shown the differences between these for both 2D and 3D multi-channel. This also allowed us to explore some of the ways in which we can vary these reconstruction routines, and how making these adjustments can have significant effects on the quality of your reconstructions.\n",
    "\n",
    "Finally we have shown the ability to extract spectral properties from the reconstruction, providing an insight to the elemental composition of the sample of interest using energy profiles and elemental maps.\n",
    "\n",
    "**Click the link below to see the potential for full volume, white-beam reconstructions using both CGLS (Left) and PDHG TV (Right)**  \n",
    "[4D Lizard Full Volume Reconstruction](images/Lizard_gif.gif \"segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
