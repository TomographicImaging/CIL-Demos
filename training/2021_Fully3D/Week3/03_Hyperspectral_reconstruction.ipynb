{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#   This work is part of the Core Imaging Library (CIL) developed by CCPi \n",
    "#   (Collaborative Computational Project in Tomographic Imaging), with \n",
    "#   substantial contributions by UKRI-STFC and University of Manchester.\n",
    "\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "#   Copyright 2019 UKRI-STFC, The university of Manchester\n",
    "#   Authored by:    Ryan Warr (UoM)\n",
    "#                   Evangelos Papoutsellis (UKRI-STFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Hyperspectral CT Reconstruction</center></h1>\n",
    "\n",
    "<h2><center>Learning Objectives</center></h2>\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Identify the key differences in building Image/Acquisition Geometries and Operators for hyperspectral datasets \n",
    "- Build your own reconstructions using FDK, CGLS and PDHG\n",
    "- Determine optimum regularisation parameters based on reconstruction method\n",
    "- Evaluate the effectiveness of each reconstruction routine using spatial and energy profiles.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Acquisition/Image Geometry, Acquisition Data\n",
    "- ProjectionOperator\n",
    "- FDK, CGLS, PDHG, TV\n",
    "- BlockFramework\n",
    "\n",
    "### Background:\n",
    "\n",
    "Conventional X-ray detectors only measure the variable density of objects they pass through, giving no insight into what materials are actually inside. This is because standard detectors measure only the number of photons that arrive at each point on the detector.\n",
    "\n",
    "For hyperspectral imaging, one can use an energy-sensitive X-ray detector, which measures the energy of every X-ray photon that arrives at each individual pixel. This provides an additional layer of information which can provide important insight on a sample's composition or structure. However, adapted reconstruction routines are required to account for the extra energy-based dimension.\n",
    "\n",
    "The additional energy dimension is stored as a histogram of energy 'channels', indicating the number of X-ray photons detected by a pixel within a fine energy range. Typically 200+ channels are acquired, however in order to speed up computation time, we will restrict our dataset to just 40 channels, where the dominant energy signals are known to appear.   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cil.framework import AcquisitionGeometry, BlockDataContainer\n",
    "\n",
    "from cil.optimisation.algorithms import PDHG, CGLS\n",
    "from cil.optimisation.operators import BlockOperator, GradientOperator\n",
    "from cil.optimisation.functions import L2NormSquared, L1Norm, MixedL21Norm, BlockFunction, IndicatorBox\n",
    "\n",
    "from cil.io import NEXUSDataReader, NEXUSDataWriter\n",
    "\n",
    "from cil.plugins.astra.processors import FBP\n",
    "from cil.plugins.astra.operators import ProjectionOperator\n",
    "\n",
    "from cil.utilities.display import show2D, show_geometry\n",
    "from cil.utilities.jupyter import islicer, link_islicer\n",
    "\n",
    "import numpy as np                 \n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read h5 data file\n",
    "pathname = os.path.abspath(\"/mnt/materials/SIRF/Fully3D/CIL/Lizard\")\n",
    "filename = 'Lizard_Sino_100_140.h5'\n",
    "\n",
    "path = os.path.join(pathname , filename)\n",
    "arrays = {}\n",
    "\n",
    "with h5py.File(path, 'r') as f: \n",
    "    for k, v in f.items():\n",
    "        arrays[k] = np.array(v)\n",
    "    X = arrays['SS'] \n",
    "f.close()\n",
    "\n",
    "# Read Energy-Channel conversion\n",
    "tmp_energy_channels = sio.loadmat(pathname + \"/Energy_axis.mat\")\n",
    "ekeV = tmp_energy_channels['E_axis']\n",
    "ekeV_crop = ekeV[0][99:139]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample we will look at in this notebook is an iodine-stained lizard head. The use of elemental staining is common in biology and medicine, by acting as a contrast agent to provide improved visibility of internal structures for X-ray imaging. Iodine is a popular choice in the clinical and research fields, due to its energy-based properties falling in the typical range for diagnostic X-ray imaging.\n",
    "\n",
    "The sample was scanned in a lab-based X-ray CT cone-beam system at 50keV, 0.65W, using an energy-sensitive detector to acquire a full 4D dataset. The detector consisted of an 80 x 80 pixel array, with pixel sizes of 250 $\\mu$m x 250 $\\mu$m. A source-sample distance of 332.0 mm and a sample-detector distance of 270.0 mm gave a geometric magnification of 1.8x, and a reconstructed voxel size of 137$\\mu$m. The sample was scanned for 60 projections over a full 360$^{\\circ}$ rotation, with 120s exposure time per projection.\n",
    "\n",
    "A diagram of the style of setup used for spectral imaging is shown below from a paper by [C.K.Egan *et al*, 2015](https://www.nature.com/articles/srep15979#):\n",
    "\n",
    "<img src=\"Images/Spectral_Imaging_Geometry.jpg\" width=800 height=800 align=\"center\">   \n",
    "\n",
    "\n",
    "As shown by the diagram, each pixel stores its own energy channel histogram, with characteristic signals such as 'Absorption edges' (caused by photoelectric absorption of X-ray photons by the iodine in our sample) producing sharp rises in signal. These are the key features we look for when analysing spectral data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Setting up Acquisition/Image Geometry</center></h1>\n",
    "\n",
    "First we need to setup the geometries based on the acquisition system.\n",
    "These are currently ordered based on the 4D raw dataset.\n",
    "\n",
    "Run the code to see the current dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can allocate these separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = X.shape[0]\n",
    "vertical = X.shape[1]\n",
    "num_angles = X.shape[2]\n",
    "horizontal = X.shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the angles used based on the parameters chosen for data acquisition. An offset is also applied (this just gives us the freedom to adjust the rotation of our reconstructed images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.linspace(-180-160,180-160,num_angles,endpoint=False)*np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4D Acquisition and Image Geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode all this information into `AcquisitionGeometry` and `ImageGeometry`. We first define the scan geometry parameters, including source-sample-detector distances. These are then used to define our `AcquisitionGeometry`. See **Week1/00_CIL_geometry.ipynb** for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system scan geometry and detector parameters\n",
    "distance_source_center = 332.0  # [mm]\n",
    "distance_center_detector = 270.0  # [mm]\n",
    "detector_pixel_size = 0.250  # [mm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define acquisition geometry from the detector system acquisition settings\n",
    "# with reordering of the dimension labels to match the raw data\n",
    "ag = AcquisitionGeometry.create_Cone3D(source_position = [0,-distance_source_center,0],\n",
    "                                       detector_position = [0,distance_center_detector,0])\\\n",
    "                                     .set_panel([horizontal,vertical],[detector_pixel_size,detector_pixel_size])\\\n",
    "                                     .set_channels(num_channels)\\\n",
    "                                     .set_angles(-angles,angle_unit=\"radian\")\\\n",
    "                                     .set_labels(['channel', 'vertical', 'angle', 'horizontal'])\n",
    "\n",
    "# Create the 4D acquisition data\n",
    "data = ag.allocate()\n",
    "data.fill(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show acquisition geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_geometry(ag, view_distance = 4.5, elevation=10, azimuthal=-65, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `ImageGeometry` directly from the `AcquisitionGeometry` using `ig = ag.get_ImageGeometry()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = ag.get_ImageGeometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an interactive image slicer `islicer` to provide a visualisation of the `AcquisitionData` in any dimension below. Simply by taking a data slice in a particular dimension, we can then visualise the data in any other given dimension.\n",
    "\n",
    "Run the code below to see three such examples:\n",
    "\n",
    "1) Projection radiographs for each of the 60 rotation angles acquired in a single channel\n",
    "\n",
    "2) The sinogram for each energy channel for the central slice\n",
    "\n",
    "3) The spectral signals acquired in each energy channel for a single projection angle  \n",
    "\n",
    "\n",
    "**Note: You can adjust the look of your reconstructions by varying certain parameters**  \n",
    " - by removing `cmap`, you return to the default colour map of 'gray'\n",
    " - the default scaling runs through the full data range, set initial limits using e.g. `minmax = (0.0 , 2.0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "islicer(data.get_slice(channel=20), direction='angle', title = 'Projection Angle', cmap='inferno',minmax=(0.0,2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "islicer(data.get_slice(vertical=40), direction='channel', title = 'Sinogram Channel', cmap='inferno',minmax=(0.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "islicer(data.get_slice(angle=42), direction='channel', title = 'Channel', cmap='inferno',minmax=(0.0,2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the tomography operator for 3D hyperspectral data using the `AcquisitionGeometry` and `ImageGeometry`\n",
    "<a id='A3DMC' ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag3D = ag.get_slice(channel=0)\n",
    "ig3D = ag3D.get_ImageGeometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDK Reconstruction\n",
    "\n",
    "One of the simplest, and most common, means of image reconstruction for X-ray CT is the use of Filtered BackProjection (FBP). In the case of many lab-based X-ray sources, which utilise a cone-beam rather than parallel- or fan-beams, we use a specific case of FBP: The [Feldkamp-Davis-Kress (FDK)](https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-1-6-612) algorithm.\n",
    "\n",
    "The function `FBP` is capable of handling reconstructions for both parallel-beam and cone-beam geometries in 2D and 3D. To apply this to 4D data, we loop over all channels in our dataset, performing a 3D FDK reconstruction for each channel, and fill this into a 4D (3D + Channels) image data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allocate space for the FBP_4D recon\n",
    "FBP_recon_4D = ig.allocate()\n",
    "\n",
    "# FBP reconstruction per channel\n",
    "for i in range(ig.channels):\n",
    "    \n",
    "    FBP_recon_3D = FBP(ig3D, ag3D, 'gpu')(data.get_slice(channel=i))\n",
    "    FBP_recon_4D.fill(FBP_recon_3D, channel=i)\n",
    "    \n",
    "    print(\"Finish FBP recon for channel {}\".format(i), end='\\r')\n",
    "    \n",
    "print(\"\\nFDK Reconstruction Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `show2D` function to observe a 2D reconstructed slice of our 4D volume. Using the `slice_list` argument, we can set specific values for each dimension to choose what reconstructed slice we wish to see. Here we look at a single slice (35) in the vertical ('axial') plane, shown for a single energy channel (20). As expected, the data is quite noisy, with poor feature definition in the majority of the soft tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D(FBP_recon_4D,\n",
    "       slice_list=[[(\"channel\",20),(\"vertical\",35)]], \n",
    "       cmap=\"inferno\", origin=\"upper\", \n",
    "       fix_range=(0,0.5), size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some features of the lizard head can be seen in the reconstructed images, much of the signal is shrouded by noise.  \n",
    "In the next section, we will explore the first iterative algorithm - CGLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the CGLS algorithm on a 4D dataset\n",
    "\n",
    "As the next step, we will begin with a standard CGLS algorithm, applied to our 4D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very simple to set up, we simply require a `ProjectionOperator`, A, which we can create using our `AcquisitionGeometry` and `ImageGeometry`. For a 4D dataset, we require the use of `gpu`.\n",
    "\n",
    "After initialising the reconstruction with `x0 = ig.allocate()`, we can set up our CGLS algorithm.\n",
    "\n",
    "Let's test the CGLS algorithm for just 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Projection Operator\n",
    "A = ProjectionOperator(ig, ag, 'gpu')\n",
    "\n",
    "# Initialise \n",
    "x0 = ig.allocate()\n",
    "cgls = CGLS(initial = x0, operator = A, data = data,\n",
    "               max_iteration = 10, update_objective_interval = 2)\n",
    "cgls.run(10,verbose=1)\n",
    "cgls_10 = cgls.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the quality of our reconstruction, by looking at different spatial planes, as well as varying the single energy channel we observe. We access these by selecting values from our reconstruction with `cgls_10.as_array()[channel_num,slice_z,slice_y,slice_x]`.\n",
    "\n",
    "Run the code below to see reconstructions for the 10th, 20th and 30th channel in our truncated dataset, with the X-ray energies these correspond to, for three different spatial planes (Axial, Coronal, Sagittal). As you will see, the attenuation level rises sharply between the 10th and 20th energy channel, indicative of a spectral marker (absorption edge) being crossed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show CGLS reconstruction with 10 iterations at different energy channels and views: Axial, Coronal, Sagittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = [cgls_10.get_slice(channel=10, vertical=35), cgls_10.get_slice(channel=10, horizontal_y=35), cgls_10.get_slice(channel=10, horizontal_x=25),\\\n",
    "          cgls_10.get_slice(channel=20, vertical=35), cgls_10.get_slice(channel=20, horizontal_y=35), cgls_10.get_slice(channel=20, horizontal_x=25),\\\n",
    "          cgls_10.get_slice(channel=30, vertical=35), cgls_10.get_slice(channel=30, horizontal_y=35), cgls_10.get_slice(channel=0, horizontal_x=25)]\n",
    "    \n",
    "\n",
    "labels_x = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "labels_y = [\"{:.2f} keV \".format(ekeV_crop[10]),\n",
    "            \"{:.2f} keV \".format(ekeV_crop[20]),\n",
    "            \"{:.2f} keV \".format(ekeV_crop[30])]\n",
    "\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(12, 14))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(3, 3),\n",
    "                axes_pad=0.05,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='right',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.1\n",
    "                )\n",
    "k = 0\n",
    "\n",
    "for ax in grid:\n",
    "    im = ax.imshow(recons[k].as_array(), cmap=\"inferno\", vmin = 0.0, vmax = 0.5)   \n",
    "    \n",
    "    if k==0:\n",
    "        ax.set_title(labels_x[0],fontsize=20)\n",
    "        ax.set_ylabel(labels_y[0],fontsize=20)\n",
    "    if k==1:\n",
    "        ax.set_title(labels_x[1],fontsize=20)  \n",
    "    if k==2:\n",
    "        ax.set_title(labels_x[2],fontsize=20)  \n",
    "    if k==3:\n",
    "         ax.set_ylabel(labels_y[1],fontsize=20)  \n",
    "    if k==6:\n",
    "         ax.set_ylabel(labels_y[2],fontsize=20) \n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    k+=1\n",
    "\n",
    "plt.colorbar(im, cax=grid.cbar_axes[0]).set_label(label='Optical Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now run the reconstruction for 30 iterations, and compare the two results in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgls = CGLS(initial = x0, operator = A, data = data,\n",
    "               max_iteration = 30, update_objective_interval = 10)\n",
    "cgls.run(verbose=1)\n",
    "cgls_30 = cgls.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show CGLS reconstruction 10 iterations vs 30 iterations at the 20th energy channel and views: Axial, Coronal, Sagittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = [cgls_10.get_slice(channel=20, vertical=35), cgls_10.get_slice(channel=20, horizontal_y=35), cgls_10.get_slice(channel=20, horizontal_x=25),\\\n",
    "          cgls_30.get_slice(channel=20, vertical=35), cgls_30.get_slice(channel=20, horizontal_y=35), cgls_30.get_slice(channel=20, horizontal_x=25)]  \n",
    "\n",
    "labels_x = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "labels_y = [\"10 Iter.\",\"30 Iter.\"]\n",
    "\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(12, 14))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 3),\n",
    "                axes_pad=0.05,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='right',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.1\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax in grid:\n",
    "    im = ax.imshow(recons[k].as_array(), cmap=\"inferno\", vmin = 0.0, vmax = 0.5)   \n",
    "    \n",
    "    if k==0:\n",
    "        ax.set_title(labels_x[0],fontsize=20)\n",
    "        ax.set_ylabel(labels_y[0],fontsize=20)\n",
    "    if k==1:\n",
    "        ax.set_title(labels_x[1],fontsize=20)  \n",
    "    if k==2:\n",
    "        ax.set_title(labels_x[2],fontsize=20)  \n",
    "    if k==3:\n",
    "        ax.set_ylabel(labels_y[1],fontsize=20)  \n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    k+=1\n",
    "\n",
    "plt.colorbar(im, cax=grid.cbar_axes[0]).set_label(label='Optical Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images highlight the instability of a basic CGLS algorithm, where the **number of iterations** effectively acts as the algorithm's **regularisation parameter**. As a result, too many iterations leads to a divergence from an optimum solution, with only additional noise being contributed beyond a certain point. \n",
    "\n",
    "Next we will look at an extension of the CGLS algorithm, where we now apply a specific regularisation factor. Here, we will use **Tikhonov** regularisation, and show how it can be applied to improve reconstruction quality in both the spatial and spectral dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tikhonov Regularisation for CGLS\n",
    "\n",
    "Here we will expand upon what you learned about BlockFrameworks. In particular, we will cover both `BlockOperators` and `BlockDataContainers`, which were covered in **Week2/02_tikhonov_block_framework**.\n",
    "\n",
    "Below gives a brief definition of each type:\n",
    "\n",
    "`BlockDataContainer` holds datacontainers as a column vector.\n",
    "\n",
    "`BlockOperator` is a matrix of operators.\n",
    "\n",
    "### Setting up \"Regularised CGLS\"\n",
    "\n",
    "For our regularisation, we wish to solve:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\binom{\\alpha \\nabla}{A} u - \\binom{0}{g}\\end{Vmatrix}^2_2$$\n",
    "With the definitions:\n",
    "\n",
    "$\\tilde{A} = \\binom{\\alpha \\nabla}{A} \\quad\\Longleftrightarrow\\quad$ `BlockOperator(alpha*Grad(ig),A)`  \n",
    "(where $\\alpha$ is the regularisation parameter)\n",
    "\n",
    "$\\tilde{g} = \\binom{0}{g} \\quad\\Longleftrightarrow\\quad$ `BlockDataContainer(Grad.domain.allocate(0),data)`\n",
    "\n",
    "this can now be recognised as a least squares problem:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{g}\\end{Vmatrix}^2_2$$\n",
    "and being a least squares problem, it can be solved using CGLS with $\\tilde{A}$ as operator and $\\tilde{g}$ as data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `BlockOperator`, $\\tilde{A} = \\binom{\\alpha \\nabla}{A}$\n",
    "\n",
    "Using the 2D hyperspectral data and geometry constructed above, build a `BlockOperator`, $\\tilde{A}$, applying a \"Space-Channel\" correlation. This means that our regularisation will be applied across both the spatial and spectral domains.  \n",
    "Choose a regularisation value around $\\alpha$ = 0.1 as a starting point.\n",
    "<a id='Choosing_alpha'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up operators for BlockOperator\n",
    "Grad = GradientOperator(ig, correlation='SpaceChannels')\n",
    "\n",
    "alpha = 0.1\n",
    "A_block = BlockOperator(alpha*Grad,A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `BlockDataContainer`, $\\tilde{g} = \\binom{0}{g}$\n",
    "\n",
    "Next build a `BlockDataContainer`, $\\tilde{g}$, containing an array with the range of the regularising operator, $\\alpha \\nabla$, and our `AcquisitionData` (`data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BlockDataContainer\n",
    "g_block = BlockDataContainer(Grad.domain.allocate(0),data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise and Run\n",
    "\n",
    "Now we can initialise the `BlockOperator` and run the algorithm for 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the BlockOperator\n",
    "x0 = ig.allocate(0)\n",
    "\n",
    "# Setup and run the regularised CGLS algorithm\n",
    "\n",
    "cgls_reg = CGLS(x_init = x0, operator = A_block, data = g_block,\n",
    "                max_iteration = 100, update_objective_interval = 2)\n",
    "cgls_reg.run(10, verbose=1)\n",
    "cgls_reg_10 = cgls_reg.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `show2D` in the cell below to compare 10 iterations of the basic CGLS algorithm, with the 10 iteration result of CGLS with Tikhonov regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([cgls_10,cgls_reg_10],\n",
    "       slice_list=[[(\"channel\",20),(\"vertical\",35)]]*2, \n",
    "       cmap=\"inferno\", origin=\"upper\",title=[\"CGLS 10 iterations\", \"Tikhonov 10 iterations\"],\n",
    "       fix_range=(0,0.5), size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the main effect of the **Tikhonov** regularisation is to smooth the fetaures, such that the noise in the image is suppressed. However this is still not perfect for restoring strong feature definition.\n",
    "\n",
    "In the next section, we will look at a different algorithm: Primal-Dual Hybrid Gradient (PDHG), combined with a Total Variation (TV) regularising factor, to see if this improves our reconstructed data quality any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Variation Regularisation in 4D Volume using PDHG\n",
    "\n",
    "The PDHG algorithm and Total Variation regularisation were covered extensively in **Week2/03_PDHG** notebook, but below gives a brief recap of the basics behind each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on PDHG\n",
    "\n",
    "PDHG aims to solve problems of the form:\n",
    "\n",
    "$$ \\begin{equation} \\min_{u} \\mathcal{F}(K u) + \\mathcal{G}(u) \\label{min_problem} \\end{equation} $$\n",
    "\n",
    "In order to setup and run PDHG, we need to define the following:\n",
    "\n",
    " - The operator $K$.\n",
    " - The function $\\mathcal{F}$ and $\\mathcal{G}$.\n",
    " - Step-sizes $\\sigma$ and $\\tau$ such that $\\sigma\\tau\\|K\\|^{2}<1$.\n",
    " \n",
    "Then we can setup PDHG:\n",
    "\n",
    "`pdhg = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma, max_iteration = maxiter)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Total Variation Regularisation\n",
    "\n",
    "<a id='TV_setup'></a>\n",
    "\n",
    "For this notebook, we will be applying Total Variation (TV) regularisation to our PDHG algorithm. TV is a non-smooth regulariser, \n",
    "\n",
    "$$ \\underset{u}{\\operatorname{argmin}} \\alpha\\,\\mathrm{TV}(u) + \\frac{1}{2} \\| \\mathcal{A} u - g\\|^{2}_{2} + \\mathbb{I}_{\\{u>0\\}}(u) $$\n",
    "\n",
    "where,\n",
    "\n",
    "- The Total Variation is taken as a `MixedL21Norm()`, such that $$\\mathrm{TV}(u) = \\|\\nabla u \\|_{2,1} = \\sum \\sqrt{ (\\partial_{y}u)^{2} + (\\partial_{x}u)^{2} }$$  \n",
    "- $g$ is the Acquisition data obtained from the detector  \n",
    "- $\\mathcal{A}$ is the projection operator ( Radon transform ) that maps from an image-space to an acquisition space, i.e.,  \n",
    "$\\mathcal{A} : X \\rightarrow Y$.  \n",
    "- $\\alpha$ is the regularising parameter that measures a trade-off between the fidelity and the regulariser terms  \n",
    "- $\\mathbb{I}_{\\{u>0\\}}(u) : = \n",
    "\\begin{cases}\n",
    "0,\\quad u>0\\\\\n",
    "\\infty,\\quad \\mbox{otherwise}\n",
    "\\quad\n",
    "\\end{cases},\\quad\n",
    "$ is a positivity constraint for the minimiser $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up PDHG for TV\n",
    "\n",
    "We define K as a `BlockOperator`, containing the Gradient and Projection operator:\n",
    "\n",
    "$$ K = \n",
    "\\begin{bmatrix}\n",
    "\\nabla\\\\\n",
    "A\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "K = `BlockOperator(Grad, A)`\n",
    "\n",
    "The function $\\mathcal{F}$, is a `BlockFunction` with\n",
    "\n",
    "a function $\\alpha\\|\\cdot\\|_{2,1}\\quad\\Longleftrightarrow\\quad$ `MixedL21Norm()` term that represents the Total variation regularisation ,\n",
    "\n",
    "a function $\\|\\cdot -g \\|_{2}^{2}\\quad\\Longleftrightarrow\\quad$ `L2NormSquared(data)` term that represents the data fitting.\n",
    "\n",
    "Hence, $\\mathcal{F} = [f_{1}, f_{2}] \\quad\\Longleftrightarrow\\quad $ `F = BlockFunction(MixedL21Norm(), L2NormSquared(data))`\n",
    "\n",
    "Finally, we have the function $\\mathcal{G} = \\mathbb{I}_{\\{u>0\\}}(u) \\quad\\Longleftrightarrow\\quad$ `G = IndicatorBox(lower=0)`\n",
    "\n",
    "Again, we can verify that with the above setting we can express our problem into this form, for $x=u$\n",
    "\n",
    "$$ \\begin{align} \\underset{u}{\\operatorname{argmin}}\\alpha\\|\\nabla u\\|_{2,1} + \\frac{1}{2}\\|\\mathcal{A} u - g\\|^{2}_{2} + \\mathbb{I}_{\\{u>0\\}}(u) \\\\= \\underset{u}{\\operatorname{argmin}} f_{1}(\\nabla u) + f_{2}(\\mathcal{A}u) + \\mathbb{I}_{\\{u>0\\}}(u) \\\\ = \\underset{u}{\\operatorname{argmin}} \\mathcal{F}( \\begin{bmatrix} \\nabla \\\\ \\mathcal{A} \\end{bmatrix}u) + \\mathbb{I}_{\\{u>0\\}}(u)\\\\ = \\underset{u}{\\operatorname{argmin}} \\mathcal{F}(Ku) + \\mathcal{G}(u)\\\\ = \\underset{x}{\\operatorname{argmin}} \\mathcal{F}(Kx) + \\mathcal{G}(x) \\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by building our `BlockOperator`, K. This requires a `GradientOperator`, which to start with we will create with only a _Space_ correlation, therefore only applying across the spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The operator K is a Block Operator that contains the gradient and the tomography operator (as created previously)\n",
    "Grad = GradientOperator(ig, correlation=\"Space\")\n",
    "\n",
    "# Set up a BlockOperator K\n",
    "K = BlockOperator(Grad,A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{F}$ is a `BlockFunction` of a fidelity term and our TV regularising term:\n",
    "\n",
    "- $f_{1}$ = $\\alpha\\|\\cdot\\|_{2,1}\\quad\\Longleftrightarrow\\quad$ `MixedL21Norm()` term that represents the Total variation regularisation ,\n",
    "\n",
    "- $f_{2}$ = $\\|\\cdot -g \\|_{2}^{2}\\quad\\Longleftrightarrow\\quad$ `L2NormSquared(data)` term that represents the data fitting.\n",
    "\n",
    "Therefore as $f_{1}$ and $f_{2}$ act on each element of $K$, we end up with  \n",
    "$$ \\mathcal{F}(Ku) = \\mathcal{F}(\n",
    "\\begin{bmatrix}\n",
    "\\nabla u \\\\\n",
    "A u\n",
    "\\end{bmatrix}) = ( f_{1}(\\nabla u), f_{2}(Au) ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regularising parameter, $\\alpha$ adjusts the wighting of the TV regularisation. THe greater impact you want the regularisation to have on your data, the larger you make $\\alpha$. Typically, the optimum value will vary for each dataset, and some trial and error may be required to find the best result.  \n",
    "Let us start here by using $\\alpha$ = 0.004, and then build our `BlockFunction` as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the weighting of the regularising parameter, alpha\n",
    "alpha = 0.004\n",
    "\n",
    "# List of BlockFunctions\n",
    "f1 = alpha * MixedL21Norm()  \n",
    "f2 = 0.5 * L2NormSquared(b = data) \n",
    "\n",
    "F = BlockFunction(f1, f2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have our positivity constraint function $\\mathcal{G} = \\mathbb{I}_{\\{u>0\\}}(u) \\quad\\Longleftrightarrow\\quad$ `G = IndicatorBox(lower=0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = IndicatorBox(lower = 0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the operator norm of $K$ (`normK = K.norm()`), and set our step sizes, $\\sigma$ and $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the operator norm for K\n",
    "normK = K.norm()\n",
    "\n",
    "# Define the step sizes sigma and tau\n",
    "sigma = 1./normK\n",
    "tau = 1./normK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can setup and run the PDHG algorithm. Here it will run for 100 iterations.\n",
    "\n",
    "Due to the increased complexity of the algorithm, combined with the reconstruction of a 4D dataset, the runtime for 100 iterations alone will be around **3 minutes**. However, we may require many more than 100 iterations to reach an optimum solution. Further, we may wish to reconstruct hundreds of energy channels, rather than just the 40 we use here.\n",
    "\n",
    "Therefore, consideration must be taken on the number of iterations you perform based on your choice of algorithm and size of your dataset.\n",
    "\n",
    "In the following cells, we have also provided a final reconstruction after 1000 iterations of PDHG TV, which required around 30 minutes of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PDHG_TV = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma,\n",
    "            max_iteration = 100, update_objective_interval = 25)\n",
    "PDHG_TV.run(verbose=1)\n",
    "PDHG_TV_100_Sp = PDHG_TV.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we directly compare the reconstructions of FDK with PDHG TV. As you will see, even at 100 iterations, we get a reasonable reconstructed volume, with already much improved noise suppression compared to the FDK result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show FBP reconstruction vs PDHG TV reconstruction with no regularisation on channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = [FBP_recon_4D.get_slice(channel=20, vertical=35), PDHG_TV_100_Sp.get_slice(channel=20, horizontal_y=35),\\\n",
    "          FBP_recon_4D.get_slice(channel=20, horizontal_x=35), PDHG_TV_100_Sp.get_slice(channel=20, horizontal_x=35)]\n",
    "\n",
    "labels_text = [\"FDK\", \"PDHG TV - 100 Iter.\"]\n",
    "\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(12, 14))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 2),\n",
    "                axes_pad=0.05,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='right',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.1\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax in grid:\n",
    "    im = ax.imshow(recons[k].as_array(), cmap=\"inferno\", vmin = 0.0, vmax = 0.5)   \n",
    "    \n",
    "    if k==0:\n",
    "        ax.set_title(labels_text[0],fontsize=20)\n",
    "    if k==1:\n",
    "        ax.set_title(labels_text[1],fontsize=20)  \n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    k+=1\n",
    "\n",
    "plt.colorbar(im, cax=grid.cbar_axes[0]).set_label(label='Optical Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PDHG TV: 1000 Iterations\n",
    "\n",
    "You may notice that, for 100 iterations, the PDHG TV result looks slightly __blocky__ in places, despite significant noise suppression. This may be because 100 iterations is insufficient for convergence, therefore we include below a reconstructed dataset after 1000 iterations, stored as a Nexus (`.nxs`) file.\n",
    "\n",
    "We load in the 1000 iteration result using the `NEXUSDataReader()`. We can now directly compare this result to all our previous reconstructions, including our Tikhonov CGLS result, and the PDHG TV result for 100 iterations.\n",
    "\n",
    "As you can see, 1000 iterations was sufficient for convergence of the PDHG TV reconstruction. We now see smoothing across all spatial features, reducing all noise such that boundaries of soft tissue features are more clealy defined. In particular, the noisy __haze__ around the main soft tissue is considerably suppressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = NEXUSDataReader(file_name = \"/mnt/materials/SIRF/Fully3D/CIL/Lizard/PDHG_TV_1000_Sp_alpha_0.004.nxs\")\n",
    "PDHG_TV_1000_Sp = reader.read()\n",
    "\n",
    "recons = [FBP_recon_4D.get_slice(channel=20, vertical=35), cgls_reg_10.get_slice(channel=20, vertical=35),\\\n",
    "          PDHG_TV_100_Sp.get_slice(channel=20, vertical=35), PDHG_TV_1000_Sp.get_slice(channel=20, vertical=35),\\\n",
    "          FBP_recon_4D.get_slice(channel=20, horizontal_x=25), cgls_reg_10.get_slice(channel=20, horizontal_x=25),\\\n",
    "          PDHG_TV_100_Sp.get_slice(channel=20, horizontal_x=25), PDHG_TV_1000_Sp.get_slice(channel=20, horizontal_x=25)]\n",
    "\n",
    "labels_text = [\"FDK\",\"CGLS Tik.- 10 Iter.\",\"PDHG TV - 100 Iter.\", \"PDHG TV - 1000 Iter.\"]\n",
    "\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 4),\n",
    "                axes_pad=0.05,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='right',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.1\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax in grid:\n",
    "    im = ax.imshow(recons[k].as_array(), cmap=\"inferno\", vmin = 0.0, vmax = 0.5)   \n",
    "    \n",
    "    if k==0:\n",
    "        ax.set_title(labels_text[0],fontsize=20)\n",
    "    if k==1:\n",
    "        ax.set_title(labels_text[1],fontsize=20)  \n",
    "    if k==2:\n",
    "        ax.set_title(labels_text[2],fontsize=20)      \n",
    "    if k==3:\n",
    "        ax.set_title(labels_text[3],fontsize=20) \n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    k+=1\n",
    "\n",
    "plt.colorbar(im, cax=grid.cbar_axes[0]).set_label(label='Optical Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Set up PDHG with Space-Channel TV Regularisation\n",
    "\n",
    "We can make some adjustments to our framework to see how these affect the reconstruction.\n",
    "Our gradient component is capable of smoothing our reconstruction both in the spatial domain, but also in the energy domain, by using neighbouring channels to aid the iterative reconstruction process. We will now test this by setting up PDHG with a Space-Channel TV regularisation.\n",
    "\n",
    "**Step 1)** Adjust the `GradientOperator` to correlate in both the spatial and spectral domains. Then build your `BlockOperator` K using the `ProjectionOperator` we created earlier for our CGLS reconstruction.\n",
    "\n",
    "Hint: For TV regularisation, we have the ability to split our regularisation, such that we can adjust the weighting of TV for the spatial and spectral dimensions separately. If you want to do this, add a third argument to your `GradientOperator` called `split=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust correlation of gradient component\n",
    "Grad = GradientOperator(ig, correlation = \"SpaceChannels\", split=True)\n",
    "\n",
    "# Construct new BlockOperator\n",
    "K = BlockOperator(Grad, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2)** Set the regularisation parameters.\n",
    "\n",
    "If you decided to split your TV regularisation, then now instead of **one** parameter, we now need to create **two**, $\\alpha$ and $\\beta$, which will act on the spatial and spectral domains respectively.\n",
    "\n",
    "For our original PDHG reconstruction, our $\\alpha$ parameter was:  \n",
    "$\\alpha$ = 0.004.\n",
    "\n",
    "Now that we have two parameters, $\\alpha$ across the spatial domain and $\\beta$ across the energy domain, you can try different combinations, for example:  \n",
    "$\\alpha$ = 0.003,  \n",
    "$\\beta$ = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regularising parameter alpha\n",
    "alpha = 0.003\n",
    "beta = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3)** Build the `BlockFunction`\n",
    "\n",
    "Previously our `BlockFunction` contained two terms: the TV regularisation, and the data fitting. As our TV term is now split, we must build this term as a `BlockFunction` first, combining the spatial and spectral regularisation elements, before combining this with our data fitting term.\n",
    "\n",
    "Our first term will now look like the following:\n",
    "\n",
    "$$ \\mathcal{f_{1}} = \\begin{bmatrix}\n",
    "\\beta\\|\\cdot\\|_{1} \\\\\n",
    "\\alpha\\|\\cdot\\|_{2,1}\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "So we use the `L1Norm()` for our $\\beta$ parameter, and the `MixedL21Norm()` for our $\\alpha$ parameter. \n",
    "\n",
    "Then we can simply combine this new term with the `L2NormSquared` term we used previously for our data fitting, and build our final `BlockFunction`, F.\n",
    "\n",
    "Have a go at building this, referring back to our past constructions of `BlockFunctions` if you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fidelity terms f1,f2\n",
    "f1 = BlockFunction(beta*L1Norm(), alpha * MixedL21Norm())\n",
    "f2 = 0.5 * L2NormSquared(b = data)\n",
    "\n",
    "# Construct BlockFunction\n",
    "F = BlockFunction(f1,f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4)** Apply a positivity constraint function, G\n",
    "\n",
    "This will be identical to before, enabling us to restrict our reconstruction to non-negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positivity Constraint Function\n",
    "G = IndicatorBox(lower = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5)** Compute our operator norm, K, and define the step sizes, $\\sigma$ and $\\tau$.\n",
    "\n",
    "These will again be the same as we have used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the operator norm for K\n",
    "normK = K.norm()\n",
    "\n",
    "# Define the step sizes sigma and tau\n",
    "sigma = 1./normK\n",
    "tau = 1./normK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6)** Run the reconstruction for 100 iterations.\n",
    "\n",
    "We have provided below the skeleton of the `PDHG` algorithm, you just need to finish adding in the correct arguments, and then run the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDHG_TV_SpCh = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma,\n",
    "            max_iteration = 100, update_objective_interval = 25)\n",
    "PDHG_TV_SpCh.run(verbose=1)\n",
    "PDHG_TV_100_SpCh = PDHG_TV_SpCh.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `show2D` function below to see how your reconstruction looks in each view. Feel free to adjust the channel or slice numbers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2D(PDHG_TV_100_SpCh,\n",
    "       slice_list=[[(\"channel\",20),(\"vertical\",35)],\n",
    "                   [(\"channel\",20),(\"horizontal_y\",35)],\n",
    "                   [(\"channel\",20),(\"horizontal_x\",25)]],\n",
    "                   cmap=\"inferno\", num_cols=3, \n",
    "                   origin=\"upper\", fix_range=(0,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly compare the two types of PDHG reconstruction using `islicer`. Once more, we have provided a 1000 iteration reconstruction of the Space-Channel regularised result as a Nexus file. As you move across energy channels, see if there are any major differences between the constructions.  \n",
    " 1) PDHG TV using a Spatial correlation for 1000 iterations  \n",
    " 2) PDHG TV using a Space-Channel correlation for 1000 iterations\n",
    " \n",
    "**Note:** If you wish, you can also compare the 100 iteration results for each method, simply by adding extra lines in the cell below, such as:  \n",
    "`islicer(PDHG_TV_100_SpCh.get_slice(vertical=35), direction='channel', title = 'Sinogram Channel', cmap='inferno',minmax=(0.0,0.5))`\n",
    "\n",
    "Look for any differences between the reconstructions as you move across energy channels. For example, do you notice the smoother transition from one channel to the next in our **Space-Channel** reconstructed dataset? This is because the additional spectral regularisation, with its own weighted parameter, helped to reduce noise fluctuations from channel to channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = NEXUSDataReader(file_name = \"/mnt/materials/SIRF/Fully3D/CIL/Lizard/PDHG_TV_1000_Sp_alpha_0.004.nxs\")\n",
    "PDHG_TV_1000_Sp = reader.read()\n",
    "\n",
    "reader = NEXUSDataReader(file_name = \"/mnt/materials/SIRF/Fully3D/CIL/Lizard/PDHG_TV_1000_SpCh_alpha_0.003_beta_0.5.nxs\")\n",
    "PDHG_TV_1000_SpCh = reader.read()\n",
    "\n",
    "islicer(PDHG_TV_1000_Sp.get_slice(vertical=35), direction='channel', title = 'Channel', cmap='inferno',minmax=(0.0,0.5), origin=\"upper\")\n",
    "islicer(PDHG_TV_1000_SpCh.get_slice(vertical=35), direction='channel', title = 'Channel', cmap='inferno',minmax=(0.0,0.5),origin=\"upper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of 4D reconstruction algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we can compare all reconstruction algorithms we have tried so far:\n",
    "1) FDK  \n",
    "2) Basic CGLS  \n",
    "3) CGLS with Tikhonov Regularisation ($\\alpha$ = 0.1)  \n",
    "4) PDHG with Space-Channel Total Variation Regularisation ($\\alpha$ = 0.003, $\\beta$ = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = [FBP_recon_4D.get_slice(channel=20, vertical=35), cgls_reg_10.get_slice(channel=20, vertical=35),\\\n",
    "          cgls_reg_10.get_slice(channel=20, vertical=35), PDHG_TV_1000_SpCh.get_slice(channel=20, vertical=35),\\\n",
    "          FBP_recon_4D.get_slice(channel=20, horizontal_x=25), cgls_reg_10.get_slice(channel=20, horizontal_x=25),\\\n",
    "          cgls_reg_10.get_slice(channel=20, horizontal_x=25), PDHG_TV_1000_SpCh.get_slice(channel=20, horizontal_x=25)]\n",
    "\n",
    "labels_text = [\"FDK\",\"CGLS - 10 Iter.\",\"Tikhonov CGLS - 10 Iter.\", \"SpCh. PDHG TV - 1000 Iter.\"]\n",
    "\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 4),\n",
    "                axes_pad=0.05,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='right',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.1\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax in grid:\n",
    "    im = ax.imshow(recons[k].as_array(), cmap=\"inferno\", vmin = 0.0, vmax = 0.5)   \n",
    "    \n",
    "    if k==0:\n",
    "        ax.set_title(labels_text[0],fontsize=20)\n",
    "    if k==1:\n",
    "        ax.set_title(labels_text[1],fontsize=20)  \n",
    "    if k==2:\n",
    "        ax.set_title(labels_text[2],fontsize=20)      \n",
    "    if k==3:\n",
    "        ax.set_title(labels_text[3],fontsize=20) \n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    k+=1\n",
    "\n",
    "plt.colorbar(im, cax=grid.cbar_axes[0]).set_label(label='Optical Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial/Energy Profiles\n",
    "\n",
    "One way we can directly observe the effect of applying Spatial/Spectral correlation to our algorithms is through the use of pixel profiles across our reconstructed images in each domain respectively.\n",
    "\n",
    "By plotting signal values across spatial pixels, or across energy channels, the smoothing effects of our regularisation are seen. We will demonstrate each of these below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Spatial Profiles\n",
    "\n",
    "By identifying a region of our reconstructed slices were the Iodine signals are strong, we can plot along the pixels in this region and compare the line profiles for each algorithm covered here.\n",
    "\n",
    "Given the strong signals given by the eyes of the lizard head sample, we will look across this pixel row for a single channel, given by slice indices of:\n",
    " - `vertical = 35`\n",
    " - `horizontal_y = 35`\n",
    " - `channel = 20`\n",
    " \n",
    "**Feel free to adjust these values in the cell below if you wish to explore different regions of the reconstructed images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,8])\n",
    "\n",
    "# Extract line profiles for each algorithm\n",
    "plt.plot(FBP_recon_4D.get_slice(vertical = 35, horizontal_y = 35, channel = 20).as_array(),label='FDK')\n",
    "plt.plot(cgls_10.get_slice(vertical = 35, horizontal_y = 35, channel = 20).as_array(),label='CGLS')\n",
    "plt.plot(PDHG_TV_1000_Sp.get_slice(vertical = 35, horizontal_y = 35, channel = 20).as_array(),label='Space PDHG TV')\n",
    "plt.plot(PDHG_TV_1000_SpCh.get_slice(vertical = 35, horizontal_y = 35, channel = 20).as_array(),label='Space-Channel PDHG TV')\n",
    "\n",
    "plt.ylim((-0.1,0.7))\n",
    "# Label and add key\n",
    "plt.xlabel('Pixels X', fontsize=20)\n",
    "plt.ylabel('Optical Density (no units)', fontsize=20)\n",
    "plt.legend(loc='upper right',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the reduced noise fluctuations for both PDHG TV reconstructions, compared to the significant noise seen in both FDK and CGLS reconstructions. While the Space-Channel correlation may be overly smoothed, this highlights the impact that a small change in parameter weighting can have on our reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Energy Profiles\n",
    "\n",
    "Once we have chosen and optimised our reconstruction routine, we can exploit this additional, energy dimension further by identifying the spectral signals that lie within.\n",
    "\n",
    "First we can plot out energy profiles for any area within our reconstructed slices. This allows us to find, for instance, an absorption edge.\n",
    "Iodine has a known absorption 'K-edge' of 33.169 keV, so we can test the accuracy of reconstruction algorithms by seeing where this edge falls in each case. A plot of an idealised, theoretical Iodine K-edge is shown below, occurring precisely at 33.169 keV.  \n",
    "\n",
    "<img src=\"Images/Iodine_K_edge.png\" width=800 height=800 align=\"center\">\n",
    "Given that the data will be noisiest for a single voxel, we will extract spectral profiles from one voxel within the eye of the lizard, allowing us to compare the noise level of each reconstruction along the energy axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single voxel in lizard eye region\n",
    "\n",
    "# FDK Recon\n",
    "fdk_vox = FBP_recon_4D.as_array()[:,35,35,55]\n",
    "\n",
    "# 3D multi-channel 10 iteration CGLS\n",
    "cgls_vox = cgls_reg_10.as_array()[:,35,35,55]\n",
    "\n",
    "# 3D multi-channel space correlated PDHG\n",
    "pdhg_Sp_vox = PDHG_TV_1000_Sp.as_array()[:,35,35,55]\n",
    "\n",
    "# 3D multi-channel space-channel correlated PDHG TV\n",
    "pdhgSpCh_vox = PDHG_TV_1000_SpCh.as_array()[:,35,35,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channel numbers for reduced dataset (here 100 to 140)\n",
    "channel_no = np.linspace(100,140,num_channels)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(ekeV_crop,fdk_vox)\n",
    "plt.plot(ekeV_crop,cgls_vox) \n",
    "plt.plot(ekeV_crop,pdhg_Sp_vox)\n",
    "plt.plot(ekeV_crop,pdhgSpCh_vox)\n",
    "\n",
    "plt.plot((33.169,33.169),plt.ylim(0.1,0.6))\n",
    "\n",
    "plt.legend(labels=['FDK', 'Tik. CGLS', 'Space PDHG TV', \n",
    "                   'Sp-Ch. PDHG TV', 'I K-edge 33.169 keV'],fontsize=15)\n",
    "plt.xlim([29,39])\n",
    "\n",
    "plt.ylabel('Optical Density (no units)',fontsize=20)\n",
    "plt.xlabel('Energy (keV)',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our plots, we can see all algorithms experience a sharp rise in signal value due to the iodine absorption K-edge. Compared to the theoretical value line, each of the cases match well with the expected position of the edge.\n",
    "We can very clearly see the impact of the spectral regularisation using PDHG TV, with all noise entirely removed, and an almost perfectly smooth transition across energy channels. We still clearly see the rising edge at the iodine K-edge position. The use of spectral correlation enforces our operator to use the previous energy channel as a reference point for reconstructing data in the next, resulting in a smoother transition across channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Elemental Maps\n",
    "\n",
    "Once we know have identified the position of this edge in our energy profile, we can narrow our dataset and produce an 'Iodine map'. That is, we can select only the energy channels occupied by the absorption edge, so all reconstructed signal is now due only to the iodine contrast agent. This method is known as **'K-edge subtraction'**, which you can read about in more detail in papers such as that by [C.K.Egan *et al*, 2015](https://www.nature.com/articles/srep15979#).  \n",
    "A basic concept is shown below for an energy profile plot. The hashed area highlights the energy range we are interested in, corresponding to the absorption edge.\n",
    "\n",
    "<img src=\"Images/K_edge_Sub.jpg\" width=800 height=800 align=\"center\">\n",
    "\n",
    "Based on our plots, we will estimate the start and end of the edge to occur at approximately 32 keV and 34.5 keV respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy channels corresponding to start and end of the K-edge\n",
    "e_keV = np.array([32,34.5])\n",
    "# Convert back to channel number based on calibration values \n",
    "# (these are specific to the dataset, used here just to show the method.)\n",
    "channel_no = ((e_keV-0.8575)/0.2786)-100\n",
    "\n",
    "# Display the channels corresponding to the start and end of the K-edge (within our truncated dataset)\n",
    "print(\"Start of edge = channel\",int(channel_no[0]))\n",
    "print(\"End of edge = channel\",int(channel_no[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to average over all the channels in this channel range for each reconstruction, isolating the signal around the K-edge that only corresponds to Iodine. For simplicity, we will perform this over a single slice, in this case the 25th slice in the `horizontal_x` plane that we have used previously for comparing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D FBP\n",
    "# Sum over all pixels for channels of interest\n",
    "FBP_chan = np.mean(FBP_recon_4D.as_array()[int(channel_no[0]):int(channel_no[1]),:,:,25],0)\n",
    "\n",
    "# 4D Tikhonov CGLS\n",
    "CGLS_Tik_chan = np.mean(cgls_reg_10.as_array()[int(channel_no[0]):int(channel_no[1]),:,:,25],0)\n",
    "\n",
    "# 4D Space-Channel PDHG TV\n",
    "PDHG_SpCh_chan = np.mean(PDHG_TV_1000_Sp.as_array()[int(channel_no[0]):int(channel_no[1]),:,:,25],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `islicer` once more to compare our results, which shows the iodine maps for each reconstruction. By stacking the results as an array, `islicer` allows you to switch from one reconstruction to the next. You may notice that a lot of the same signal is present to before! This is because the iodine is a high concentration contrast agent which diffuses into nearly all soft tissue structures, increasing the attenuation levels of many areas except the bone regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect together iodine maps\n",
    "stack_maps = (np.array([FBP_chan, CGLS_Tik_chan, PDHG_SpCh_chan]))\n",
    "titles = ['Simple CGLS', 'Regularised CGLS', 'Space-Channel PDHG TV']\n",
    "islicer(stack_maps, title=titles, direction=0, cmap='inferno',minmax = (0.0,0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Conclusions</center></h1>\n",
    "\n",
    "This notebook focused on bringing together the core elements of the CIL framework you have learned in the previous notebooks, and seeing how these may be applied to a hyperspectral dataset. \n",
    "\n",
    "We looked at the key differences in building Image/Acquisition Geometries and Operators for hyperspectral datasets.\n",
    "\n",
    "We have covered three key algorithms (FDK, CGLS and PDHG) and shown the various ways in which we can build them, both with and without the addition of regularisation terms. We have also explored how each type of regularisation impacts our resulting reconstruction, highlighting why optimisation of our regularisation parameters is so important to produce the highest quality data. This is further highlighted through the extraction of both spatial and spectral profiles, as well as extraction of elemental maps using spectral analyses like K-edge subtraction. For more information on hyperspectral tomography reconstruction we refer to [Warr et al](https://arxiv.org/pdf/2103.04796), [Ametova et al](https://iopscience.iop.org/article/10.1088/1361-6463/ac02f9/pdf) and [Papoutsellis et al](https://arxiv.org/pdf/2102.06126).\n",
    "\n",
    "**Click the link below to see the potential for full volume, white-beam reconstructions using both CGLS (Left) and PDHG TV (Right)**  \n",
    "[4D Lizard Full Volume Reconstruction](Images/Lizard_gif.gif \"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
