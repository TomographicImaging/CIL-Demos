{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#   This work is part of the Core Imaging Library (CIL) developed by CCPi \n",
    "#   (Collaborative Computational Project in Tomographic Imaging), with \n",
    "#   substantial contributions by UKRI-STFC and University of Manchester.\n",
    "\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "#   Copyright 2021 UKRI-STFC\n",
    "#   Authored by: Evangelos Papoutsellis (UKRI-STFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Colour Processing </center></h1>\n",
    "\n",
    "In this notebook, we present how to **denoise** and **inpaint** our first **multichannel** data using CIL, i.e., a data with only 3 channels that contains information from the **Red**, **Green** and **Blue** bands. We start by loading a colour image from CIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataexample that contains different colour images\n",
    "from cil.utilities import dataexample, noise\n",
    "\n",
    "# import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from cil.utilities.display import show2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rainbow image\n",
    "data = dataexample.RAINBOW.get(size=(500,500), scale=(0,1))\n",
    "data.reorder(['horizontal_y', 'horizontal_x','channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show colour image and RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data.array)\n",
    "plt.title(\"Colour Image\")\n",
    "plt.show()\n",
    "\n",
    "show2D([data.get_slice(channel=0),\n",
    "        data.get_slice(channel=1),\n",
    "        data.get_slice(channel=2)], title=[\"Red\",\"Green\",\"Blue\"], origin=\"upper\", num_cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f64ba1",
   "metadata": {},
   "source": [
    "<h1><center>Imaging Model </center></h1>\n",
    "\n",
    "Let $u:\\Omega\\subset\\mathbb{R}^{N\\times M}\\rightarrow\\mathbb{R}^{N\\times M\\times3}$ a colour image that depicts a real _perfect_ scene (the unknown). Typically, we assume that $u$ has been transformed through a continuous and linear operation $\\mathcal{L}$ (**forward operator**). Additionally, we have a noisy component $\\eta$ that usually follows a certain distribution, e.g., **Gaussian** , **Salt and Pepper (Impluse)**. The **Imaging model** is defined as\n",
    "\n",
    "<a id =\"eq1\"></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "u_{0} = \\mathcal{L}u + \\eta\\,. \n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* **Image Denoising:** $\\mathcal{L}$ is the Identity operator and we are trying to remove the noise from $u_{0}$ in order to reconstruct $u$.\n",
    "\n",
    "<table><tr><td><img src='denoising_fig1.png'>\n",
    "</td><td><img src='inpainting_fig2.png'></td></tr></table>\n",
    "\n",
    "<a id =\"chi_func\"></a>\n",
    "* **Image Inpainting:** $\\mathcal{L}=\\mathcal{X}_{\\Omega\\setminus D}$ is the characteristic function defined as \n",
    "\n",
    "    $$\\mathcal{X}_{\\Omega\\setminus \\mathcal{D}}(x) = \n",
    "    \\begin{cases}\n",
    "    1, & x\\in \\Omega\\setminus D\\\\\n",
    "    0, & \\mbox{otherwise}\n",
    "    \\end{cases},\n",
    "    $$\n",
    "    \n",
    "    where $\\mathcal{D}$ is a subdomain of $\\Omega$ (**inpainting domain**). In the inpainting domain there is no data information available and we are trying to reconstruct $u$ based on the information provided from the known region of $u_{0}$. \n",
    "    \n",
    "<table><tr><td><img src='inpainting_fig1.png'>\n",
    "</td><td><img src='inpainting_fig2.png'></td></tr></table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9561694",
   "metadata": {},
   "source": [
    "In this notebook, we will consider the cases of \n",
    "\n",
    "* denoising a noisy image corrupted by additive Gaussian noise,\n",
    "* inpainting + denoising a noisy image corrupted by Salt \\& Pepper noise with missing text information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Color Denoising </center></h1>\n",
    "\n",
    "We solve the following minimisation problem to denoise our coloured image:\n",
    "\n",
    "<a id=\"rof\"></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} = \\underset{u}{\\operatorname{argmin}}  \\frac{1}{2}\\| b - u \\|^{2}_{2} + \\alpha\\,\\mathrm{VTV}(u)\n",
    "\\label{ROF}\n",
    "\\tag{1}\n",
    "\\end{equation},\n",
    "$$\n",
    "\n",
    "where the data $b$ is corrupted with Gaussian noise and $\\mathrm{\\textbf{VTV}}$ is the **Vectorial** extension of the classical Total variation regularisation for coloured images. We recall that the definition of the (isotropic) Total Variation, used for gray-valued images, is\n",
    "\n",
    "$$\n",
    "\\mathrm{TV}(u) = \\|Du\\|_{2,1} = \\sum_{i,j}^{M,N}\\big(|(D_{y}u, D_{x}u)|_{2}\\big)_{i,j} =  \\sum_{i,j}^{M,N} \\big(\\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big)_{i,j}.\n",
    "$$\n",
    "\n",
    "Now, for vector-valued images the gradient is $Du=(Du_{1}, Du_{2}, Du_{3})$, where for each **RGB** channels $k=1,2,3$, $Du_{k}:=(D_{y}u_{k}, D_{x}u_{k})$. \n",
    "\n",
    "For this type of multichannel data, we can create different configurations on how the **colour channels**, the **derivatives** and the **image pixels** are correlated and under which norm. One generic approach for this regulariser is presented in [Duran et al](https://arxiv.org/pdf/1508.01308.pdf#page=8), where the **Collaborative Total variation** is introduced, i.e.,\n",
    "\n",
    "$$\n",
    "\\|A\\|_{p,q,r} := \\bigg(\\sum_{i=1}^{N}\\quad\\bigg(\\sum_{j=1}^{M}\\quad\\bigg(\\sum_{k=1}^{C} |A_{i,j,k}|^{p}\\bigg)^{\\frac{q}{p}}\\quad\\bigg)^{\\frac{r}{q}}\\quad\\bigg)^{\\frac{1}{r}}\\quad .\n",
    "$$\n",
    "\n",
    "For simplicity, in this notebook, we will use the _Channelwise TV_ definition, namely, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{VTV}(u)  := \\|D u\\|_{2,1}  = \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} (|Du_{k}|_{2})_{i,j} = \n",
    "                 \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} \\big( \\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big) = \\sum_{k=1}^{3} \\mathrm{TV}(u_{k}).\n",
    "\\label{tv_color}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The above definition corresponds to the $\\ell_{2,1,1}$ (derivative, pixels, colour) Collaborative TV. This means that, an $\\ell_{2}$ norm is applied for the **derivatives**, followed by an $\\ell_{1}$ norm for the **pixels** of the image and a final $\\ell_{1}$ norm for the three **channels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Total variation\n",
    "from cil.optimisation.functions import TotalVariation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and corrupt with gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rainbow data\n",
    "data = dataexample.RAINBOW.get(size=(500,500), scale=(0,1))\n",
    "data.reorder(['horizontal_y', 'horizontal_x','channel'])\n",
    "\n",
    "noisy_data = noise.gaussian(data, seed = 10, var = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data.as_array(), noisy_data.as_array(),\n",
    "          data.as_array()[:,:,0], noisy_data.as_array()[:,:,0],\n",
    "          data.as_array()[:,:,1], noisy_data.as_array()[:,:,1],\n",
    "          data.as_array()[:,:,2], noisy_data.as_array()[:,:,2]]\n",
    "          \n",
    "                             \n",
    "labels_y = [\"Red\", \"Green\",\"Blue\"]\n",
    "labels_x = [\"Ground truth\",\"Noisy data\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(4, 2),\n",
    "                axes_pad=0.1,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.4\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "    \n",
    "    \n",
    "    img = ax.imshow(images[k])\n",
    "    if k==0 or k==1:\n",
    "        ax.set_title(labels_x[k],fontsize=25)\n",
    "    if k==2:\n",
    "        ax.set_ylabel(labels_y[0],fontsize=25)\n",
    "    if k==4:\n",
    "        ax.set_ylabel(labels_y[1],fontsize=25)\n",
    "    if k==6:\n",
    "        ax.set_ylabel(labels_y[2],fontsize=25)        \n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the above minimisation problem using the `proximal` method of the `TotalVariation` class that was used in previous notebooks. Recall, that given a function $f$, the _proximal operator of $f$_ is\n",
    "\n",
    "$$\\mathrm{prox}_{\\tau f}(x) := \\underset{u}{\\operatorname{argmin}}\\frac{1}{2}\\|x-u\\|_{2}^{2} + \\tau f(u), \\quad\\mbox{for any } x.$$\n",
    "\n",
    "This definition is exactly the same with the [above minimisation problem](#rof), if we replace $f$ by $\\alpha\\mathrm{VTV}$, $x$ with $b$ and $\\tau=1.0$. Therefore, the _proximal operator of VTV at $b$_ is \n",
    "\n",
    "$$\\mathrm{prox}_{\\tau (\\alpha \\mathrm{VTV})}(b)\\, .$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "TV = alpha * TotalVariation(max_iteration=500)\n",
    "proxTV = TV.proximal(noisy_data, tau=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data.as_array(), noisy_data.as_array(), proxTV.as_array(),\n",
    "         data.as_array()[:,:,0], noisy_data.as_array()[:,:,0], proxTV.as_array()[:,:,0],\n",
    "         data.as_array()[:,:,1], noisy_data.as_array()[:,:,1], proxTV.as_array()[:,:,1],\n",
    "         data.as_array()[:,:,2], noisy_data.as_array()[:,:,2], proxTV.as_array()[:,:,2]],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"Noisy Data\", \"TV denoising\",\n",
    "           \"(Red) Ground Truth\", \" (Red) Noisy Data\", \"(Red) TV denoising\",\n",
    "           \"(Green) Ground Truth\", \"(Green) Noisy Data\", \" (Green) TV denoising\",\n",
    "           \"(Blue) Ground Truth\", \"(Blue) Noisy Data\", \"(Blue) TV denoising\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=12\n",
    "plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(4, 3),\n",
    "                axes_pad=0.5,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.4\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "    \n",
    "    \n",
    "    img = ax.imshow(images[0][k])\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise : Use the PDHG algorithm to solve the above problem\n",
    "\n",
    "The triplet $(K, \\mathcal{F}, \\mathcal{G})$ is defined as:\n",
    "\n",
    "* $K = D \\Longleftrightarrow$ `K = GradientOperator(noisy_data.geometry)` .\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{F}(z) = \\alpha\\,\\|z\\|_{2,1}\\Longleftrightarrow$ `F = alpha * MixedL21Norm()` .\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{G}(u) = \\frac{1}{2}\\|b - u \\|^{2}_{2}\\, \\Longleftrightarrow$ `G = 0.5 * L2NormSquared(b=noisy_data)` .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Colour Inpainting </center></h1>\n",
    "\n",
    "Given an image where a specific region is unknown, the task of image inpainting is to recover the missing region $\\mathcal{D}$ from the known part of the image $\\Omega$. For this example, we will use the _rainbow image_,  where we are trying to remove a repeated text (+ salt and pepper noise) from the image that represents the unknown domain $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create corrupted image\n",
    "\n",
    "We use the *Pillow* library to add text in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array\n",
    "img_np = data.array\n",
    "\n",
    "# Add text to the image\n",
    "img_pil = Image.fromarray(np.uint8(img_np*255)).convert('RGB')\n",
    "text = \"\\n    This is a double \\\n",
    "        \\n         rainbow \\n\"*3 \n",
    "\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "font = ImageFont.truetype('FreeSerifBold.ttf', 50)\n",
    "draw.text((0, 0), text, (0, 0, 0), font=font)\n",
    "\n",
    "# Pillow image to numpy\n",
    "im1 = np.array(img_pil)\n",
    "\n",
    "# Rescale numpy array\n",
    "img_np_rescale = im1/im1.max()\n",
    "\n",
    "# Get image geometry\n",
    "ig = data.geometry\n",
    "\n",
    "# Create ImageData\n",
    "data_with_text = ig.allocate()\n",
    "data_with_text.fill(img_np_rescale)\n",
    "\n",
    "# Show rainbow with text\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data_with_text.array)\n",
    "plt.title(\"Rainbow with text\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the mask representing the $\\mathcal{D}$ region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask that contains only text information\n",
    "mask_boolean = (data_with_text-data).abs()==0\n",
    "\n",
    "# Show rainbow with text\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(mask_boolean[:,:,0])\n",
    "plt.title(\"Mask: (Yellow=True, Blue=False)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the mask for the RGB channels\n",
    "\n",
    "Our mask plays the role of the characteristic function defined [above](#chi_func). Here, we use the `MaskOperator` that applies a mask to our image for all the red, green and blue channels using the `ChannelwiseOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.optimisation.operators import MaskOperator, ChannelwiseOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ig.subset(channel=0).allocate(True,dtype=np.bool)\n",
    "mask.fill(mask_boolean[:,:,0])\n",
    "MO = ChannelwiseOperator(MaskOperator(mask), 3, dimension = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = noise.saltnpepper(data_with_text, amount=0.01, seed = 10)\n",
    "noisy_data = MO.direct(noisy_data) \n",
    "\n",
    "# noisy_data = MO.direct(data) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(noisy_data.as_array())\n",
    "plt.title(\"Corrupted image: Missing information + Salt and pepper noise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total variation inpainting vs Total Generalised Variation\n",
    "\n",
    "We will use two different regularisation in order to restore the above corrupted image. We start with the TV regularisation described above and its generalisation, namely the **Total Generalised Variation (TGV)** introduced in [Bredies et al](https://epubs.siam.org/doi/abs/10.1137/090769521?mobileUi=0). TGV is a higher-order regulariser, that is able to obtain piecewise smooth solutions and restore staircasing artifacts that TV promotes. We let $\\alpha, \\beta>0$ be two regularisation parameters and define\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{TGV}_{\\alpha, \\beta}(u) = \\min_{w} \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\label{TGV}\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\mathcal{E}$ denotes the **Symmetrised Gradient** operator defined as \n",
    "\n",
    "$$\n",
    "\\mathcal{E}w = \\frac{1}{2}(D w + D w^{T}).\n",
    "$$\n",
    "\n",
    "The minimisation problems, using the $L^{1}$ norm as a data fidelity term which is suitable for salt & pepper noise, are:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} \\|\\mathcal{M}u-b\\|_{1} + \\alpha\\mathrm{VTV}(u) \n",
    "\\label{TV_L1_inpainting}\n",
    "\\tag{TV-$L^{1}$}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "<a id='TGV_L1'></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} & \\|\\mathcal{M}u-b\\|_{1} + \\mathrm{TGV}_{\\alpha, \\beta}(u) \\Leftrightarrow \\\\\n",
    "(u^{*},w^{*}) =\\underset{u, w}{\\operatorname{argmin}} &  \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{TGV_L1_inpainting}\n",
    "\\tag{TGV-$L^{1}$}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the $\\mathcal{M}$ is a diagonal operator with 1 in the diagonal elements corresponding to pixels in $\\Omega\\setminus\\mathcal{D}$ and 0 in $\\mathcal{D}$.\n",
    "\n",
    "We solve the above problems using the **PDHG** algorithm described in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cil.optimisation.operators import BlockOperator, SymmetrisedGradientOperator, GradientOperator, ZeroOperator, IdentityOperator \n",
    "from cil.optimisation.functions import ZeroFunction, L1Norm, MixedL21Norm, BlockFunction, L2NormSquared\n",
    "from cil.optimisation.algorithms import PDHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run the PDHG algorithm for $\\mathrm{TV}-L^{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grad = GradientOperator(ig)\n",
    "K = BlockOperator(Grad, MO)\n",
    "\n",
    "alpha_tv = 0.5\n",
    "f1 = alpha_tv * MixedL21Norm()\n",
    "f2 = L1Norm(b=noisy_data)\n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "G = ZeroFunction()\n",
    "\n",
    "pdhg_tv = PDHG(f=F,g=G,operator=K,\n",
    "            max_iteration = 1000,\n",
    "            update_objective_interval = 200)\n",
    "pdhg_tv.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run the PDHG algorithm for $\\mathrm{TGV}-L^1$ \n",
    "\n",
    "Recall, that we need to define the triplet ($K$,  $\\mathcal{F}$, $\\mathcal{G}$) and write the above problem into the following form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} \\mathcal{F}(Ku) + \\mathcal{G}(u).\n",
    "\\label{general_form}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let $\\textbf{u} = (u, w)\\in \\mathbb{X}$ and define an operator $K:\\mathbb{X}\\rightarrow\\mathbb{Y}$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M} & \\mathcal{O}\\\\\n",
    "D & -\\mathcal{I}\\\\\n",
    "\\mathcal{O} & \\mathcal{E}\n",
    "\\end{bmatrix} \\quad\\Rightarrow\\quad\n",
    "K\\textbf{u} = \n",
    "K \\begin{bmatrix}\n",
    "u\\\\\n",
    "w\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix} = \\textbf{y}\\in \\mathbb{Y},\n",
    "\\label{def_K}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{O}$, $\\mathcal{I}$ denote the zero and identity operators respectively.\n",
    "\n",
    "For the function $\\mathcal{F}$, we have that\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\mathcal{F}(\\textbf{y})  := \\mathcal{F}(y_{1}, y_{2}, y_{3}) = f_{1}(y_{1}) +  f_{2}(y_{2})  +  f_{3}(y_{3}), \\mbox{ where},\\\\\n",
    "& f_{1}(y_{1}) :=  \\| y_{1} - b\\|_1,\\, f_{2}(y_{2}) :=  \\alpha \\|y_{2}\\|_{2,1},\\, f_{3}(y_{3}) := \\beta\\|y_{3}\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{def_f}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "and for the function $\\mathcal{G}$, $\\mathcal{G}(\\textbf{u}) = \\mathcal{G}(u,w) = O(u)\\equiv 0 $ is the zero function. \n",
    "\n",
    "We conclude that\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "f(K\\textbf{u}) + g(\\textbf{u}) & = f\\bigg(\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix}\\bigg)  = f_{1}(\\mathcal{M}u) + f_{2}(Du-w) + f_{3}(\\mathcal{E}w) \\\\\n",
    "& = \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which is exactly the objective function in [TGV_L1](#TGV_L1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisation parameters\n",
    "alpha_tgv = 0.4\n",
    "beta_tgv = 0.2\n",
    "\n",
    "# Define BlockOperator K\n",
    "K11 = MO\n",
    "K21 = Grad\n",
    "K32 = SymmetrisedGradientOperator(K21.range)\n",
    "K12 = ZeroOperator(K32.domain, ig)\n",
    "K22 = IdentityOperator(K21.range)\n",
    "K31 = ZeroOperator(ig, K32.range)\n",
    "K = BlockOperator(K11, K12, K21, -K22, K31, K32, shape=(3,2) )\n",
    "\n",
    "# Define BlockFunction f\n",
    "f2 = alpha_tgv * MixedL21Norm()\n",
    "f3 = beta_tgv * MixedL21Norm() \n",
    "f1 = L1Norm(b=noisy_data)\n",
    "\n",
    "F = BlockFunction(f1, f2, f3) \n",
    "\n",
    "# Setup and run the PDHG algorithm\n",
    "pdhg_tgv = PDHG(f=F,g=G,operator=K,\n",
    "            max_iteration = 2000,\n",
    "            update_objective_interval = 200)\n",
    "pdhg_tgv.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data, pdhg_tv.solution, (pdhg_tv.solution-data).abs()*3,\n",
    "          noisy_data, pdhg_tgv.solution[0], (pdhg_tgv.solution[0]-data).abs()*3],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"TV inpainting/denoising\", \" |Ground Truth - TV|\", \n",
    "            \"Corrupted Image\", \"TGV inpainting/denoising\", \" |Ground Truth - TGV|\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 3),\n",
    "                axes_pad=0.8,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.3\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "        \n",
    "    img = ax.imshow(images[0][k].as_array())\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Conclusions</center></h1>\n",
    "\n",
    "In this notebook, we presented how to reconstruct multichannel data with 3 channels, using two different regularisers and data fitting terms. The following notebooks will demonstrate how to reconstruct multichannel data for CT and MRI applications:\n",
    "\n",
    "* **Dynamic CT**: Channels contain temporal information from the acquisition data.\n",
    "* **Hypespectral CT**: Channels contain spectral energy information acquired from an energy-sensitive X-ray detector.\n",
    "* **Sequence MRI**: Channels contain information from two MR images with different contrast.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
