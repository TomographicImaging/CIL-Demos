{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#   This work is part of the Core Imaging Library (CIL) developed by CCPi \n",
    "#   (Collaborative Computational Project in Tomographic Imaging), with \n",
    "#   substantial contributions by UKRI-STFC and University of Manchester.\n",
    "\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "#   Copyright 2021 UKRI-STFC\n",
    "#   Authored by:    Evangelos Papoutsellis (UKRI-STFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46830e5-df60-4912-be06-aa0b397e9391",
   "metadata": {},
   "source": [
    "<h1><center>Color Processing </center></h1>\n",
    "\n",
    "In this notebook, we present how to denoise and inpaint our first **multichannel** data using CIL, i.e., a data with only 3 channels that contains information from the **Red**, **Green** and **Blue** bands. We start by loading a color image from CIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b911b71-478e-462c-9fd2-8d95df8f397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataexample that contains different color images\n",
    "from cil.utilities import dataexample, noise\n",
    "\n",
    "# import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from cil.utilities.display import show2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d90e1-d5c6-4542-a3e7-5e2440b3531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rainbow image\n",
    "data = dataexample.RAINBOW.get(size=(500,500), scale=(0,1))\n",
    "data.reorder(['horizontal_y', 'horizontal_x','channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc74ce5-e31d-4681-b04c-4ea58720f724",
   "metadata": {},
   "source": [
    "## Show color image and RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274496ff-9a1b-46e1-995a-f0a14cbd7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data.array)\n",
    "plt.title(\"Color Image\")\n",
    "plt.show()\n",
    "\n",
    "show2D([data.get_slice(channel=0),\n",
    "        data.get_slice(channel=1),\n",
    "        data.get_slice(channel=2)], title=[\"Red\",\"Green\",\"Blue\"], origin=\"upper\", num_cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cadb0-a6b8-4a08-9af3-9d2e7338308b",
   "metadata": {},
   "source": [
    "We will consider the cases of \n",
    "\n",
    "* denoising a noisy image corrupted by Gaussian noise,\n",
    "* inpainting + denoising a noisy image corrupted by Salt \\& Pepper noise with missing text information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593afeb-fa7e-4e59-9a27-398c59cac1d3",
   "metadata": {},
   "source": [
    "<h1><center>Total variation Denoising </center></h1>\n",
    "\n",
    "We recall that the definition of the (isotropic) Total Variation, used for gray-valued images, is\n",
    "\n",
    "$$\n",
    "\\mathrm{TV}(u) = \\|Du\\|_{2,1} = \\sum_{i,j}^{M,N}\\big(|(D_{y}u, D_{x}u)|_{2}\\big)_{i,j} =  \\sum_{i,j}^{M,N} \\big(\\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big)_{i,j}.\n",
    "$$\n",
    "\n",
    "This can be extended for vector-valued images which results to a **vectorial** formulation of the total variation. The gradient for the **RGB** case is now $Du=(Du_{1}, Du_{2}, Du_{3})$, where for each channel $k=1,2,3$, $Du_{k}:=(D_{y}u_{k}, D_{x}u_{k})$. \n",
    "\n",
    "For this type of multichannel data, we can create different configurations on how the **color channels**, the **derivatives** and the **image pixels** are correlated and under which norm. One generic approach for this regulariser is presented in [Duran et al](https://arxiv.org/pdf/1508.01308.pdf#page=8), where the **Collaborative Total variation** is introduced, i.e.,\n",
    "\n",
    "$$\n",
    "\\|A\\|_{p,q,r} := \\bigg(\\sum_{i=1}^{N}\\quad\\bigg(\\sum_{j=1}^{M}\\quad\\bigg(\\sum_{k=1}^{C} |A_{i,j,k}|^{p}\\bigg)^{\\frac{q}{p}}\\quad\\bigg)^{\\frac{r}{q}}\\quad\\bigg)^{\\frac{1}{r}}\\quad .\n",
    "$$\n",
    "\n",
    "For simplicity, in this notebook, we will use a _Channelwise TV_ definition, namely, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{VTV}(u)  := \\|D u\\|_{2,1}  = \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} (|Du_{k}|_{2})_{i,j} = \n",
    "                 \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} \\big( \\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big) = \\sum_{k=1}^{3} \\mathrm{TV}(u_{k}).\n",
    "\\label{tv_color}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The above definition corresponds to the $\\ell_{2,1,1}$ (derivative, pixels, color) Collaborative TV. This means that, an $\\ell_{2}$ norm is applied for the **derivatives**, followed by an $\\ell_{1}$ norm for the **pixels** of the image and a final $\\ell_{1}$ norm for the three **channels**.\n",
    "\n",
    "For data $b$ corrupted with Gaussian noise, the minimisation problem is now:\n",
    "\n",
    "<a id=\"rof\"></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} = \\underset{u}{\\operatorname{argmin}}  \\frac{1}{2}\\| b - u \\|^{2}_{2} + \\alpha\\,\\mathrm{VTV}(u)\n",
    "\\label{ROF}\n",
    "\\tag{1}\n",
    "\\end{equation}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0116bd-1a4a-40f6-abb8-01b579a6b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Total variation\n",
    "from cil.optimisation.functions import TotalVariation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a95262-f4f3-47b6-ae83-dcfb1de2940f",
   "metadata": {},
   "source": [
    "## Load data and corrupt with gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474bccc-8bf1-4372-963e-99157db12eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rainbow data\n",
    "data = dataexample.RAINBOW.get(size=(500,500), scale=(0,1))\n",
    "data.reorder(['horizontal_y', 'horizontal_x','channel'])\n",
    "\n",
    "noisy_data = noise.gaussian(data, seed = 10, var = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828970c-1967-4fff-bc16-9a6d668e0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data.as_array(), noisy_data.as_array(),\n",
    "          data.as_array()[:,:,0], noisy_data.as_array()[:,:,0],\n",
    "          data.as_array()[:,:,1], noisy_data.as_array()[:,:,1],\n",
    "          data.as_array()[:,:,2], noisy_data.as_array()[:,:,2]]\n",
    "          \n",
    "                             \n",
    "labels_y = [\"Red\", \"Green\",\"Blue\"]\n",
    "labels_x = [\"Ground truth\",\"Noisy data\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(4, 2),\n",
    "                axes_pad=0.1,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.4\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "    \n",
    "    \n",
    "    img = ax.imshow(images[k])\n",
    "    if k==0 or k==1:\n",
    "        ax.set_title(labels_x[k],fontsize=25)\n",
    "    if k==2:\n",
    "        ax.set_ylabel(labels_y[0],fontsize=25)\n",
    "    if k==4:\n",
    "        ax.set_ylabel(labels_y[1],fontsize=25)\n",
    "    if k==6:\n",
    "        ax.set_ylabel(labels_y[2],fontsize=25)        \n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0c7fb-e267-4af3-805d-183009c48151",
   "metadata": {},
   "source": [
    "We solve the above minimisation problem using the `proximal` method of the `TotalVariation` class that was used in previous notebooks. Recall, that given a function $f$, the _proximal operator of $f$_ is\n",
    "\n",
    "$$\\mathrm{prox}_{\\tau f}(x) := \\underset{u}{\\operatorname{argmin}}\\frac{1}{2}\\|x-u\\|_{2}^{2} + \\tau f(u), \\quad\\mbox{for any } x.$$\n",
    "\n",
    "This definition is exactly the same with the [above minimisation problem](#rof), if we replace $f$ by $\\alpha\\mathrm{VTV}$ and $x$ with $b$. Therefore, the _proximal operator of VTV centered at $b$_ is $$\\mathrm{prox}_{\\tau (\\alpha \\mathrm{VTV})}(b)\\, .$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcc134-d735-48ac-af4c-59146c5dda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "TV = alpha * TotalVariation(max_iteration=500)\n",
    "proxTV = TV.proximal(noisy_data, tau=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be6f18-f4b8-4c25-8c61-be4195d90ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data.as_array(), noisy_data.as_array(), proxTV.as_array(),\n",
    "         data.as_array()[:,:,0], noisy_data.as_array()[:,:,0], proxTV.as_array()[:,:,0],\n",
    "         data.as_array()[:,:,1], noisy_data.as_array()[:,:,1], proxTV.as_array()[:,:,1],\n",
    "         data.as_array()[:,:,2], noisy_data.as_array()[:,:,2], proxTV.as_array()[:,:,2]],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"Noisy Data\", \"TV denoising\",\n",
    "           \"(Red) Ground Truth\", \" (Red) Noisy Data\", \"(Red) TV denoising\",\n",
    "           \"(Green) Ground Truth\", \"(Green) Noisy Data\", \" (Green) TV denoising\",\n",
    "           \"(Blue) Ground Truth\", \"(Blue) Noisy Data\", \"(Blue) TV denoising\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=12\n",
    "plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(4, 3),\n",
    "                axes_pad=0.5,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.4\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "    \n",
    "    \n",
    "    img = ax.imshow(images[0][k])\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49aedcf",
   "metadata": {},
   "source": [
    "## Exercise : Use the PDHG algorithm to solve the above problem\n",
    "\n",
    "The triplet $(K, \\mathcal{F}, \\mathcal{G})$ is defined as:\n",
    "\n",
    "* $K = D \\Longleftrightarrow$ `K = GradientOperator(noisy_data.geometry)` .\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{F}(z) = \\alpha\\,\\|z\\|_{2,1}\\Longleftrightarrow$ `F = alpha * MixedL21Norm()` .\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{G}(u) = \\frac{1}{2}\\|b - u \\|^{2}_{2}\\, \\Longleftrightarrow$ `G = 0.5 * L2NormSquared(b=noisy_data)` .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b200f7-fd81-427c-8184-f96f7291ecd3",
   "metadata": {},
   "source": [
    "<h1><center>Color Inpainting </center></h1>\n",
    "\n",
    "Given an image where a specific region is unknown, the task of image inpainting is to recover the missing region $\\mathcal{D}$ from the known part of the image $\\Omega$. For this example, we will use the _rainbow image_,  where we are trying to remove a repeated text (+ salt and pepper noise) from the image that represents the unknown domain $\\mathcal{D}$.\n",
    "\n",
    "<table><tr><td><img src='inpainting_fig1.png'>\n",
    "</td><td><img src='inpainting_fig2.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6b092-9dac-4985-b0fc-9b33ec1ba65d",
   "metadata": {},
   "source": [
    "## Create corrupted image\n",
    "\n",
    "We use the *Pillow* library to add text in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ed184-8ebf-45af-a0c0-47411ab00dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7376b9f-5760-4a65-b836-e47308b6d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array\n",
    "img_np = data.array\n",
    "\n",
    "# Add text to the image\n",
    "img_pil = Image.fromarray(np.uint8(img_np*255)).convert('RGB')\n",
    "text = \"\\n    This is a double \\\n",
    "        \\n         rainbow \\n\"*3 \n",
    "\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "font = ImageFont.truetype('FreeSerifBold.ttf', 50)\n",
    "draw.text((0, 0), text, (0, 0, 0), font=font)\n",
    "\n",
    "# Pillow image to numpy\n",
    "im1 = np.array(img_pil)\n",
    "\n",
    "# Rescale numpy array\n",
    "img_np_rescale = im1/im1.max()\n",
    "\n",
    "# Get image geometry\n",
    "ig = data.geometry\n",
    "\n",
    "# Create ImageData\n",
    "data_with_text = ig.allocate()\n",
    "data_with_text.fill(img_np_rescale)\n",
    "\n",
    "# Show rainbow with text\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data_with_text.array)\n",
    "plt.title(\"Rainbow with text\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821ccfb-e831-4880-aa50-2828bc122737",
   "metadata": {},
   "source": [
    "## Create the mask representing the $\\mathcal{D}$ region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c629e3d-7d28-41b7-80e3-c031d9f9dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask that contains only text information\n",
    "mask_boolean = (data_with_text-data).abs()==0\n",
    "\n",
    "# Show rainbow with text\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(mask_boolean[:,:,0])\n",
    "plt.title(\"Mask: (Yellow=True, Blue=False)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c6d0c-df7f-423a-a6be-43edfcb84573",
   "metadata": {},
   "source": [
    "## Apply the mask for the RGB channels\n",
    "\n",
    "Here, we use the `MaskOperator` that applies a mask to our image for all the red, green and blue channels using the `ChannelwiseOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d27ca-affa-49fd-a477-09b06bb04534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.optimisation.operators import MaskOperator, ChannelwiseOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd31c7-2597-4ec6-9bb0-af1984c26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ig.subset(channel=0).allocate(True,dtype=np.bool)\n",
    "mask.fill(mask_boolean[:,:,0])\n",
    "MO = ChannelwiseOperator(MaskOperator(mask), 3, dimension = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef10dc2-3493-47cd-84c5-1e8cd4118b96",
   "metadata": {},
   "source": [
    "## Add salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf41ad-4a2b-4e33-b837-69b243742605",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = noise.saltnpepper(data_with_text, amount=0.01, seed = 10)\n",
    "noisy_data = MO.direct(noisy_data) \n",
    "\n",
    "# noisy_data = MO.direct(data) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(noisy_data.as_array())\n",
    "plt.title(\"Corrupted image: Missing information + Salt and pepper noise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d357b-4ba5-4ca5-aea5-489987f364b1",
   "metadata": {},
   "source": [
    "## Total variation inpainting vs Total Generalised Variation\n",
    "\n",
    "We will use two different regularisation in order to restore the above corrupted image. We start with the TV regularisation described above and its generalisation, namely the **Total Generalised Variation (TGV)** introduced in [Bredies et al](https://epubs.siam.org/doi/abs/10.1137/090769521?mobileUi=0). TGV is a higher-order regulariser, that is able to obtain piecewise smooth solutions and restore staircasing artifacts that TV promotes. We let $\\alpha, \\beta>0$ be two regularisation parameters and define\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{TGV}_{\\alpha, \\beta}(u) = \\min_{w} \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\label{TGV}\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\mathcal{E}$ denotes the **Symmetrised Gradient** operator defined as \n",
    "\n",
    "$$\n",
    "\\mathcal{E}w = \\frac{1}{2}(D w + D w^{T}).\n",
    "$$\n",
    "\n",
    "The minimisation problems, using the $L^{1}$ norm as a data fidelity term which is suitable for salt & pepper noise, are:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} \\|\\mathcal{M}u-b\\|_{1} + \\alpha\\mathrm{VTV}(u) \n",
    "\\label{TV_L1_inpainting}\n",
    "\\tag{TV-$L^{1}$}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "<a id='TGV_L1'></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} & \\|\\mathcal{M}u-b\\|_{1} + \\mathrm{TGV}_{\\alpha, \\beta}(u) \\Leftrightarrow \\\\\n",
    "(u^{*},w^{*}) =\\underset{u, w}{\\operatorname{argmin}} &  \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{TGV_L1_inpainting}\n",
    "\\tag{TGV-$L^{1}$}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the $\\mathcal{M}$ is a diagonal operator with 1 in the diagonal elements corresponding to pixels in $\\Omega\\setminus\\mathcal{D}$ and 0 in $\\mathcal{D}$.\n",
    "\n",
    "We solve the above problems using the **PDHG** algorithm described in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa12cd-ff0c-4b7a-a1c6-cd9f2670fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cil.optimisation.operators import BlockOperator, SymmetrisedGradientOperator, GradientOperator, ZeroOperator, IdentityOperator \n",
    "from cil.optimisation.functions import ZeroFunction, L1Norm, MixedL21Norm, BlockFunction, L2NormSquared\n",
    "from cil.optimisation.algorithms import PDHG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce2afb-4be6-4f68-b480-f86de2862197",
   "metadata": {},
   "source": [
    "## Setup and run the PDHG algorithm for $\\mathrm{TV}-L^{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7efe4-da83-4c20-86d7-277e07b670a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grad = GradientOperator(ig)\n",
    "K = BlockOperator(Grad, MO)\n",
    "\n",
    "alpha_tv = 0.5\n",
    "f1 = alpha_tv * MixedL21Norm()\n",
    "f2 = L1Norm(b=noisy_data)\n",
    "F = BlockFunction(f1, f2)\n",
    "\n",
    "G = ZeroFunction()\n",
    "\n",
    "pdhg_tv = PDHG(f=F,g=G,operator=K,\n",
    "            max_iteration = 1000,\n",
    "            update_objective_interval = 200)\n",
    "pdhg_tv.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c763b-079e-4354-9504-d0c03dcea8b1",
   "metadata": {},
   "source": [
    "## Setup and run the PDHG algorithm for $\\mathrm{TGV}-L^1$ \n",
    "\n",
    "Recall, that we need to define the triplet ($K$,  $\\mathcal{F}$, $\\mathcal{G}$) and write the above problem into the following form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} \\mathcal{F}(Ku) + \\mathcal{G}(u).\n",
    "\\label{general_form}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let $\\textbf{u} = (u, w)\\in \\mathbb{X}$ and define an operator $K:\\mathbb{X}\\rightarrow\\mathbb{Y}$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M} & \\mathcal{O}\\\\\n",
    "D & -\\mathcal{I}\\\\\n",
    "\\mathcal{O} & \\mathcal{E}\n",
    "\\end{bmatrix} \\quad\\Rightarrow\\quad\n",
    "K\\textbf{u} = \n",
    "K \\begin{bmatrix}\n",
    "u\\\\\n",
    "w\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix} = \\textbf{y}\\in \\mathbb{Y},\n",
    "\\label{def_K}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{O}$, $\\mathcal{I}$ denote the zero and identity operators respectively.\n",
    "\n",
    "For the function $\\mathcal{F}$, we have that\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\mathcal{F}(\\textbf{y})  := \\mathcal{F}(y_{1}, y_{2}, y_{3}) = f_{1}(y_{1}) +  f_{2}(y_{2})  +  f_{3}(y_{3}), \\mbox{ where},\\\\\n",
    "& f_{1}(y_{1}) :=  \\| y_{1} - b\\|_1,\\, f_{2}(y_{2}) :=  \\alpha \\|y_{2}\\|_{2,1},\\, f_{3}(y_{3}) := \\beta\\|y_{3}\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{def_f}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "and for the function $\\mathcal{G}$, $\\mathcal{G}(\\textbf{u}) = \\mathcal{G}(u,w) = O(u)\\equiv 0 $ is the zero function. \n",
    "\n",
    "We conclude that\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "f(K\\textbf{u}) + g(\\textbf{u}) & = f\\bigg(\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix}\\bigg)  = f_{1}(\\mathcal{M}u) + f_{2}(Du-w) + f_{3}(\\mathcal{E}w) \\\\\n",
    "& = \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which is exactly the objective function in [TGV_L1](#TGV_L1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceeed7-56f4-4905-9243-fa86ef67a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisation parameters\n",
    "alpha_tgv = 0.4\n",
    "beta_tgv = 0.2\n",
    "\n",
    "# Define BlockOperator K\n",
    "K11 = MO\n",
    "K21 = Grad\n",
    "K32 = SymmetrisedGradientOperator(K21.range)\n",
    "K12 = ZeroOperator(K32.domain, ig)\n",
    "K22 = IdentityOperator(K21.range)\n",
    "K31 = ZeroOperator(ig, K32.range)\n",
    "K = BlockOperator(K11, K12, K21, -K22, K31, K32, shape=(3,2) )\n",
    "\n",
    "# Define BlockFunction f\n",
    "f2 = alpha_tgv * MixedL21Norm()\n",
    "f3 = beta_tgv * MixedL21Norm() \n",
    "f1 = L1Norm(b=noisy_data)\n",
    "\n",
    "F = BlockFunction(f1, f2, f3) \n",
    "\n",
    "# Setup and run the PDHG algorithm\n",
    "pdhg_tgv = PDHG(f=F,g=G,operator=K,\n",
    "            max_iteration = 2000,\n",
    "            update_objective_interval = 200)\n",
    "pdhg_tgv.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315cddb-421c-4418-a853-dbc3d8ec92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data, pdhg_tv.solution, (pdhg_tv.solution-data).abs()*3,\n",
    "          noisy_data, pdhg_tgv.solution[0], (pdhg_tgv.solution[0]-data).abs()*3],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"TV inpainting/denoising\", \" |Ground Truth - TV|\", \n",
    "            \"Corrupted Image\", \"TGV inpainting/denoising\", \" |Ground Truth - TGV|\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 3),\n",
    "                axes_pad=0.8,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.3\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "        \n",
    "    img = ax.imshow(images[0][k].as_array())\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654766e-e981-43da-9e66-2d542bc2b3af",
   "metadata": {},
   "source": [
    "<h1><center>Conclusions</center></h1>\n",
    "\n",
    "In this notebook, we presented how to reconstruct multichannel data with 3 channels, using two different regularisers and data fitting terms. The following notebooks will demonstrate how to reconstruct multichannel data for CT and MRI applications:\n",
    "\n",
    "* **Dynamic CT**: Channels contain temporal information from the acquisition data.\n",
    "* **Hypespectral CT**: Channels contain spectral energy information acquired from an energy-sensitive X-ray detector.\n",
    "* **Sequence MRI**: Channels contain information from two MR images with different contrast.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}