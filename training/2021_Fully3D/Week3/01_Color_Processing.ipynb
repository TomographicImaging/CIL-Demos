{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea913dd3-0a71-4469-b258-d5585ef6f1b0",
   "metadata": {},
   "source": [
    "<h1><center>Color Processing </center></h1>\n",
    "\n",
    "In this notebook, we present how to denoise and inpaint our first **multichannel** data using CIL, i.e., a data with only 3 channels that contains information from the **Red**, **Green** and **Blue** bands.\n",
    "\n",
    "We will consider the cases of \n",
    "\n",
    "* denoising a noisy image corrupted by Gaussian noise,\n",
    "* inpainting + denoising a noisy image corrupted by Salt \\& Pepper noise with missing text information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593afeb-fa7e-4e59-9a27-398c59cac1d3",
   "metadata": {},
   "source": [
    "<h1><center>Total variation Denoising </center></h1>\n",
    "\n",
    "We recall that the definition of the (isotropic) Total Variation, used for gray-valued images, is\n",
    "\n",
    "$$\n",
    "\\mathrm{TV}(u) = \\|Du\\|_{2,1} = \\sum_{i,j}^{M,N}\\big(|(D_{y}u, D_{x}u)|_{2}\\big)_{i,j} =  \\sum_{i,j}^{M,N} \\big(\\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big)_{i,j}.\n",
    "$$\n",
    "\n",
    "This can be extended for vector-valued images which results to a **vectorial** formulation of the total variation. The gradient for the **RGB** case is now $Du=(Du_{1}, Du_{2}, Du_{3})$, where for each channel $k=1,2,3$, $Du_{k}:=(D_{y}u_{k}, D_{x}u_{k})$. \n",
    "\n",
    "For this type of multichannel data, we can create different configurations on how the **color channels**, the **derivatives** and the **image pixels** are correlated and under which norm. One generic approach for this regulariser is presented in [Duran et al](https://arxiv.org/pdf/1508.01308.pdf#page=8), where the **Collaborative Total variation** is introduced, i.e.,\n",
    "\n",
    "$$\n",
    "\\|A\\|_{p,q,r} := \\bigg(\\sum_{i=1}^{N}\\quad\\bigg(\\sum_{j=1}^{M}\\quad\\bigg(\\sum_{k=1}^{C} |A_{i,j,k}|^{p}\\bigg)^{\\frac{q}{p}}\\quad\\bigg)^{\\frac{r}{q}}\\quad\\bigg)^{\\frac{1}{r}}\\quad .\n",
    "$$\n",
    "\n",
    "For simplicity, in this notebook, we will use a _Channelwise TV_ definition, namely, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{VTV}(u)  := \\|D u\\|_{2,1}  = \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} (|Du_{k}|_{2})_{i,j} = \n",
    "                 \\sum_{k=1}^{3}\\sum_{i,j=1}^{M,N} \\big( \\sqrt{ (D_{y}u_{k})^{2} + (D_{x}u_{k})^{2}}\\big) = \\sum_{k=1}^{3} \\mathrm{TV}(u_{k}).\n",
    "\\label{tv_color}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The above definition corresponds to the $\\ell_{2,1,1}$ (derivative, pixels, color) Collaborative TV. This means that, an $\\ell_{2}$ norm is applied for the **derivatives**, followed by an $\\ell_{1}$ norm for the **pixels** of the image and a final $\\ell_{1}$ norm for the three **channels**.\n",
    "\n",
    "For data $b$ corrupted with Gaussian noise, the minimisation problem is now:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} = \\underset{u}{\\operatorname{argmin}}  \\frac{1}{2}\\| b - u \\|^{2}_{2} + \\alpha\\,\\mathrm{VTV}(u)\n",
    "\\label{ROF}\n",
    "\\end{equation}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0116bd-1a4a-40f6-abb8-01b579a6b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cil.optimisation.functions import TotalVariation\n",
    "from cil.utilities import dataexample, noise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a95262-f4f3-47b6-ae83-dcfb1de2940f",
   "metadata": {},
   "source": [
    "## Load data and corrupt with gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474bccc-8bf1-4372-963e-99157db12eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rainbow data\n",
    "data = dataexample.RAINBOW.get(size=(500,500), scale=(0,1))\n",
    "data.reorder(['horizontal_y', 'horizontal_x','channel'])\n",
    "\n",
    "noisy_data = noise.gaussian(data, seed = 10, var = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0c7fb-e267-4af3-805d-183009c48151",
   "metadata": {},
   "source": [
    "We solve tha above minimisation problem using the `proximal` method of the `TotalVariation` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcc134-d735-48ac-af4c-59146c5dda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "TV = alpha * TotalVariation(max_iteration=500)\n",
    "proxTV = TV.proximal(noisy_data, tau=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be6f18-f4b8-4c25-8c61-be4195d90ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data.as_array(), noisy_data.as_array(), proxTV.as_array()],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"Noisy Data\", \"TV denoising\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(1, 3),\n",
    "                axes_pad=0.1,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.4\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "    \n",
    "    \n",
    "    img = ax.imshow(images[0][k])\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4e640",
   "metadata": {},
   "source": [
    "## Exercise : Use the PDHG algorithm to solve the above problem\n",
    "\n",
    "The triplet $(K, \\mathcal{F}, \\mathcal{G})$ is defined as:\n",
    "\n",
    "* $K = \\nabla$,\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{F}(z) = \\alpha\\,\\|z\\|_{2,1}$,\n",
    "\n",
    "\n",
    "\n",
    "* $\\mathcal{G}(u) = \\frac{1}{2}\\|b - u \\|^{2}_{2}\\, .$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89675e-daac-44bf-a8d2-bdefa51be010",
   "metadata": {},
   "source": [
    "<h1><center>Total Generalised Variation Inpainting </center></h1>\n",
    "\n",
    "Given an image where a specific region is unknown, the task of image inpainting is to recover the missing region $\\mathcal{D}$ from the known part of the image $\\Omega$. For this experiment, we replace the Total variation term, with a higher-order regulariser, namely the **Total Generalised Variation (TGV)** introduced in [Bredies et al](https://epubs.siam.org/doi/abs/10.1137/090769521?mobileUi=0). This regulariser is able to obtain piecewise smooth solutions and restore staircasing artifacts that TV promotes.\n",
    "\n",
    "We let $\\alpha, \\beta>0$ be regularisation parameters and define\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{TGV}_{\\alpha, \\beta}(u) = \\min_{w} \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\label{TGV}\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\mathcal{E}$ denotes the **Symmetrised Gradient** operator defined as \n",
    "\n",
    "$$\n",
    "\\mathcal{E}w = \\frac{1}{2}(D w + D w^{T}).\n",
    "$$\n",
    "\n",
    "The minimisation problem under the TGV regulariser and the $L^{1}$ norm as a data fidelity term, which is suitable for salt & pepper noise, is the following:\n",
    "\n",
    "<a id='TGV_L1'></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} & \\|\\mathcal{M}u-b\\|_{1} + \\mathrm{TGV}_{\\alpha, \\beta}(u) \\Leftrightarrow \\\\\n",
    "(u^{*},w^{*}) =\\underset{u, w}{\\operatorname{argmin}} &  \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{TGV_L1_inpainting}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the $\\mathcal{M}$ is a diagonal operator with 1 in the diagonal elements corresponding to pixels in $\\Omega\\setminus\\mathcal{D}$ and 0 in $\\mathcal{D}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788da08-56bb-4d6c-9af7-ec2889782612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cil.framework import ImageGeometry\n",
    "from cil.optimisation.operators import MaskOperator, BlockOperator, SymmetrisedGradientOperator, \\\n",
    "                                GradientOperator, ZeroOperator, IdentityOperator, ChannelwiseOperator\n",
    "\n",
    "from cil.optimisation.functions import ZeroFunction, L1Norm, MixedL21Norm, BlockFunction\n",
    "from cil.optimisation.algorithms import PDHG\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cded67-0acf-42f3-ba31-81ac860fe5c0",
   "metadata": {},
   "source": [
    "## Create corrupted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca464c1c-1509-4d88-a123-0832e1cca07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = data.array\n",
    "ig = data.geometry\n",
    "\n",
    "# Add text to the image\n",
    "tmp = Image.fromarray(np.uint8(im*255)).convert('RGB')\n",
    "text = \"\\n This is a double rainbow.  Remove the text using the Core Imaging Library.\\n\"*15\n",
    "draw = ImageDraw.Draw(tmp)\n",
    "font = ImageFont.truetype('FreeSerifBold.ttf', 13)\n",
    "draw.text((0, 0), text, (0, 0, 0), font=font)\n",
    "\n",
    "# Create an ImageData\n",
    "im1 = np.array(tmp)\n",
    "im1 = im1/im1.max()\n",
    "ig1 = ig.copy()\n",
    "data1 = ig1.allocate()\n",
    "data1.fill(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca7e70-9f11-4bd6-8ba9-8b6e8f2146c3",
   "metadata": {},
   "source": [
    "## Create the $\\mathcal{D}$ mask and apply the MaskOperator channelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02d96c-de71-49a0-b9fd-502c2db450c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask that contains only text information\n",
    "tmp_mask_array = np.abs(im1 - im)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(tmp_mask_array)\n",
    "plt.show()\n",
    "\n",
    "tmp = (data1-data).abs()==0\n",
    "mask2D = tmp[:,:,0]\n",
    "\n",
    "# Apply MaskOperator for all the 3 channels: red, green, blue\n",
    "mask = ig.subset(channel=0).allocate(True,dtype=np.bool)\n",
    "mask.fill(mask2D)\n",
    "MO = ChannelwiseOperator(MaskOperator(mask), 3, dimension = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0d4eb-4f6f-4f96-a149-1fb38273862c",
   "metadata": {},
   "source": [
    "## Add salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31767b39-c648-4984-a66e-351ebb250c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = noise.saltnpepper(data1, amount=0.03, seed = 10)\n",
    "noisy_data = MO.direct(noisy_data) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(noisy_data.as_array())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c763b-079e-4354-9504-d0c03dcea8b1",
   "metadata": {},
   "source": [
    "## Setup PDHG for TGV regularisation\n",
    "\n",
    "We solve the above problem using the `PDGH` algorithm. Recall, that we need to define the triplet ($K$,  $\\mathcal{F}$, $\\mathcal{G}$) and write the above problem into the following form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{*} =\\underset{u}{\\operatorname{argmin}} \\mathcal{F}(Ku) + \\mathcal{G}(u).\n",
    "\\label{general_form}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let $\\textbf{u} = (u, w)\\in \\mathbb{X}$ and define an operator $K:\\mathbb{X}\\rightarrow\\mathbb{Y}$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M} & \\mathcal{O}\\\\\n",
    "D & -\\mathcal{I}\\\\\n",
    "\\mathcal{O} & \\mathcal{E}\n",
    "\\end{bmatrix} \\quad\\Rightarrow\\quad\n",
    "K\\textbf{u} = \n",
    "K \\begin{bmatrix}\n",
    "u\\\\\n",
    "w\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix} = \\textbf{y}\\in \\mathbb{Y},\n",
    "\\label{def_K}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{O}$, $\\mathcal{I}$ denote the zero and identity operators respectively.\n",
    "\n",
    "For the function $\\mathcal{F}$, we have that\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\mathcal{F}(\\textbf{y})  := \\mathcal{F}(y_{1}, y_{2}, y_{3}) = f_{1}(y_{1}) +  f_{2}(y_{2})  +  f_{3}(y_{3}), \\mbox{ where},\\\\\n",
    "& f_{1}(y_{1}) :=  \\| y_{1} - b\\|_1,\\, f_{2}(y_{2}) :=  \\alpha \\|y_{2}\\|_{2,1},\\, f_{3}(y_{3}) := \\beta\\|y_{3}\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\label{def_f}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "and for the function $\\mathcal{G}$, $\\mathcal{G}(\\textbf{u}) = \\mathcal{G}(u,w) = O(u)\\equiv 0 $ is the zero function. \n",
    "\n",
    "We conclude that\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "f(K\\textbf{u}) + g(\\textbf{u}) & = f\\bigg(\\begin{bmatrix}\n",
    "\\mathcal{M}u\\\\\n",
    "Du - w\\\\\n",
    "\\mathcal{E}w\n",
    "\\end{bmatrix}\\bigg)  = f_{1}(\\mathcal{M}u) + f_{2}(Du-w) + f_{3}(\\mathcal{E}w) \\\\\n",
    "& = \\|\\mathcal{M}u -b\\|_{1} + \\alpha \\|D u - w \\|_{2,1} + \\beta\\|\\mathcal{E}w\\|_{2,1},\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which is exactly the objective function in [TGV_L1](#TGV_L1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceeed7-56f4-4905-9243-fa86ef67a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisation parameters\n",
    "alpha = 0.6\n",
    "beta = 0.2\n",
    "\n",
    "# Define BlockFunction f\n",
    "f2 = alpha * MixedL21Norm()\n",
    "f3 = beta * MixedL21Norm() \n",
    "f1 = L1Norm(b=noisy_data)\n",
    "F = BlockFunction(f1, f2, f3)         \n",
    "\n",
    "# Define function g \n",
    "G = ZeroFunction()\n",
    "\n",
    "# Define BlockOperator K\n",
    "K11 = MO\n",
    "K21 = GradientOperator(ig)\n",
    "K32 = SymmetrisedGradientOperator(K21.range)\n",
    "K12 = ZeroOperator(K32.domain, ig)\n",
    "K22 = IdentityOperator(K21.range)\n",
    "K31 = ZeroOperator(ig, K32.range)\n",
    "K = BlockOperator(K11, K12, K21, -K22, K31, K32, shape=(3,2) )\n",
    "\n",
    "normK = K.norm()\n",
    "eta = 5\n",
    "sigma = (1./normK)*eta\n",
    "tau = (1./normK)/eta\n",
    "\n",
    "# Setup and run the PDHG algorithm\n",
    "pdhg = PDHG(f=F,g=G,operator=K,\n",
    "            max_iteration = 500, sigma=sigma, tau=tau,\n",
    "            update_objective_interval = 100)\n",
    "pdhg.run(500,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315cddb-421c-4418-a853-dbc3d8ec92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data, noisy_data, \\\n",
    "          pdhg.solution[0], (pdhg.solution[0]-data).abs()],  \n",
    "                             \n",
    "labels_x = [\"Ground Truth\", \"Noisy Data\", \"TGV inpainting/denoising\", \"Absolute difference\"]\n",
    "\n",
    "# set fontszie xticks/yticks\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(2, 2),\n",
    "                axes_pad=0.8,\n",
    "                cbar_mode='single',\n",
    "                cbar_location='bottom',\n",
    "                cbar_size = 0.5,\n",
    "                cbar_pad=0.3\n",
    "                )\n",
    "\n",
    "k = 0\n",
    "for ax in grid:\n",
    "        \n",
    "    img = ax.imshow(images[0][k].as_array())\n",
    "    ax.set_title(labels_x[k],fontsize=25)\n",
    "    k+=1\n",
    "    \n",
    "cbar = ax.cax.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654766e-e981-43da-9e66-2d542bc2b3af",
   "metadata": {},
   "source": [
    "<h1><center>Conclusions</center></h1>\n",
    "\n",
    "In this notebook, we presented how to reconstruct multichannel data with 3 channels, using two different regularisers and data fitting terms. The following notebooks will demonstrate how to reconstruct multichannel data for tomography applications:\n",
    "\n",
    "* **Dynamic CT**: Channels contain temporal information from the acquisition data.\n",
    "* **Hypespectral CT**: Channels contain spectral energy information acquired from an energy-sensitive X-ray detector.\n",
    "* **Sequence MRI**: Channels contain information from two MR images with different contrast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16429afd-4abb-44c2-b1ae-259f56464e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
