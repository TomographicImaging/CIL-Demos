{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.framework import AcquisitionGeometry, AcquisitionData\n",
    "\n",
    "from cil.optimisation.algorithms import FISTA\n",
    "from cil.optimisation.functions import ZeroFunction, LeastSquares\n",
    "\n",
    "from cil.io import TIFFStackReader\n",
    "\n",
    "from cil.processors import TransmissionAbsorptionConverter, Binner, Normaliser\n",
    "\n",
    "from cil.plugins.astra import ProjectionOperator, FBP\n",
    "\n",
    "from cil.plugins.ccpi_regularisation.functions import FGP_TV\n",
    "\n",
    "from cil.utilities.display import show2D, show_geometry\n",
    "from cil.utilities.jupyter import islicer, link_islicer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lamniography reconstruction with TV regularisation using FISTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise uses CIL to reconstruct a Laminography dataset - that is a dataset with a tilted rotation axis. \n",
    "\n",
    "Laminography scanning is commonly used for large thin samples like circuit boards. In conventional CT these samples lead to widely varying path-lengths as the sample rotates. By tilting the sample and rotating it around a vector perpendicular to the sample plane the path-lengths stay relatively constant. However, this geometry leads to some artefacts in the reconstruction from the missing data. These artefacts are particularly prevelant when you look at a slice out of the sample plane.\n",
    "\n",
    "By using regularisation, we can supress these artefacts. This notebook compares FDK, a least-squares with FISTA and Total-Variation with FISTA on a Lego phantom.\n",
    "\n",
    "**Learning objectives:**\n",
    "\n",
    "1. Construct an advanced AcquistionGeometry by-hand to describe the tilted and offset data\n",
    "\n",
    "2. Use this geometry to read in a tiff stack and create an AcquisitionData object\n",
    "\n",
    "3. Create a custom ImageGeometry around the thin-flat sample\n",
    "\n",
    "4. Reconstruct the data with LS and TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example requires data from https://zenodo.org/record/2540509\n",
    "\n",
    "https://zenodo.org/record/2540509/files/CLProjectionData.zip\n",
    "\n",
    "https://zenodo.org/record/2540509/files/CLShadingCorrection.zip\n",
    "\n",
    "Once downloaded update `path_common` to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the directory containing the data\n",
    "path_common = '/mnt/materials/SIRF/Fully3D/CIL/Laminography'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the acquisition geometry\n",
    "\n",
    "We know the system parameters from the paper and author clarification. We use this to set up a 3D cone-beam geometry with the rotation axis tilited 30&deg towards the source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#parameters are from the original paper/author clarification\n",
    "src_to_det = 967.3209839\n",
    "src_to_object = 295\n",
    "tilt = 30. * np.pi / 180.\n",
    "centre_of_rotation = 0.254 * 6.\n",
    "\n",
    "mag = src_to_det / src_to_object \n",
    "object_offset_x = centre_of_rotation / mag\n",
    "\n",
    "source_pos_y = -src_to_object\n",
    "detector_pos_y = src_to_det-src_to_object\n",
    "angles_list = -np.linspace(0, 360, 2513, endpoint=False)\n",
    "num_pixels_x = 1596\n",
    "num_pixels_y = 1148\n",
    "pixel_size_xy = 0.254\n",
    "\n",
    "\n",
    "ag = AcquisitionGeometry.create_Cone3D( source_position=[0.0, source_pos_y,0.0], \\\n",
    "                                        detector_position=[0.0, detector_pos_y,0.0],\\\n",
    "                                        rotation_axis_position=[object_offset_x,0,0],\\\n",
    "                                        rotation_axis_direction=[0,-np.sin(tilt), np.cos(tilt)] ) \\\n",
    "                        .set_angles(angles=angles_list, angle_unit='degree')\\\n",
    "                        .set_panel( num_pixels=[num_pixels_x, num_pixels_y], \\\n",
    "                                    pixel_size=pixel_size_xy,\\\n",
    "                                    origin='top-left')\\\n",
    "                        .set_labels(['angle','vertical','horizontal'])\n",
    "print(ag)\n",
    "show_geometry(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data\n",
    "We will start by reading in data from a stack of tiffs. As we read in the data we will symmetrically crop and down-sample the data. We will remove a 100 pixel border from each projection, and we will only read in every 7 projections. This significantly reduces the computational time and memory cost without a loss of reconstruction quality.\n",
    "\n",
    "As we are reading in a stack of tiffs we know that 'axis_0' is the angle, 'axis_1' is vertical and 'axis_2' is the horizontal. We want to crop in the horizontal and vertical directions, and slice the angles direction. We create a region of interest (RoI) dictionary with the axis name, and a tuple containing the starting pixel index, the end pixel index and the step size to slice.\n",
    "\n",
    "We also need to update the geometry to account for the new panel size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = 100\n",
    "\n",
    "roi = {'axis_0': (None, None, 7),\n",
    "       'axis_1': (crop, -crop, None), \n",
    "       'axis_2': (crop, -crop, None)}\n",
    "\n",
    "num_pixels_x = (1596 -2*crop)\n",
    "num_pixels_y = (1148 -2*crop)\n",
    "pixel_size_xy = 0.254\n",
    "\n",
    "angles_list = -np.linspace(0, 360, int(2513/7), endpoint=False)\n",
    "\n",
    "ag.set_angles(angles_list)\n",
    "ag.set_panel(num_pixels=[num_pixels_x,num_pixels_y],pixel_size=pixel_size_xy,origin='top-left')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `cil.io` we import and create a `TIFFStackReader` instance to read in the data, this is created with the directory path and the RoI dictionary defined above.\n",
    "\n",
    "As we have already defined our acquisition geometry we can use the function `read_as_AcquisitionData()` to pass this to the reader. The reader will use this to configure and return an `AcquisitionData` object containing the data and the geometry describing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Lego_Lamino30deg_XTH/'\n",
    "\n",
    "reader = TIFFStackReader(file_name=os.path.join(path_common, path),roi=roi, mode = 'slice')\n",
    "acq_data_raw = reader.read_as_AcquisitionData(ag)\n",
    "\n",
    "islicer(acq_data_raw, direction='angle',origin='upper-left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in the dark and flat field images and use these to normalise the data. We need to crop these tiffs with the same RoI as previously. We now can use use `read()` here to simply read in the tiffs and return a numpy array which we delete after applying to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiffs = [   os.path.join(path_common,'Lego_Lamino30deg_ShadingCorrection_XTH/Dark_80kV85uA.tif'),\n",
    "            os.path.join(path_common,'Lego_Lamino30deg_ShadingCorrection_XTH/Flat_80kV85uA.tif') ]\n",
    "\n",
    "roi = {'axis_0': (None, None, None),\n",
    "       'axis_1': (crop, -crop, None), \n",
    "       'axis_2': (crop, -crop, None)}\n",
    "\n",
    "reader = TIFFStackReader(file_name=tiffs, roi=roi)\n",
    "dark_flat_data = reader.read()\n",
    "\n",
    "normaliser = Normaliser(dark_flat_data[1], dark_flat_data[0])\n",
    "acq_data_SC = normaliser(acq_data_raw)\n",
    "\n",
    "islicer(acq_data_SC, direction='angle',origin='upper-left')\n",
    "\n",
    "del acq_data_raw\n",
    "del dark_flat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we convert the intensity data to attenuation data using the Beer-Lambert law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converter = TransmissionAbsorptionConverter()\n",
    "acq_data_atten = converter(acq_data_SC)\n",
    "islicer(acq_data_atten, direction='angle',origin='upper-left')\n",
    "\n",
    "del acq_data_SC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this notebook over 4x binned data for speed. The iterative reconstructions will take approximately 5 minutes at this binning.\n",
    "\n",
    "We use CIL's Binner processor to average together every 4 pixels in the horizontal and vertical directions.\n",
    "\n",
    "We define the RoI using the same syntax as previously, however now we set out start and stop indices to `None` as we want to include the full width of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the data for speed \n",
    "binning = 4\n",
    "\n",
    "roi = {'horizontal': (None, None, binning),\n",
    "       'vertical': (None, None, binning)}\n",
    "acq_data_binned = Binner(roi=roi)(acq_data_atten)\n",
    "\n",
    "#note the number of pixels and pixel size is updated for you\n",
    "print(acq_data_binned.geometry)\n",
    "\n",
    "islicer(acq_data_binned,direction='angle',origin='upper-left')\n",
    "del acq_data_atten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the data using FDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using the ASTRA backend we need to reorder the data for use by ASTRA. If we were using TIGRE as the backend we could use `data.reorder('tigre')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_data = acq_data_binned\n",
    "acq_data.reorder('astra')\n",
    "ag = acq_data.geometry\n",
    "print(ag.dimension_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use FDK to reconstruct the data. If we use the default `ImageGeomerty` then we will end up reconstructing a lot of empty space which becomes costly over many iterations. If we collapse the data along the Z and Y axes we can clearly identify a reconstruction window around the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_default = ag.get_ImageGeometry()\n",
    "fbp = FBP(ig_default, ag)\n",
    "FDK_reco = fbp(acq_data)\n",
    "show2D([FDK_reco.max(axis=0),FDK_reco.max(axis=1)],title=['x-y plane','x-z plane'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the fast FDK reconstruction to modify this reconstruction window to remove as much of the empty space as possible, whilst keeping every voxel that will contain the object. Below we shrink and offset the window, but keep the voxel size as the pixel size scaled by magnification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ig = ag.get_ImageGeometry()\n",
    "ig.voxel_num_z=130\n",
    "ig.voxel_num_y=240\n",
    "ig.voxel_num_x=310\n",
    "\n",
    "ig.center_x=15*ig.voxel_size_x\n",
    "ig.center_z=-10*ig.voxel_size_z\n",
    "\n",
    "fbp = FBP(ig, ag)\n",
    "FDK_reco = fbp(acq_data)\n",
    "\n",
    "show2D([FDK_reco.max(axis=0),FDK_reco.max(axis=1)],title=['x-y plane','x-z plane'])\n",
    "show_geometry(ag,ig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some slices from the FDK reconstruction are shown below. Along the `vertical` direction (x-y plane) we can see some ghosting of the object in the nearest layer. If we slice instead along the `horizontal_x` and `horizontal_y` directions we can clearly see missing data wedge artefacts which cause this this ghosting. This is usual for laminography datasets and the reconstructions are often analysed only in 2D slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list=[('vertical',76),('vertical',55),('horizontal_x',155),('horizontal_y',138)]\n",
    "show2D(FDK_reco,slice_list=slice_list, title=\"FDK reconstruction\", fix_range=(-0.02,0.07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the data using Least Squares with FISTA\n",
    "\n",
    "Using our ImageGeometry (ig) and AcquisitionGeometry (ag) we define our projector and a data-fidelity LeastSquares term.\n",
    "\n",
    "We can use FISTA to iteratively solve this reconstruction. As there is no regularisation term we will stop at 100 iterations and observe a similar reconstruction to that obtained by FDK. This example will take approximatly 1 minute to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Projector = ProjectionOperator(ig, ag)\n",
    "LS = LeastSquares(A=Projector, b=acq_data)\n",
    "fista_LS = FISTA(initial=FDK_reco, f=LS, g=ZeroFunction(), max_iteration=1000, update_objective_interval=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_LS.run(100)\n",
    "LS_reco = fista_LS.get_output()\n",
    "show2D(LS_reco,slice_list=slice_list, title=\"LS reconstruction\", fix_range=(-0.02,0.07))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the data using Total Variation regularised Least Squares with FISTA\n",
    "\n",
    "We reuse the LeastSquares function, but now we also can define a Total-Variation function. In this example we use FGP_TV from the CCPi-RegularisationToolkit with the `gpu` backend.\n",
    "\n",
    "We also can add a non-negativity constraint to the function.\n",
    "\n",
    "Again, we set up and use FISTA to iteratively solve this reconstruction. We run this until the background appears uniform suggesting TV has converged.\n",
    "\n",
    "For this example we will run 100 iterations, which will take approximately 3 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "TV = FGP_TV(alpha=alpha, nonnegativity=True, device='gpu',)\n",
    "fista_TV = FISTA(initial=FDK_reco, f=LS, g=TV, max_iteration=1000, update_objective_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_TV.run(100)\n",
    "TV_reco = fista_TV.get_output()\n",
    "show2D(TV_reco,slice_list=slice_list, title=\"TV reconstruction\", fix_range=(-0.02,0.07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the results\n",
    "\n",
    "We can compare the results of the three reconstructions. Using Total-Variation we have supressed the missing data artefacts and the ghosting, which would allow us to perform a cleaner segmentation of this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in slice_list:\n",
    "    show2D([FDK_reco,LS_reco,TV_reco],slice_list=slice, title=['FDK','LS','TV'], fix_range=(-0.02,0.07),num_cols=3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b02c58cf1d50ca3ecf8d994a115db1c36867e9b4bbac4652683be1266bef7975"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
