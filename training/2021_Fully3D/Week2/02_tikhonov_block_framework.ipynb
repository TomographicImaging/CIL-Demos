{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#   This work is part of the Core Imaging Library (CIL) developed by CCPi \n",
    "#   (Collaborative Computational Project in Tomographic Imaging), with \n",
    "#   substantial contributions by UKRI-STFC and University of Manchester.\n",
    "\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "#   Copyright 2019 UKRI-STFC, The University of Manchester, Technical University of Denmark\n",
    "#   Authored by:    Jakob S. JÃ¸rgensen (DTU)\n",
    "#                   Gemma Fardell (UKRI-STFC)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tikhonov regularisation using CGLS and block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise introduces Tikhonov regularisation and explains how this is implemented in the CIL framework using the so-called block framework.\n",
    "\n",
    "In a previous exercise, it was seen how CGLS could be used to determine a reconstruction based on the least squares reconstruction problem. It was seen that in case of noisy data, the least squares solution obtained by running until convergence is not desirable due to a high amount of noise. The number of iterations was seen to have a regularising effect, with the smooth, low-frequency components of the image recovered in the first iterations, while high-frequency components of the image such as edges were recovered later. Unfortunately, noise also kicks in, and one needs to pick the number of iterations that best balances the sharpness and amount of noise. As such, the regularising effect is implicitly obtained by choosing the number of iterations to run and never actually running until converged to the least squares solution.\n",
    "\n",
    "Tikhonov regularisation is more explicit in that a regularisation term is added to the least squares fitting term, specifically a squared 2-norm. This problem should now be solved to convergence instead of using the number of iterations as implicit regularising effect. Instead, a parameter, the regularisation parameter, balances the emphasis on fitting the data and enforcing the regularity and must be chosen to provide the best trade-off.\n",
    "\n",
    "Tikhonov regularisation tends to offer reduction of noise in the reconstruction, at the price of some blurring. This will be seen in what follows.\n",
    "\n",
    "To set up Tikhonov problems we need to represent block matrices and concatenate data. In CIL we can do this using BlockOperator and BlockDataContainer as demonstrated in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Learning objectives:**\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularisation parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all imports required are carried out. This includes tools from the cil.framework and cil.optimisation modules, as well as test image generation tools in the tomophantom library and standard imports such as numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# CIL core components needed\n",
    "from cil.framework import ImageGeometry, ImageData, AcquisitionGeometry, AcquisitionData, BlockDataContainer\n",
    "\n",
    "# CIL optimisation algorithms and linear operators\n",
    "from cil.optimisation.algorithms import CGLS\n",
    "from cil.optimisation.operators import BlockOperator, GradientOperator, IdentityOperator, FiniteDifferenceOperator\n",
    "\n",
    "# CIL example synthetic test image\n",
    "from cil.utilities.dataexample import SHAPES\n",
    "\n",
    "# CIL display tools\n",
    "from cil.utilities.display import show2D, show_geometry\n",
    "\n",
    "# Forward/backprojector from CIL ASTRA plugin\n",
    "from cil.plugins.astra import ProjectionOperator\n",
    "\n",
    "# For shepp-logan test image in CIL tomophantom plugin\n",
    "import cil.plugins.TomoPhantom as TP\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting up a simulated 2D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D parallel beam case will be simulated. We start by creating a test image and will use the classic Shepp-Logan Phantom with 1024x1024 pixels on the square domain [-1,1]x[-1,1]. We set up the `ImageGeometry` to specify the dimensions and pixel size of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up image geometry\n",
    "n = 256\n",
    "ig = ImageGeometry(voxel_num_x=n, \n",
    "                   voxel_num_y=n, \n",
    "                   voxel_size_x=2/n, \n",
    "                   voxel_size_y=2/n)\n",
    "print(ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the CIL tomophantom plugin we can create a CIL `ImageData` holding the Shepp-Logan image of the desired size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom2D = TP.get_ImageData(num_model=1, geometry=ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D(phantom2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the acquisition parameters and store them in an `AcquisitionGeometry` object. We use a parallel-beam geometry with 180 projections, and a detector with the same of number and size of pixels as the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_angles = 180\n",
    "ag = AcquisitionGeometry.create_Parallel2D()  \\\n",
    "                   .set_angles(np.linspace(0, 180, num_angles, endpoint=False))  \\\n",
    "                   .set_panel(n, 2/n)\n",
    "print(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate the geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_geometry(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a sinogram we set up a ProjectionOperator using GPU-acceleration using the ASTRA plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"gpu\"\n",
    "A = ProjectionOperator(ig, ag, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal noisefree sinogram is created by forward-projecting the phantom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinogram = A.direct(phantom2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated test image and sinogram are displayed as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [phantom2D, sinogram]\n",
    "titles = [\"Ground truth\", \"sinogram\"]\n",
    "show2D(plots, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_noise\"></a>\n",
    "Next, Poisson noise will be applied to this noise-free sinogram. The severity of the noise can be adjusted by changing the background_counts variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incident intensity: lower counts will increase the noise\n",
    "background_counts = 5000 \n",
    "\n",
    "# Convert the simulated absorption sinogram to transmission values using Lambert-Beer. \n",
    "# Use as mean for Poisson data generation.\n",
    "# Convert back to absorption sinogram.\n",
    "counts = background_counts * np.exp(-sinogram.as_array())\n",
    "noisy_counts = np.random.poisson(counts)\n",
    "sino_out = -np.log(noisy_counts/background_counts)\n",
    "\n",
    "# Create new AcquisitionData object with same geometry and fill with noisy data.\n",
    "sinogram_noisy = ag.allocate()\n",
    "sinogram_noisy.fill(sino_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated clean and noisy sinograms are displayed side by side as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [sinogram, sinogram_noisy]\n",
    "titles = [\"sinogram\", \"sinogram noisy\"]\n",
    "show2D(plots, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_simple\"></a>\n",
    "### Reconstruct using CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before describing Tikhonov regularisation, we recall the problem solved by CGLS:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b\\end{Vmatrix}^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be determined\n",
    "\n",
    "In the solution provided by CGLS the low frequency components tend to converge faster than the high frequency components. This means we need to control the number of iterations carefully to select the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Set up the CGLS algorithm, including specifying its initial point to start from, and an upper bound on the number of iterations to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_init = ig.allocate(0)\n",
    "cgls_simple = CGLS(x_init=x_init, operator=A, data=sinogram_noisy)\n",
    "cgls_simple.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once set up, we can run the algorithm for a specified number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgls_simple.run(5, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Display the resulting image from CGLS, along with its difference image with the original ground truth image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [cgls_simple.solution, cgls_simple.solution - phantom2D]\n",
    "titles = [\"CGLS reconstruction\",\"Difference from ground truth\" ]\n",
    "show2D(plots, titles, fix_range=[(-0.2,1.2),(-0.2,0.2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot central vertical line profile of CGLS and ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cgls_simple.solution.get_slice(horizontal_y=n/2).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(phantom2D.get_slice(horizontal_y=n/2).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 1:**</span> Try running fewer and more iterations to see how the image and line profile changes. Try also with noisier data, by specifying a smaller value of background_counts. Remember you can change the number of iterations to run between outputs. Also note that the algorithm will continue from the point it stopped and run more iterations from that point if `run` is called again. If you want to run from the beginning, the algorithm needs to be re-initialised. Try to stop the algorithm before the solution starts to diverge. [go to section start](#section_CGLS_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tikhonov regularisation using CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularisation\n",
    "\n",
    "Noisy datasets are problematic with an ill-posed problem such as tomographic reconstruction. If we try to solve these using CGLS we end up with an unstable solution. Regularisation adds information in order for us to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "We can add a regularisation term to problem solved by CGLS; this gives us the minimisation problem in the following form, which is known as Tikhonov regularisation:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b \\end{Vmatrix}^2_2 + \\alpha^2\\|Lu\\|^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be solved for\n",
    "\n",
    "- $\\alpha$ is the regularisation parameter\n",
    "\n",
    "- $L$ is a regularisation operator\n",
    "\n",
    "\n",
    "The first term measures the fidelity of the solution to the data. The second term meausures the fidelity to the prior knowledge we have imposed on the system, operator $L$. $\\alpha$ controls the trade-off between these terms. $L$ is often chosen to be a smoothing operator like the identity matrix, or a gradient operator **constrained to the squared L2-norm**.\n",
    "\n",
    "This can be re-written equivalently in the block matrix form:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha L} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha L}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "this can now be recognised as a least squares problem:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "and being a least squares problem, it can be solved using CGLS with $\\tilde{A}$ as operator and $\\tilde{b}$ as data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Introducing the block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can construct $\\tilde{A}$ and $\\tilde{b}$ using the BlockFramework in the CIL.\n",
    "\n",
    "$\\tilde{A}$ is a (column) BlockOperator of size 2x1 and can be set up by\n",
    "\n",
    "`BlockOperator(op0,op1)`\n",
    "\n",
    "The right hand side $\\tilde{b}$ is a BlockDataContainer and can be set up by\n",
    "\n",
    "`BlockDataContainer(DataContainer0, DataContainer1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_alpha\"></a>\n",
    "#### Reconstruct using CGLS and the identity operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest form of Tikhonov uses the identity matrix as the regularisation operator. We use an identity matrix as our regularisation operator we are penalising on the magnitude of the solution $u$, which will tend to reduce the pixel values of $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = IdentityOperator(ig)\n",
    "alpha = 0.1\n",
    "\n",
    "operator_block = BlockOperator(A, alpha*L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the formulation of Tikhonov as a least squares problem, we need to set up the right hand side vector $\\tilde{b}$ holding both the $b$ and a zero-filled `ImageData` of the right size, matching the range of the regularising operator. The operator allows us to query the geometry of its range and allocate a zero-filled `ImageData` of that geometry. We combine both into a `BlockDataContainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "zero_data = L.range.allocate(0)\n",
    "\n",
    "data_block = BlockDataContainer(sinogram_noisy, zero_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Run CGLS as before, but passing the BlockOperator and BlockDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the Block Operator and Block DataContainer\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_tikh = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikh.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_tikh.run(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Display results as images and plot central vertical line profile of the Tikhonov with Identity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [cgls_tikh.solution, cgls_tikh.solution - phantom2D]\n",
    "titles = [\"Tikhonov with Identity regularisation\",\"Difference from ground truth\" ]\n",
    "show2D(plots, titles, fix_range=[(-0.2,1.2),(-0.2,0.2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the reconstructions from CGLS and Tikhonov with identity regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [cgls_simple.solution, cgls_tikh.solution]\n",
    "titles = [\"CGLS\", \"Tikhonov with Identity regularisation\" ]\n",
    "show2D(plots, titles, fix_range=(-0.2,1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cgls_simple.solution.get_slice(horizontal_y=n/2).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(cgls_tikh.solution.get_slice(horizontal_y=n/2).as_array(),label=\"Tikhonov with Identity regularisation\",color='firebrick')\n",
    "plt.plot(phantom2D.get_slice(horizontal_y=n/2).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 2:**</span> Try running Tikhonov with a range of $\\alpha$ values from very small to very large, display reconstruction and line profile and describe the effect of $\\alpha$. Find the value of $\\alpha$ that gives you the best solution. Then change how much noise you add to the data by going back here: [set noise](#section_noise) and run through the notebook again. Try with `background_counts` set to 5000, 10000 and 1000 remember to find an appropriate value of alpha for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Tikhonov regularisation the problem should now be solved to convergence instead of using the number of iterations as implicit regularising effect. By increasing the regularisation parameter $\\alpha$ we balance the emphasis on fitting the data and enforcing the regularity. A low value of $\\alpha$ will give you the CGLS solution, a higher value will reduce the noise in the reconstruction but at the cost of some blurring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the BlockFramework to build a gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Tikhonov with the identity operator provided perhaps a bit of improvement compared to just CGLS, but there was still a lot of noise in the reconstruction and the pixel values had been reduced. Using the identity as regularising operator means that we penalise pixel values that are non-zero, which may not be what we want. Instead, we want to encourage similar values of neighboring pixels to smooth out the noise. This can be achieved by using the gradient as the smoothing operator. \n",
    "\n",
    "To do that we will again need to use the BlockFramework, which is now demonstrated in a bit more detail.\n",
    "\n",
    "A discrete gradient operator (using finite differences) can be constructed using BlockOperators.\n",
    "\n",
    "The direct gradient operator $\\nabla$ acts on an image $u$ and returns a BlockDataContainer $\\textbf{w}$, holding finite differences in the $x$ and $y$ directions:\n",
    "\n",
    "$$ \\nabla(u) = \n",
    "\\begin{bmatrix}\n",
    "   \\nabla_x\\\\\n",
    "   \\nabla_y\\\\\n",
    "\\end{bmatrix}\n",
    "*u =\n",
    "\\begin{bmatrix}\n",
    "    \\nabla_xu\\\\\n",
    "    \\nabla_yu\\\\\n",
    "\\end{bmatrix}\n",
    "=  \n",
    "\\begin{bmatrix}w_{x}\\\\w_{y}\\end{bmatrix}= \\textbf{w}$$\n",
    "\n",
    "The adjoint gradient operator $\\nabla^*$ acts on the BlockDataContainer $\\textbf{y}$ and returns an image $\\rho$\n",
    "\n",
    "$$  \\nabla^*(\\textbf w) = \n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x &\n",
    "    \\nabla^*_y\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "    w_{x}\\\\\n",
    "    w_{y}\\\\\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x w_x + \\nabla^*_y w_y\n",
    "\\end{bmatrix} =  \\rho$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a test image to demonstrate how the gradient operator works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "shapes = SHAPES.get()\n",
    "show2D(shapes, \"shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite difference operator can be called from the framework. This returns the difference between each pair of pixels along one direction.\n",
    "\n",
    "We need to initialise it with the image geometry, the direction of the calculation and the boundary conditions to use.\n",
    "\n",
    "`FiniteDifferenceOperator(gm_domain, direction, bnd_cond='Neumann' or 'Periodic')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the operator FiniteDiff - needs to image geometry, the direction and the boundary conditions\n",
    "fdx = FiniteDifferenceOperator(shapes.geometry, direction='horizontal_x', bnd_cond='Neumann')\n",
    "\n",
    "#run it over the input image\n",
    "image_2D_dx = fdx.direct(shapes)\n",
    "\n",
    "#plot ths results\n",
    "show2D(image_2D_dx, \"dx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how all vertical edges have been picked up (and their sign) applying this operator doing finite differences in the horizontal direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up a gradient in both $x$ and $y$ directions, we can create a BlockOperator to contain a finite difference operator for each of the $x$ and $y$ directions. We can apply it (using its `direct` method) to the test image and visualise the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the x and y operators \n",
    "fdx = FiniteDifferenceOperator(shapes.geometry, direction='horizontal_x', bnd_cond='Neumann')\n",
    "fdy = FiniteDifferenceOperator(shapes.geometry, direction='horizontal_y', bnd_cond='Neumann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the BlockOperator combining the two operators\n",
    "FD = BlockOperator(fdx, fdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run it on the test image\n",
    "fd_out = FD.direct(shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [fd_out.get_item(0), fd_out.get_item(1)]\n",
    "titles = [\"dx\",\"dy\" ]\n",
    "show2D(plots,titles,fix_range=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what is going on, we take a closer look at data types.\n",
    "\n",
    "First, the input is an `ImageData` and its shape is a 2-element vector with the number of pixels in each direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(shapes))\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output however is a `BlockDataContainer`, essentially a list (with additional functionality) holding two `ImageData` elements, one for each direction we have taken finite differences. We can pick out each element of the `BlockDataContainer` and see that they indeed are `ImageData` and print their shapes (number of pixels in each direction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#output is BloackDataContainer\n",
    "print(type(fd_out))\n",
    "print(fd_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\tDataContainer 0\")\n",
    "print(type(fd_out.get_item(0)))\n",
    "print(fd_out.get_item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\tDataContainer 1\")\n",
    "print(type(fd_out.get_item(1)))\n",
    "print(fd_out.get_item(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BlockFramework provides basic algebra between BlockDataContainers, numpy arrays, lists of numbers,  DataContainers, subclasses and scalars providing the shape of the containers are compatible\n",
    "- add\n",
    "- subtract\n",
    "- multiply\n",
    "- divide\n",
    "- power\n",
    "- squared_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BlockOperator` is a special kind of `Operator`, and being an `Operator` it should have an adjoint method. This is automatically provided from the adjoints of the operators. In the present case our `BlockOperator` will take a `BlockDataContainer` as input to its adjoint and return an `ImageData`, as visualised below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Run the adjoint method\n",
    "adjoint_output = FD.adjoint(fd_out)\n",
    "\n",
    "show2D(adjoint_output, \"adjoint gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper look at the BlockFramework\n",
    "#### BlockDataContainer \n",
    "\n",
    "BlockDataContainer holds datacontainers as a column vector\n",
    "\n",
    "$$\\textbf{x} = \\begin{bmatrix}x_{1}\\\\ x_{2}\\end{bmatrix}$$\n",
    "\n",
    "$$\\textbf{y} = \\begin{bmatrix}y_{1}\\\\ y_{2} \\\\ y_{3}\\end{bmatrix}$$\n",
    "\n",
    "#### BlockOperator: \n",
    "\n",
    "BlockOperator is a matrix of operators.\n",
    "\n",
    "$$ K = \\begin{bmatrix}\n",
    "A_{1} & A_{2} \\\\\n",
    "A_{3} & A_{4} \\\\\n",
    "A_{5} & A_{6}\n",
    "\\end{bmatrix}_{(3,2)} *  \\quad \\underbrace{\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \n",
    "\\end{bmatrix}_{(2,1)}}_{\\textbf{x}} =  \\begin{bmatrix}\n",
    "A_{1}x_{1}  + A_{2}x_{2}\\\\\n",
    "A_{3}x_{1}  + A_{4}x_{2}\\\\\n",
    "A_{5}x_{1}  + A_{6}x_{2}\\\\\n",
    "\\end{bmatrix}_{(3,1)} =  \\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix}_{(3,1)} = \\textbf{y}$$\n",
    "\n",
    "Column: Share the same domains $X_{1}, X_{2}$<br>\n",
    "Rows: Share the same ranges $Y_{1}, Y_{2}, Y_{3}$\n",
    "\n",
    "$$ K : (X_{1}\\times X_{2}) \\rightarrow (Y_{1}\\times Y_{2} \\times Y_{3})$$\n",
    "\n",
    "\n",
    "$$ A_{1}, A_{3}, A_{5}: \\text{share the same domain }  X_{1}$$\n",
    "$$ A_{2}, A_{4}, A_{6}: \\text{share the same domain }  X_{2}$$\n",
    "\n",
    "$$A_{1}: X_{1} \\rightarrow Y_{1}, \\quad A_{3}: X_{1} \\rightarrow Y_{2}, \\quad  A_{5}: X_{1} \\rightarrow Y_{3}$$\n",
    "$$A_{2}: X_{2} \\rightarrow Y_{1}, \\quad A_{4}: X_{2} \\rightarrow Y_{2}, \\quad  A_{6}: X_{2} \\rightarrow Y_{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconstruct using Tikhonov by CGLS with the gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "Now we go back to our Tikhonov reconstruction, this time use the gradient operator in the regulariser.\n",
    "\n",
    "$${\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha \\nabla} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha \\nabla}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "And solve using CGLS:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "\n",
    "We'll use the framework's `Gradient()` operator - this is an optimised form of FD over the space dimensions (or even or space+channels in case of multiple channels).\n",
    "\n",
    "\n",
    "<span style=\"color:red;font-size:larger\">**Exercise 3:**</span> Set up the BlockOperator $\\tilde{A}$ and the BlockDataContainer $\\tilde{b}$ as before but with the Gradient operator. Outline code to be completed is given in the next two code cells. Once set up, run the following cells to execute CGLS with these as input. Run Tikhonov reconstruction using gradient regularisation. Try a range of $\\alpha$ values ranging from very small to very large, visualise the resulting image and central line profiles, and describe the effect of the regularisation parameter choice. Find the $\\alpha$ that (visually) gives you the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = GradientOperator(ig)\n",
    "alpha = 0.01\n",
    "\n",
    "operator_block = BlockOperator( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the data b\n",
    "data_block = BlockDataContainer( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the block operator and block data\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_tikh_g = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikh_g.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_tikh_g.run(200, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#plot the results\n",
    "plots = [cgls_tikh_g.solution, cgls_tikh_g.solution - phantom2D]\n",
    "titles = [\"Tikhonov with gradient regularisation\",\"Difference from ground truth\" ]\n",
    "show2D(plots,titles,fix_range=[(-0.2,1.2),(-0.2,0.2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central vertical line profiles of ground truth and Tikhonov with Gradient operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the vertical line profiles\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cgls_tikh_g.solution.get_slice(horizontal_y=n/2).as_array(),label=\"Tikhonov with Gradient regularisation\",color='purple')\n",
    "plt.plot(phantom2D.get_slice(horizontal_y=n/2).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the outputs of each reconstruction\n",
    "\n",
    "To wrap up we compare the reconstructions produced by all reconstruction methods considered in this notebook: Simple CGLS, Tikhonov with Identity regularisation and Tikhonov with Gradient regularisation, along with the ground truth image. We display images and central vertical line profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [phantom2D, cgls_simple.solution, cgls_tikh.solution, cgls_tikh_g.solution]\n",
    "titles = [\"Ground truth\", \"CGLS simple\", \"Tikhonov with Identity regularisation\", \"Tikhonov with gradient regularisation\" ]\n",
    "show2D(plots, titles, fix_range=(-0.2,1.2), num_cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cgls_simple.solution.get_slice(horizontal_y=n/2).as_array(),label=\"CGLS\",color='dodgerblue')\n",
    "plt.plot(cgls_tikh.solution.get_slice(horizontal_y=n/2).as_array(),label=\"Tikhonov with Identity regularisation\",color='firebrick')\n",
    "plt.plot(cgls_tikh_g.solution.get_slice(horizontal_y=n/2).as_array(),label=\"Tikhonov with Gradient regularisation\",color='purple')\n",
    "plt.plot(phantom2D.get_slice(horizontal_y=n/2).as_array(),label=\"Ground Truth\",color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from images and line profiles, Tikhonov with Gradient regularisation allows us to reduce the noise in the reconstruction substantially. However, we may pay a price in terms of blurring the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "\n",
    "After having worked through this notebook, we have now seen how to:\n",
    "\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularisation parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the present exercise on Tikhonov regularisation with the CGLS algorithm.  In other exercises we will see how to use the CIL framework for real data reconstruction and how to do regularisation based on non-smooth optimisation, to help preserve edges better, while reducing the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}